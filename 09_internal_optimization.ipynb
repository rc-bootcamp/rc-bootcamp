{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. Optimizing the ESN's Internal Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you will learn about RC schemes that adjust the internal connections of ESNs through online learning.\n",
    "\n",
    "**Note:** The code in this chapter does not work on Google Colaboratory.\n",
    "Please refer to the README to set up a local environment and run the code there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In standard ESN setups, the internal connections of the ESN are fixed.\n",
    "The internal weight, however, can be considered a type of closed loop.\n",
    "For example, consider the following ESN:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed} y[k] \\right)\\\\\n",
    "y[k] &= W^\\mathrm{out}x[k]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can be rewritten as the following equation:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed}W^\\mathrm{out}x[k] \\right)\\\\\n",
    "&= \\tanh\\left(\\left(\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}\\right) x[k] + W^\\mathrm{in} u[k+1] \\right)\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the internal connection can be viewed as $\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}$.\n",
    "Conversely, the pre-synaptic connection $W^\\mathrm{rec}_{i~\\cdot}$ and the post-synaptic connection $W^\\mathrm{rec}_{\\cdot~i}$ of the $i$-th node can be externalized as $W^\\mathrm{out}$ and $W^\\mathrm{feed}$ in a feedback loop, respectively.\n",
    "This means that internal connections can be adjusted using the closed-loop learning methods introduced in the previous chapter.\n",
    "A new question then arises: how to specify the target time-series data for the internal connection.\n",
    "Both **innate training**<sup>[1]</sup> and **full-FORCE**<sup>[2]</sup> generate a target time series using a different ESN and train the internal connection with FORCE learning<sup>[3]</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innate training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Innate training**<sup>[1]</sup> is an online learning method that adjusts the internal connections of ESNs, proposed by R. Laje et al.\n",
    "Innate training uses a chaotic ESN, and another ESN's internal connections are tuned to reproducibly generate the chaotic dynamics over a certain period.\n",
    "This target trajectory is called an **innate trajectory**.\n",
    "\n",
    "The learning process consists of pre-training and post-training.\n",
    "In pre-training, the internal connections are adjusted using FORCE learning<sup>[3]</sup>.\n",
    "Post-training is performed after pre-training, similar to standard RC.\n",
    "In other words, the readout layer is trained to output a specific trajectory in an open-loop system.\n",
    "The cost function $C(W^\\mathrm{rec})$ of the pre-training is expressed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] - x[k]\\|^2\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $x^\\mathrm{target}[k]$ is an innate trajectory, and $T$ is a time range.\n",
    "In innate training, a time series for a given input with an initial value $x^\\mathrm{target}[t_0]$ is often used as a target.\n",
    "Interestingly, the chaoticity is not completely suppressed even after pre-training.\n",
    "That is, even though the system is globally chaotic, the ESP locally recovers, and high-dimensional complex trajectories are reproducibly generated for a certain period.\n",
    "\n",
    "In addition, as will be shown in the demonstration, the high-dimensional chaotic trajectory has high expressiveness.\n",
    "This high-dimensional chaos can embed not only local patterns but also global switching rules between them<sup>[4]</sup> (see [the code provided by the paper's authors](https://github.com/katsuma-inoue/designing_chaotic_itinerancy_demo))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-FORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full FORCE**<sup>[2]</sup>, proposed by B. DePasquale et al., is another online learning method that adjusts the internal connections of an ESN.\n",
    "Unlike innate training, it does not use a chaotic ESN and its trajectory as the target time series.\n",
    "Instead, it uses the trajectory of a non-chaotic ESN ($\\rho<1$) with an additional input $u^\\mathrm{embed}[k]$, expressed by the following equation:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x^\\mathrm{target}[k+1] &= (1-a)x^\\mathrm{target}[k] + a\\tanh\\left(\\rho W^\\mathrm{rec} x^\\mathrm{target}[k] + W^\\mathrm{in} u^\\mathrm{in}[k]+ W^\\mathrm{embed} u^\\mathrm{embed}[k] \\right)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $u^\\mathrm{embed}[k]$ is an additional input to be embedded and is a function of $u^\\mathrm{in}[k]$.\n",
    "Full-FORCE aims to design an ESN that replicates the dynamics **without** this $u^\\mathrm{embed}[k]$.\n",
    "The cost function $C(W^\\mathrm{rec})$ is expressed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] + W^\\mathrm{embed}u^\\mathrm{embed}[k] - x[k]\\|^2\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full-FORCE learning also involves post-training, where an additional readout layer is adjusted.\n",
    "A key feature of full-FORCE is that embedding $W^\\mathrm{embed} u^\\mathrm{embed}[k]$ allows for designing more complex time series compared to FORCE learning alone.\n",
    "In this way, full-FORCE improves the design capability of time series by adjusting the internal connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises and demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to import the classes that we implemented previously, as well as the basic libraries.\n",
    "You can check the internal implementations by uncommenting the lines after `import inspect` or by using `...?? / ??...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import Output\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    if False:  # Set to True if you want to use Google Drive and save your work there.\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "        %cd /content/gdrive/My Drive/rc-bootcamp/\n",
    "        # NOTE: Change it to your own path if you put the zip file elsewhere.\n",
    "        # e.g., %cd /content/gdrive/My Drive/[PATH_TO_EXTRACT]/rc-bootcamp/\n",
    "    else:\n",
    "        pass\n",
    "        %cd /content/\n",
    "        !git clone --branch en https://github.com/rc-bootcamp/rc-bootcamp.git\n",
    "        %cd /content/rc-bootcamp/\n",
    "else:\n",
    "    sys.path.append(\".\")\n",
    "\n",
    "from utils.interface import InteractiveViewer\n",
    "from utils.interpolate import interp1d\n",
    "from utils.reservoir import ESN, RidgeReadout, rls_update\n",
    "from utils.style_config import plt\n",
    "from utils.tester import load_from_chapter_name\n",
    "from utils.tqdm import tqdm, trange\n",
    "from utils.viewer import show_innate_error, show_innate_record\n",
    "\n",
    "test_func, show_solution = load_from_chapter_name(\"09_internal_optimization\")\n",
    "\n",
    "\n",
    "# Uncomment it to see the implementations.\n",
    "# import inspect\n",
    "# print(inspect.getsource(Linear))\n",
    "# print(inspect.getsource(RidgeReadout))\n",
    "# print(inspect.getsource(ESN))\n",
    "# print(inspect.getsource(rls_update))\n",
    "\n",
    "# Or just use ??.../...?? (uncomment the following lines).\n",
    "# Linear??\n",
    "# RidgeReadout??\n",
    "# ESN??\n",
    "# rls_update??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by implementing the pre-training process.\n",
    "As mentioned above, innate training considers the pre-synaptic connections of each node as a linear closed loop and adjusts them using FORCE learning.\n",
    "The following equation shows the weight update rule based on FORCE learning for the $i$-th pre-synaptic connection ($1 \\leq i \\leq N$).\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "k^{i} &= P^{i} x^{i} \\\\\n",
    "g^{i} &= \\frac{1}{1+{x^{i}}^\\top k^{i}} \\\\\n",
    "\\Delta P^{i} &= g^{i}{k}^{i}{k^{i}}^\\top \\\\\n",
    "\\Delta W^\\mathrm{rec}_{i~\\cdot} &= g^{i} (\\hat{x}^{i} - {x}^{i}) {k}^{i} \\\\\n",
    "P^{i} &\\leftarrow P^{i} - \\Delta P^{i} \\\\\n",
    "W^\\mathrm{rec}_{i~\\cdot}  &\\leftarrow W^\\mathrm{rec}_{i~\\cdot}  + \\Delta W^\\mathrm{rec}_{i~\\cdot}\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $P^{i} \\in \\mathbb{R}^{N^{i}\\times N^{i}}$ is a positive definite matrix initialized as ${I}/{\\alpha}$, and $\\hat{x}$ is the innate trajectory.\n",
    "Since we use FORCE learning based on the RLS algorithm, we can reuse `rls_update` implemented in the previous chapter.\n",
    "Note that since the internal connections of the ESN are sparse (`sparse < 1.0`, $p < 1.0$), $N^{i}$ takes a smaller value than $N$ ($N^{i} \\approx pN$), which reduces the computational complexity from $O(N \\times N^2)$ to $O(p^2 N^3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.1.\n",
    "\n",
    "Complete `InnateESN.__init__` and `InnateESN.train` by filling in the blanks in the following cell.\n",
    "\n",
    "- `InnateESN.train`\n",
    "  - Argument(s)\n",
    "    - `x_target`: `np.ndarray`\n",
    "      - innate trajectory $\\hat{x}[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
    "    - `x_now`: `np.ndarray`\n",
    "      - $x[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
    "  - Return(s)\n",
    "    - `self.w_net`: `np.ndarray`\n",
    "      - $\\Delta W^\\mathrm{rec}$\n",
    "\n",
    "  - Operation(s)\n",
    "    - Update `InnateESN.P` ($P^i$) with `rls_update`, which are initialized $I/\\lambda$ in `__init__`.\n",
    "    - Update `InnateESN.w_net` with `rls_update`.\n",
    "\n",
    "<details><summary>tips</summary>\n",
    "\n",
    "- [`np.nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnateESN(ESN):\n",
    "    def __init__(self, *args, lmbd=1.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Tunable ESN [Laje, R., & Buonomano, D. V. (2013). Nature neuroscience, 16(7), 925-933.]\n",
    "\n",
    "        Args:\n",
    "            alpha (float, optional): regularization parameter for RLS algorithm. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        super(InnateESN, self).__init__(*args, **kwargs)\n",
    "        self.w_pre = {}\n",
    "        self.P = {}\n",
    "        for post in range(self.dim):\n",
    "            non_zeros = self.weight[post].nonzero()[0]\n",
    "            self.w_pre[post] = non_zeros\n",
    "            self.P[post] = ...  # TODO Initialize P matrix for RLS.\n",
    "\n",
    "    def train(self, x_target, x_now=None, node_list=None):\n",
    "        \"\"\"\n",
    "        Update the internal weight by RLS algorithm\n",
    "\n",
    "        Args:\n",
    "            x_target (np.ndarray): State(s) on an inante trajectory.\n",
    "            x_now (np.ndarray, optional): Current state(s). Defaults to None (use self.x).\n",
    "            node_list (list, slice, optional): Tuned nodes. Defaults to None (train all nodes).\n",
    "        \"\"\"\n",
    "        if x_now is None:\n",
    "            x_now = np.asarray(self.x)\n",
    "        if node_list is None:\n",
    "            node_list = range(self.dim)\n",
    "        for xt, xn in zip(x_target.reshape(-1, self.dim), x_now.reshape(-1, self.dim), strict=False):\n",
    "            es = xt[node_list] - xn[node_list]\n",
    "            for node_id, e in zip(node_list, es, strict=False):\n",
    "                x = ...  # TODO Use self.w_pre (hint: `x = xn[...]`).\n",
    "                P = ...  # TODO Get P matrix for the node (hint: `P = self.P[...]`).\n",
    "                g, k, P_new = ...  # TODO Use `rls_update`.\n",
    "                dw = ...  # TODO Calculate dw (hint: use `g`, `e`, and `k`).\n",
    "                self.P[node_id] = P_new\n",
    "                self.weight[node_id, self.w_pre[node_id]] += dw[0]\n",
    "        return self.weight\n",
    "\n",
    "    def to_pickle(self, file_name):\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "        P, w_pre = self.P, self.w_pre\n",
    "        self.P, self.w_pre = {}, {}\n",
    "        with open(file_name, mode=\"wb\") as f:\n",
    "            joblib.dump(self, f, compress=True)\n",
    "        self.P, self.w_pre = P, w_pre\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pickle(file_name):\n",
    "        with open(file_name, mode=\"rb\") as f:\n",
    "            module = joblib.load(f)\n",
    "        return module\n",
    "\n",
    "\n",
    "def solution(dim, seed, x_target, x_now, node_list):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    net = InnateESN(dim, seed=seed, node_list=node_list)\n",
    "    net.train(x_target=x_target, x_now=x_now, node_list=node_list)\n",
    "    return net.weight\n",
    "\n",
    "\n",
    "test_func(solution, \"01_01\")\n",
    "# show_solution(\"01_01\", \"InnateESN\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.2.\n",
    "\n",
    "Implement `emulate_innate` by filling in the blank in the following cell.\n",
    "It will update $W^\\mathrm{rec}$ using `InnateESN.train` when $k \\in [t_\\mathrm{b}, t_\\mathrm{e}) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every})$, and do nothing otherwise.\n",
    "\n",
    "- `emulate_innate`\n",
    "  - Argument(s):\n",
    "    - `ts`: `list | np.ndarray`\n",
    "    - `net`: `InnateESN`\n",
    "    - `f_in`: `Callable`\n",
    "      - $f^\\text{in}(t)$\n",
    "    - `innate_range`: `tuple(int, int)`\n",
    "      - $[t_\\mathrm{b}, t_\\mathrm{e})$\n",
    "    - `innate_node`: `list | slice`\n",
    "    - `innate_every`: `int`\n",
    "      - $t_\\mathrm{every}$\n",
    "    - `innate_func`: `Callable`\n",
    "      - $\\hat{x}: T \\to \\mathbb{R}^{\\cdots \\times N}$\n",
    "  - Return(s):\n",
    "    - `record`: `dict`\n",
    "      - `'t'`: `np.ndarray`\n",
    "        - $[t_0, t_1,~\\ldots,~t_{T-1}]$\n",
    "      - `'x'`: `np.ndarray`\n",
    "        - $[x[t_0], x[t_1],~\\ldots,~x[t_{T-1}]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate_innate(\n",
    "    ts,\n",
    "    net,\n",
    "    f_in=None,\n",
    "    innate_range=None,\n",
    "    innate_func=None,\n",
    "    innate_node=None,\n",
    "    innate_every=2,\n",
    "    prefix=\"\",\n",
    "    leave=True,\n",
    "    display=True,\n",
    "):\n",
    "    record = {}\n",
    "    record[\"t\"] = np.zeros(len(ts), dtype=int)\n",
    "    record[\"x\"] = np.zeros((len(ts), *net.x.shape))\n",
    "    pbar = tqdm(ts, leave=leave, display=display)\n",
    "    for cnt, t in enumerate(pbar):\n",
    "        pbar.set_description(\"{}t={:.0f}\".format(prefix, t))\n",
    "        u_in = np.zeros_like(net.x)\n",
    "        if f_in is not None:\n",
    "            u_in += f_in(t)\n",
    "        net.step(u_in)\n",
    "        record[\"t\"][cnt] = t\n",
    "        record[\"x\"][cnt] = net.x\n",
    "        if (innate_range is not None) and (innate_range[0] <= t < innate_range[1]):\n",
    "            if cnt % innate_every == 0:\n",
    "                # TODO Use `net.train` and specify `node_list=innate_node`.\n",
    "                ...\n",
    "    return record\n",
    "\n",
    "\n",
    "def solution(ts, dim, seed, **kwargs):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    net = InnateESN(dim, seed=seed)\n",
    "    record = emulate_innate(ts, net, **kwargs)\n",
    "    return record[\"x\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"01_02\")\n",
    "# show_solution(\"01_02\", \"emulate_innate\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell.\n",
    "\n",
    "- `create_target`: Generate the innate trajectory.\n",
    "- `train_network`: Run the pre-training.\n",
    "- `eval_network`: Evaluate the pre-trained network.\n",
    "- `eval_error`: Evaluate the MSE and NRMSE between the innate trajectory and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(record_range, net, f_in, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"sample \")\n",
    "    return record\n",
    "\n",
    "\n",
    "def train_network(record_range, net, f_in, rec_target, innate_range, innate_node, innate_every, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    innate_func = interp1d(rec_target[\"x\"], x=rec_target[\"t\"], kind=1, axis=0)\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
    "    record = emulate_innate(\n",
    "        range(*record_range),\n",
    "        net,\n",
    "        f_in=f_in,\n",
    "        prefix=\"train \",\n",
    "        innate_func=innate_func,\n",
    "        innate_node=innate_node,\n",
    "        innate_range=innate_range,\n",
    "        innate_every=innate_every,\n",
    "    )\n",
    "    return record\n",
    "\n",
    "\n",
    "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
    "    return record\n",
    "\n",
    "\n",
    "def eval_error(rec_eval, rec_target, innate_range, innate_node):\n",
    "    begin_id = int(innate_range[0] - rec_eval[\"t\"][0])\n",
    "    end_id = int(innate_range[1] - rec_eval[\"t\"][0])\n",
    "    diff = rec_eval[\"x\"] - rec_target[\"x\"][:, None]  # -> [Time_steps, Eval_num, w_pulse_num, Net_dim]\n",
    "    norm = (diff[begin_id:end_id, ..., innate_node] ** 2).sum(axis=-1)  # -> [T, E, W]\n",
    "    mse = norm.mean(axis=0)  # -> [E, W]\n",
    "\n",
    "    var = (rec_target[\"x\"][begin_id:end_id, ..., innate_node] ** 2).sum(axis=(0, 2))  # -> [W]\n",
    "    nrmse = (norm.sum(axis=0) / var) ** 0.5  # -> [E, W]\n",
    "    return {\"mse\": mse, \"nrmse\": nrmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to the demonstration.\n",
    "\n",
    "First, specify the experimental parameters.\n",
    "Since pre-training might take a long time, the following cells create an output folder `save_dir` (`./output` by default) to allow restoring the results even after it halts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./result\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "w_pulse_num = 1\n",
    "dim, a, sr, p = 1000, 0.1, 1.6, 0.2\n",
    "pulse_amp, pulse_period = 10.0, 50\n",
    "\n",
    "alpha = 1.0\n",
    "innate_epoch = 20\n",
    "innate_period, innate_rate, innate_every = 3000, 0.1, 4\n",
    "washout_period, record_period = 1000, 5000\n",
    "\n",
    "rnd = np.random.default_rng(seed)\n",
    "net = InnateESN(dim, a=a, sr=sr, p=p, alpha=alpha, rnd=rnd)\n",
    "w_pulse = rnd.uniform(size=(w_pulse_num + 2, dim), low=-1.0, high=1.0)\n",
    "\n",
    "innate_range = [0, innate_period]\n",
    "innate_node = list(range(0, int(innate_rate * net.dim)))\n",
    "record_range = [-washout_period, record_period]\n",
    "pulse_range = [-pulse_period, 0]\n",
    "\n",
    "plot_range = list(range(5))\n",
    "\n",
    "\n",
    "def f_in(t):\n",
    "    if -pulse_period <= t < 0:\n",
    "        return pulse_amp * w_pulse[:w_pulse_num]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "f_in.dim = w_pulse_num\n",
    "\n",
    "with open(f\"{save_dir}/params.json\", mode=\"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"pulse_amp\": pulse_amp,\n",
    "            \"pulse_period\": pulse_period,\n",
    "            \"innate_period\": innate_period,\n",
    "            \"innate_rate\": innate_rate,\n",
    "            \"innate_every\": innate_every,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "np.save(f\"{save_dir}/w_pulse.npy\", w_pulse)\n",
    "net.to_pickle(f\"{save_dir}/net_init.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will generate the innate trajectory $\\hat{x}[k]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_target = create_target(record_range, net, f_in, rnd=rnd)\n",
    "fig_target = show_innate_record(\n",
    "    rec_target,\n",
    "    plot_range,\n",
    "    lw=1.5,\n",
    "    color=\"k\",\n",
    "    title=\"innate trajectory\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "np.savez_compressed(f\"{save_dir}/rec_target.npz\", *rec_target)\n",
    "fig_target.savefig(f\"{save_dir}/rec_target.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray area represents the period when the pulse input is given.\n",
    "The pink area shows the pre-training period $[t_\\mathrm{b}, t_\\mathrm{e})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):  # noqa: F811\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
    "    return record\n",
    "\n",
    "\n",
    "rec_init = eval_network(record_range, net, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_target,\n",
    "    plot_range,\n",
    "    lw=1.5,\n",
    "    ls=\":\",\n",
    "    clear=True,\n",
    "    color=\"k\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "fig = show_innate_record(\n",
    "    rec_init,\n",
    "    plot_range,\n",
    "    lw=0.5,\n",
    "    ls=\"-\",\n",
    "    fig=fig,\n",
    "    cmap=plt.get_cmap(\"tab10\"),\n",
    "    title=\"eval (before pre-training)\",\n",
    ")\n",
    "fig.savefig(f\"{save_dir}/eval/init.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows that the ESN cannot reproducibly generate the innate trajectories (dotted lines) at this point.\n",
    "\n",
    "The following cell runs the pre-training iteratively.\n",
    "This will take 20-30 minutes, so please wait until it finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {}\n",
    "best_score = np.array(np.inf)\n",
    "figs = defaultdict(lambda: None)\n",
    "\n",
    "pbar = trange(innate_epoch)\n",
    "out_tqdm, out_figure = Output(), Output()\n",
    "display(out_tqdm)\n",
    "display(out_figure)\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(\"best:{:.2e}\".format(best_score))\n",
    "    with out_tqdm:\n",
    "        clear_output(wait=True)\n",
    "        # Training phase\n",
    "        rec_train = train_network(\n",
    "            record_range,\n",
    "            net,\n",
    "            f_in,\n",
    "            rec_target,\n",
    "            innate_range,\n",
    "            innate_node,\n",
    "            innate_every,\n",
    "            rnd=rnd,\n",
    "        )\n",
    "        figs[\"train\"] = show_innate_record(\n",
    "            rec_target,\n",
    "            plot_range,\n",
    "            lw=1.5,\n",
    "            ls=\":\",\n",
    "            clear=True,\n",
    "            color=\"black\",\n",
    "            fig=figs[\"train\"],\n",
    "            pulse_range=pulse_range,\n",
    "            innate_range=innate_range,\n",
    "        )\n",
    "        figs[\"train\"] = show_innate_record(\n",
    "            rec_train,\n",
    "            plot_range,\n",
    "            lw=1.0,\n",
    "            ls=\"-\",\n",
    "            fig=figs[\"train\"],\n",
    "            cmap=plt.get_cmap(\"tab10\"),\n",
    "            title=f\"train (epoch #{epoch})\",\n",
    "        )\n",
    "        figs[\"train\"].savefig(\"{}/train/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
    "\n",
    "        # Evaluation phase\n",
    "        rec_eval = eval_network(record_range, net, f_in, rnd=rnd)\n",
    "        figs[\"eval\"] = show_innate_record(\n",
    "            rec_target,\n",
    "            plot_range,\n",
    "            lw=1.5,\n",
    "            ls=\":\",\n",
    "            clear=True,\n",
    "            color=\"black\",\n",
    "            fig=figs[\"eval\"],\n",
    "            pulse_range=pulse_range,\n",
    "            innate_range=innate_range,\n",
    "        )\n",
    "        figs[\"eval\"] = show_innate_record(\n",
    "            rec_eval,\n",
    "            plot_range,\n",
    "            lw=0.5,\n",
    "            ls=\"-\",\n",
    "            fig=figs[\"eval\"],\n",
    "            cmap=plt.get_cmap(\"tab10\"),\n",
    "            title=f\"eval (epoch #{epoch})\",\n",
    "        )\n",
    "        figs[\"eval\"].savefig(\"{}/eval/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
    "\n",
    "        # Record evaluation error\n",
    "        rec = eval_error(rec_eval, rec_target, innate_range, innate_node)\n",
    "        best_score = min(best_score, rec[\"nrmse\"].sum())\n",
    "        rec[\"best\"] = best_score\n",
    "\n",
    "        for key, val in rec.items():\n",
    "            if key not in record:\n",
    "                record[key] = np.zeros((innate_epoch, *val.shape))\n",
    "            record[key][epoch] = val\n",
    "\n",
    "    with out_figure:\n",
    "        clear_output(wait=True)\n",
    "        figs[\"nrmse\"] = show_innate_error(record[\"nrmse\"][: epoch + 1], fig=figs[\"nrmse\"])\n",
    "        figs[\"nrmse\"].savefig(f\"{save_dir}/nrmse.png\", dpi=200)\n",
    "        for _name, fig in figs.items():\n",
    "            size = fig.get_size_inches()\n",
    "            fig.set_size_inches(8, 3)\n",
    "            display(fig)\n",
    "            fig.set_size_inches(size)\n",
    "\n",
    "net.to_pickle(f\"{save_dir}/net_term.pkl\")\n",
    "np.savez_compressed(f\"{save_dir}/record.npz\", **record)\n",
    "\n",
    "for _name, fig in figs.items():\n",
    "    fig.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that the ESN gradually becomes able to reproducibly generate complex high-dimensional chaos despite different initial values.\n",
    "Check the figures saved in `{save_dir}/eval`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.3. (Advanced)\n",
    "\n",
    "- Vary the number of nodes and observe the differences in MSE.\n",
    "- Try a longer `innate_period` and compare the pre-training performance.\n",
    "- Increase `w_pulse_num` and pre-train with multiple inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing post-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the readout layer using a pre-trained ESN.\n",
    "The following cell loads the ESN saved in `{load_dir}/net_term.pkl` and the parameter file saved in `{load_dir}/params.json`.\n",
    "You can skip the previous cell and start from here if you have already completed the pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = \"./result\"\n",
    "\n",
    "net_init = InnateESN.read_pickle(f\"{load_dir}/net_init.pkl\")\n",
    "net_term = InnateESN.read_pickle(f\"{load_dir}/net_term.pkl\")\n",
    "w_pulse = np.load(f\"{load_dir}/w_pulse.npy\")\n",
    "with open(f\"{load_dir}/params.json\", mode=\"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "pulse_amp = params[\"pulse_amp\"]\n",
    "pulse_period = params[\"pulse_period\"]\n",
    "innate_period = params[\"innate_period\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell compares the trajectories of the ESN before and after pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "w_pulse_num = 1\n",
    "washout_period, record_period = 1000, 10000\n",
    "record_range = [-washout_period, record_period]\n",
    "pulse_range = [-pulse_period, 0]\n",
    "innate_range = [0, innate_period]\n",
    "plot_range = list(range(5))\n",
    "\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "def f_in(t):\n",
    "    if -pulse_period <= t < 0:\n",
    "        return pulse_amp * w_pulse[:w_pulse_num]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "f_in.dim = w_pulse_num\n",
    "\n",
    "rec_sample_init = eval_network(record_range, net_init, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_sample_init,\n",
    "    plot_range,\n",
    "    lw=1.0,\n",
    "    title=\"initial\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "\n",
    "rec_sample_term = eval_network(record_range, net_term, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_sample_term,\n",
    "    plot_range,\n",
    "    lw=1.0,\n",
    "    title=\"pre-trained\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's prepare the target output time series for the readout layer.\n",
    "`abc.csv` and `star.csv` are available in `./data/09_internal_optimization`.\n",
    "Let's use `abc.csv` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./data/09_internal_optimization/abc.csv\", delimiter=\",\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(data[:, 0], data[:, 1])\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained ESN reproducibly generates innate trajectories for $t\\in[0, t_\\mathrm{innate})$ after the input is given.\n",
    "The following cell trains the readout layer to map this high-dimensional chaos to the prepared time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, xs = rec_sample_term[\"t\"], rec_sample_term[\"x\"]\n",
    "\n",
    "x_train = xs[washout_period : washout_period + innate_period, :, 0, :]\n",
    "\n",
    "target_func = interp1d(data, kind=1, axis=0)\n",
    "ds = target_func(np.linspace(0, 1, innate_period))\n",
    "ds = np.broadcast_to(ds[:, None, :], (*x_train.shape[:-1], ds.shape[-1]))\n",
    "\n",
    "w_out = RidgeReadout(net_term.dim, 2, lmbd=1e-2)\n",
    "weight, bias = w_out.train(x_train.reshape(-1, x_train.shape[-1]), ds.reshape(-1, ds.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`InteractiveView` is an interface where you can interactively give inputs.\n",
    "Run the following cell and check that the target trajectory `abc.csv` is properly output after the input is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import copy\n",
    "\n",
    "try:\n",
    "    del viewer  # type: ignore\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "net_term_cp = copy.deepcopy(net_term)\n",
    "\n",
    "net_term_cp.x = rnd.uniform(-1, 1, net_term_cp.dim)\n",
    "viewer = InteractiveViewer(\n",
    "    net_term_cp,\n",
    "    w_out,\n",
    "    w_pulse,\n",
    "    pulse_amp,\n",
    "    pulse_period,\n",
    "    plot_num=5,\n",
    "    input_num=w_pulse_num,\n",
    "    max_time_steps=10000,\n",
    "    cmap=\"Greens\",\n",
    ")\n",
    "\n",
    "viewer.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.1. (Advanced)\n",
    "\n",
    "- By increasing the `input_num` argument in `InteractiveView`, you can increase the number of input types. However, the network has not been trained for these inputs yet, so only meaningless outputs will be obtained. Increase the number of inputs to 2 (`w_pulse_num=2`) and perform both pre-training and post-training so that a different input generates a \"star\" output (`star.csv`) (this can be done with minor modifications)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.2. (Advanced)\n",
    "\n",
    "- Full FORCE can be implemented with almost no code changes from innate training. Implement `FullFORCEESN` inheriting from `InnateESN` by referring to [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Laje, R., & Buonomano, D. V. (2013). *Robust timing and motor patterns by taming chaos in recurrent neural networks*. Nature Neuroscience, 16(7), 925–933. https://doi.org/10.1038/nn.3405\n",
    "\n",
    "[2] DePasquale, B., Cueva, C. J., Rajan, K., Escola, G. S., & Abbott, L. F. (2018). *full-FORCE: A target-based method for training recurrent networks*. PLOS ONE, 13(2), e0191527. https://doi.org/10.1371/journal.pone.0191527\n",
    "\n",
    "[3] Sussillo, D., & Abbott, L. F. (2009). *Generating Coherent Patterns of Activity from Chaotic Neural Networks*. Neuron, 63(4), 544–557. https://doi.org/10.1016/j.neuron.2009.07.018\n",
    "\n",
    "[4] Inoue, K., Nakajima, K., & Kuniyoshi, Y. (2020). *Designing spontaneous behavioral switching via chaotic itinerancy*. Science Advances, 6(46), eabb3989. https://doi.org/10.1126/sciadv.abb3989"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc-bootcamp (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
