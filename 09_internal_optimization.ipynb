{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. ESNの内部結合の学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章では、前章の手法を発展させ、ESNの内部結合をオンライン学習で調整する手法を扱います。\n",
    "\n",
    "**注意:** この章のコードはGoogle Colaboratory上では動作しません。READMEを参照の上、ローカル環境を構築し、その上で実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前書き"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常、ESNを用いたRCではESNの内部結合は固定されます。\n",
    "一方で内部結合は、前回議論されたように、閉ループの一種としてみなせます。\n",
    "例えば以下のESNを考えます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed} y[k] \\right)\\\\\n",
    "y[k] &= W^\\mathrm{out}x[k]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時、 $y[k]$ を代入すると以下の式になります。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed}W^\\mathrm{out}x[k] \\right)\\\\\n",
    "&= \\tanh\\left(\\left(\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}\\right) x[k] + W^\\mathrm{in} u[k+1] \\right)\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つまり内部結合が $\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}$ とみなせます。\n",
    "また逆の操作で、あるESN上の $i$ 番目のノードに結合する前結合 $W^\\mathrm{rec}_{i~\\cdot}$ 、後結合 $W^\\mathrm{rec}_{\\cdot~i}$ をそれぞれ $W^\\mathrm{out}$、$W^\\mathrm{feed}$ として内部結合を閉ループとして外部化できます。\n",
    "あとは前章の閉ループの学習プロセスで調整すれば内部結合を調整できます。\n",
    "ここで新たにどのように目標時系列を指定するか問題となります。\n",
    "\n",
    "今回紹介する **生得的学習 (innate training)**<sup>[1]</sup>ならびに **full-FORCE**<sup>[2]</sup>はいずれも別のESNを用いて目標時系列を生成し、FORCE学習<sup>[3]</sup>によって学習を達成します。\n",
    "以下その概要を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生得的学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**生得的学習**<sup>[1]</sup> はR. Lajeらによって提案されたESNの内部結合を調整するオンライン学習法の一種です。\n",
    "生得的学習の特徴的な点はその目標時系列の指定方法です。\n",
    "特にカオスESNを用意し、ある入力が与えられた後のカオスESNの内部状態の時系列を、別のESNで一定期間再現的に生成するように内部結合が学習されます。\n",
    "またこの目標となる軌道は **生得的軌道 (innate trajectory)** と呼ばれます。\n",
    "\n",
    "生得的学習の学習プロセスは、事前学習と事後学習の2段階に分けられます。\n",
    "事前学習では、FORCE学習<sup>[3]</sup>を用いて内部結合が調整されます。\n",
    "事後学習は、通常のRCと同様に、事前学習の後に行われます。\n",
    "すなわち開ループ系で特定の軌道を出力するようにリードアウト層が学習されます。\n",
    "このときのコスト関数 $C(W^\\mathrm{rec})$ は以下のとおり表されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] - x[k]\\|^2\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x^\\mathrm{target}[k]$ は生得的軌道、$T$ はある時間の範囲です。\n",
    "生得的学習ではある初期値 $x^\\mathrm{target}[t_0]$ とある入力に対する時系列をターゲットとして採用するケースが多いです。\n",
    "\n",
    "生得的学習の興味深い点は、カオス性が事前学習後にも完全に抑圧されない点にあります。\n",
    "即ち全体としては系がカオス的にも関わらず、局所的にESPが回復し一定期間高次元な複雑な軌道が再現的に生成されるのです。\n",
    "またデモンストレーションで後ほど示されますが、その高次元なカオス軌道は高い表現能力を有し、様々な軌道を設計できます。\n",
    "またこの高次元カオスは、局所的なパターンのみならず、大域的なパターン間の切り替え則を埋め込み、カオス的遍歴上の軌道を設計できます<sup>[4]</sup>（[論文のコード参照](https://github.com/katsuma-inoue/designing_chaotic_itinerancy_demo)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-FORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. DePasqualeらによって提案された**Full FORCE**<sup>[2]</sup>もまた、ESNの内部状態を調整するオンライン学習法です。\n",
    "生得的学習とは異なり、カオスESNとその軌道を目標時系列としては使用しません。\n",
    "代わりに以下の式で表される、ある入力 $u^\\mathrm{embed}[k]$ が与えられた際の非カオスESN（ $\\rho<1$ ）の軌道を目標に据えます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x^\\mathrm{target}[k+1] &= (1-a)x^\\mathrm{target}[k] + a\\tanh\\left(\\rho W^\\mathrm{rec} x^\\mathrm{target}[k] + W^\\mathrm{in} u^\\mathrm{in}[k]+ W^\\mathrm{embed} u^\\mathrm{embed}[k] \\right)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$u^\\mathrm{embed}[k]$ は埋め込み対象の追加の入力で、 $u^\\mathrm{in}[k]$ の関数であるものを用います。\n",
    "full-FORCEでは、この $u^\\mathrm{embed}[k]$ **なしに** ESNへの埋め込みを目指します。\n",
    "つまりこのときのコスト関数 $C(W^\\mathrm{rec})$ は以下の式で表されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] + W^\\mathrm{embed}u^\\mathrm{embed}[k] - x[k]\\|^2\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full-FORCE学習でも事後学習は存在し、追加のリードアウト層が調整されます。\n",
    "full-FORCEの特徴として、この $W^\\mathrm{embed} u^\\mathrm{embed}[k]$ の埋め込みにより、FORCE学習単体より複雑な時系列の設計が可能になる点が挙げられます。\n",
    "このようにfull-FORCEは、内部結合の調整により時系列の設計性を向上させる手法といえます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題と実演"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同様、各種ライブラリおよび実装済みの関数の`import`を行うために次のセルを実行してください。\n",
    "なお内部実装を再確認するには、`import inspect`以下の行をコメントアウトするか`...?? / ??...`を使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import Output\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    if False:  # Set to True if you want to use Google Drive and save your work there.\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "        %cd /content/gdrive/My Drive/rc-bootcamp/\n",
    "        # NOTE: Change it to your own path if you put the zip file elsewhere.\n",
    "        # e.g., %cd /content/gdrive/My Drive/[PATH_TO_EXTRACT]/rc-bootcamp/\n",
    "    else:\n",
    "        pass\n",
    "        %cd /content/\n",
    "        !git clone --branch ja_sol https://github.com/rc-bootcamp/rc-bootcamp.git\n",
    "        %cd /content/rc-bootcamp/\n",
    "else:\n",
    "    sys.path.append(\".\")\n",
    "\n",
    "from utils.interface import InteractiveViewer\n",
    "from utils.interpolate import interp1d\n",
    "from utils.reservoir import ESN, RidgeReadout, rls_update\n",
    "from utils.style_config import plt\n",
    "from utils.tester import load_from_chapter_name\n",
    "from utils.tqdm import tqdm, trange\n",
    "from utils.viewer import show_innate_error, show_innate_record\n",
    "\n",
    "test_func, show_solution = load_from_chapter_name(\"09_internal_optimization\")\n",
    "\n",
    "\n",
    "# Uncomment it to see the implementations.\n",
    "# import inspect\n",
    "# print(inspect.getsource(Linear))\n",
    "# print(inspect.getsource(RidgeReadout))\n",
    "# print(inspect.getsource(ESN))\n",
    "# print(inspect.getsource(rls_update))\n",
    "\n",
    "# Or just use ??.../...?? (uncomment the following lines).\n",
    "# Linear??\n",
    "# RidgeReadout??\n",
    "# ESN??\n",
    "# rls_update??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 事前学習の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは 生得的学習の事前学習の実装から始めましょう。\n",
    "先述のとおり生得的学習は、各ノードの前結合を線形閉ループと見なし、FORCE学習を用いて内部結合を調整する手法です。\n",
    "次の式は、$i$ 番目の前結合 ($1\\leq i \\leq N$) に対する FORCE 学習に基づく重み更新則を示しています。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "k^{i} &= P^{i} x^{i} \\\\\n",
    "g^{i} &= \\frac{1}{1+{x^{i}}^\\top k^{i}} \\\\\n",
    "\\Delta P^{i} &= g^{i}{k}^{i}{k^{i}}^\\top \\\\\n",
    "\\Delta W^\\mathrm{rec}_{i~\\cdot} &= g^{i} (\\hat{x}^{i} - {x}^{i}) {k}^{i} \\\\\n",
    "P^{i} &\\leftarrow P^{i} - \\Delta P^{i} \\\\\n",
    "W^\\mathrm{rec}_{i~\\cdot}  &\\leftarrow W^\\mathrm{rec}_{i~\\cdot}  + \\Delta W^\\mathrm{rec}_{i~\\cdot}\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、$P^{i} \\in \\mathbb{R}^{N^{i}\\times N^{i}}$ は ${I}/{\\alpha}$ として初期化された正定値行列であり、$\\hat{x}$ は 生得的軌道です。\n",
    "RLSアルゴリズムに基づくFORCE学習を使用しているため、前章で実装した `rls_update` を再利用できます。\n",
    "ESNの内部結合が疎（`sparse < 1.0`; $p<1.0$ ）であるため、$N^{i}$ は $N$ よりも小さい値を取り ( $N^{i} \\approx p N$ )、計算量が $O(N\\times N^2)$ と比較して大幅に小さい点に注意してください（$O(p^2 N^3)$）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.1.\n",
    "\n",
    "以下の穴埋めを実装し、 `InnateESN.__init__` と `InnateESN.train` を完成させよ。\n",
    "\n",
    "- `InnateESN.train`\n",
    "  - Argument(s)\n",
    "    - `x_target`: `np.ndarray`\n",
    "      - innate trajectory $\\hat{x}[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
    "    - `x_now`: `np.ndarray`\n",
    "      - $x[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
    "  - Return(s)\n",
    "    - `self.w_net`: `np.ndarray`\n",
    "      - $\\Delta W^\\mathrm{rec}$\n",
    "\n",
    "  - Operation(s)\n",
    "    - `rls_update`を用いた`InnateESN.P`の更新（ $I/\\lambda$ で初期化）\n",
    "    - `InnateESN.w_net` の更新\n",
    "\n",
    "<details><summary>tips</summary>\n",
    "\n",
    "- [`np.nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnateESN(ESN):\n",
    "    def __init__(self, *args, lmbd=1.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Tunable ESN [Laje, R., & Buonomano, D. V. (2013). Nature neuroscience, 16(7), 925-933.]\n",
    "\n",
    "        Args:\n",
    "            alpha (float, optional): regularization parameter for RLS algorithm. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        super(InnateESN, self).__init__(*args, **kwargs)\n",
    "        self.w_pre = {}\n",
    "        self.P = {}\n",
    "        for post in range(self.dim):\n",
    "            non_zeros = self.weight[post].nonzero()[0]\n",
    "            self.w_pre[post] = non_zeros\n",
    "            self.P[post] = np.eye(len(self.w_pre[post])) / lmbd  # TODO Initialize P matrix for RLS.\n",
    "\n",
    "    def train(self, x_target, x_now=None, node_list=None):\n",
    "        \"\"\"\n",
    "        Update the internal weight by RLS algorithm\n",
    "\n",
    "        Args:\n",
    "            x_target (np.ndarray): State(s) on an inante trajectory.\n",
    "            x_now (np.ndarray, optional): Current state(s). Defaults to None (use self.x).\n",
    "            node_list (list, slice, optional): Tuned nodes. Defaults to None (train all nodes).\n",
    "        \"\"\"\n",
    "        if x_now is None:\n",
    "            x_now = np.asarray(self.x)\n",
    "        if node_list is None:\n",
    "            node_list = range(self.dim)\n",
    "        for xt, xn in zip(x_target.reshape(-1, self.dim), x_now.reshape(-1, self.dim), strict=False):\n",
    "            es = xt[node_list] - xn[node_list]\n",
    "            for node_id, e in zip(node_list, es, strict=False):\n",
    "                x = xn[self.w_pre[node_id]]  # TODO Use self.w_pre (hint: `x = xn[...]`).\n",
    "                P = self.P[node_id]  # TODO Get P matrix for the node (hint: `P = self.P[...]`).\n",
    "                g, k, P_new = rls_update(P, x)  # TODO Use `rls_update`.\n",
    "                dw = g * np.outer(e, k)  # TODO Calculate dw (hint: use `g`, `e`, and `k`).\n",
    "                self.P[node_id] = P_new\n",
    "                self.weight[node_id, self.w_pre[node_id]] += dw[0]\n",
    "        return self.weight\n",
    "\n",
    "    def to_pickle(self, file_name):\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "        P, w_pre = self.P, self.w_pre\n",
    "        self.P, self.w_pre = {}, {}\n",
    "        with open(file_name, mode=\"wb\") as f:\n",
    "            joblib.dump(self, f, compress=True)\n",
    "        self.P, self.w_pre = P, w_pre\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pickle(file_name):\n",
    "        with open(file_name, mode=\"rb\") as f:\n",
    "            module = joblib.load(f)\n",
    "        return module\n",
    "\n",
    "\n",
    "def solution(dim, seed, x_target, x_now, node_list):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    net = InnateESN(dim, seed=seed, node_list=node_list)\n",
    "    net.train(x_target=x_target, x_now=x_now, node_list=node_list)\n",
    "    return net.weight\n",
    "\n",
    "\n",
    "test_func(solution, \"01_01\")\n",
    "# show_solution(\"01_01\", \"InnateESN\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.2.\n",
    "\n",
    "生得的学習の事前学習を実装する `emulate_innate` を実装せよ。\n",
    "ただし $k \\in [t_\\mathrm{b}, t_\\mathrm{e}) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every}) $ のときに `InnateESN.train` によって $W^\\mathrm{rec}$ を更新、それ以外のときは何もしない。\n",
    "\n",
    "- `emulate_innate`\n",
    "  - Argument(s):\n",
    "    - `ts`: `list | np.ndarray`\n",
    "    - `net`: `InnateESN`\n",
    "    - `f_in`: `Callable`\n",
    "      - $f^\\text{in}(t)$\n",
    "    - `innate_range`: `tuple(int, int)`\n",
    "      - $[t_\\mathrm{b}, t_\\mathrm{e})$\n",
    "    - `innate_node`: `list | slice`\n",
    "    - `innate_every`: `int`\n",
    "      - $t_\\mathrm{every}$\n",
    "    - `innate_func`: `Callable`\n",
    "      - $\\hat{x}: T \\to \\mathbb{R}^{\\cdots \\times N}$\n",
    "  - Return(s):\n",
    "    - `record`: `dict`\n",
    "      - `'t'`: `np.ndarray`\n",
    "        - $[t_0, t_1,~\\ldots,~t_{T-1}]$\n",
    "      - `'x'`: `np.ndarray`\n",
    "        - $[x[t_0], x[t_1],~\\ldots,~x[t_{T-1}]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate_innate(\n",
    "    ts,\n",
    "    net,\n",
    "    f_in=None,\n",
    "    innate_range=None,\n",
    "    innate_func=None,\n",
    "    innate_node=None,\n",
    "    innate_every=2,\n",
    "    prefix=\"\",\n",
    "    leave=True,\n",
    "    display=True,\n",
    "):\n",
    "    record = {}\n",
    "    record[\"t\"] = np.zeros(len(ts), dtype=int)\n",
    "    record[\"x\"] = np.zeros((len(ts), *net.x.shape))\n",
    "    pbar = tqdm(ts, leave=leave, display=display)\n",
    "    for cnt, t in enumerate(pbar):\n",
    "        pbar.set_description(\"{}t={:.0f}\".format(prefix, t))\n",
    "        u_in = np.zeros_like(net.x)\n",
    "        if f_in is not None:\n",
    "            u_in += f_in(t)\n",
    "        net.step(u_in)\n",
    "        record[\"t\"][cnt] = t\n",
    "        record[\"x\"][cnt] = net.x\n",
    "        if (innate_range is not None) and (innate_range[0] <= t < innate_range[1]):\n",
    "            if cnt % innate_every == 0:\n",
    "                # TODO Use `net.train` and specify `node_list=innate_node`.\n",
    "                x_target = innate_func(t)\n",
    "                net.train(x_target, node_list=innate_node)\n",
    "                # end of TODO\n",
    "    return record\n",
    "\n",
    "\n",
    "def solution(ts, dim, seed, **kwargs):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    net = InnateESN(dim, seed=seed)\n",
    "    record = emulate_innate(ts, net, **kwargs)\n",
    "    return record[\"x\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"01_02\")\n",
    "# show_solution(\"01_02\", \"emulate_innate\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`emulate_innate` が準備できたら以下のセルを実行してください。\n",
    "\n",
    "- `create_target`: 生得的軌道の生成\n",
    "- `train_network`: 事前学習の実行\n",
    "- `eval_newtork`: 事前学習の評価\n",
    "- `eval_error`: MSEならびにNRMSEの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(record_range, net, f_in, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"sample \")\n",
    "    return record\n",
    "\n",
    "\n",
    "def train_network(record_range, net, f_in, rec_target, innate_range, innate_node, innate_every, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    innate_func = interp1d(rec_target[\"x\"], x=rec_target[\"t\"], kind=1, axis=0)\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
    "    record = emulate_innate(\n",
    "        range(*record_range),\n",
    "        net,\n",
    "        f_in=f_in,\n",
    "        prefix=\"train \",\n",
    "        innate_func=innate_func,\n",
    "        innate_node=innate_node,\n",
    "        innate_range=innate_range,\n",
    "        innate_every=innate_every,\n",
    "    )\n",
    "    return record\n",
    "\n",
    "\n",
    "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
    "    return record\n",
    "\n",
    "\n",
    "def eval_error(rec_eval, rec_target, innate_range, innate_node):\n",
    "    begin_id = int(innate_range[0] - rec_eval[\"t\"][0])\n",
    "    end_id = int(innate_range[1] - rec_eval[\"t\"][0])\n",
    "    diff = rec_eval[\"x\"] - rec_target[\"x\"][:, None]  # -> [Time_steps, Eval_num, w_pulse_num, Net_dim]\n",
    "    norm = (diff[begin_id:end_id, ..., innate_node] ** 2).sum(axis=-1)  # -> [T, E, W]\n",
    "    mse = norm.mean(axis=0)  # -> [E, W]\n",
    "\n",
    "    var = (rec_target[\"x\"][begin_id:end_id, ..., innate_node] ** 2).sum(axis=(0, 2))  # -> [W]\n",
    "    nrmse = (norm.sum(axis=0) / var) ** 0.5  # -> [E, W]\n",
    "    return {\"mse\": mse, \"nrmse\": nrmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 事前学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからデモンストレーションに移ります。\n",
    "まず実験パラメータを指定します。\n",
    "また事前学習に非常に時間がかかるため、出力フォルダ `save_dir` （デフォルトでは`./output`）を作成し、実験条件と結果を保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./result\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "w_pulse_num = 1\n",
    "dim, a, sr, p = 1000, 0.1, 1.6, 0.2\n",
    "pulse_amp, pulse_period = 10.0, 50\n",
    "\n",
    "alpha = 1.0\n",
    "innate_epoch = 20\n",
    "innate_period, innate_rate, innate_every = 3000, 0.1, 4\n",
    "washout_period, record_period = 1000, 5000\n",
    "\n",
    "rnd = np.random.default_rng(seed)\n",
    "net = InnateESN(dim, a=a, sr=sr, p=p, alpha=alpha, rnd=rnd)\n",
    "w_pulse = rnd.uniform(size=(w_pulse_num + 2, dim), low=-1.0, high=1.0)\n",
    "\n",
    "innate_range = [0, innate_period]\n",
    "innate_node = list(range(0, int(innate_rate * net.dim)))\n",
    "record_range = [-washout_period, record_period]\n",
    "pulse_range = [-pulse_period, 0]\n",
    "\n",
    "plot_range = list(range(5))\n",
    "\n",
    "\n",
    "def f_in(t):\n",
    "    if -pulse_period <= t < 0:\n",
    "        return pulse_amp * w_pulse[:w_pulse_num]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "f_in.dim = w_pulse_num\n",
    "\n",
    "with open(f\"{save_dir}/params.json\", mode=\"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"pulse_amp\": pulse_amp,\n",
    "            \"pulse_period\": pulse_period,\n",
    "            \"innate_period\": innate_period,\n",
    "            \"innate_rate\": innate_rate,\n",
    "            \"innate_every\": innate_every,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "np.save(f\"{save_dir}/w_pulse.npy\", w_pulse)\n",
    "net.to_pickle(f\"{save_dir}/net_init.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは生得的軌道 $\\hat{x}[k]$ を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_target = create_target(record_range, net, f_in, rnd=rnd)\n",
    "fig_target = show_innate_record(\n",
    "    rec_target,\n",
    "    plot_range,\n",
    "    lw=1.5,\n",
    "    color=\"k\",\n",
    "    title=\"innate trajectory\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "np.savez_compressed(f\"{save_dir}/rec_target.npz\", *rec_target)\n",
    "fig_target.savefig(f\"{save_dir}/rec_target.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "灰色の領域は、パルス入力が与えられた期間を表します。\n",
    "ピンク色の領域は、事前学習期間 $[t_\\mathrm{b}, t_\\mathrm{e})$ を表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):  # noqa: F811\n",
    "    rnd = rnd if rnd else np.random.default_rng()\n",
    "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
    "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
    "    return record\n",
    "\n",
    "\n",
    "rec_init = eval_network(record_range, net, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_target,\n",
    "    plot_range,\n",
    "    lw=1.5,\n",
    "    ls=\":\",\n",
    "    clear=True,\n",
    "    color=\"k\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "fig = show_innate_record(\n",
    "    rec_init,\n",
    "    plot_range,\n",
    "    lw=0.5,\n",
    "    ls=\"-\",\n",
    "    fig=fig,\n",
    "    cmap=plt.get_cmap(\"tab10\"),\n",
    "    title=\"eval (before pre-training)\",\n",
    ")\n",
    "fig.savefig(f\"{save_dir}/eval/init.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この図より、生得的軌道 (点線) をESNが現時点では再現的に生成できない様子が読み取れます。\n",
    "\n",
    "以下のセルは事前学習を実行します。\n",
    "20〜30分はかかりますので、終了するまでお待ちください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {}\n",
    "best_score = np.array(np.inf)\n",
    "figs = defaultdict(lambda: None)\n",
    "\n",
    "pbar = trange(innate_epoch)\n",
    "out_tqdm, out_figure = Output(), Output()\n",
    "display(out_tqdm)\n",
    "display(out_figure)\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(\"best:{:.2e}\".format(best_score))\n",
    "    with out_tqdm:\n",
    "        clear_output(wait=True)\n",
    "        # Training phase\n",
    "        rec_train = train_network(\n",
    "            record_range,\n",
    "            net,\n",
    "            f_in,\n",
    "            rec_target,\n",
    "            innate_range,\n",
    "            innate_node,\n",
    "            innate_every,\n",
    "            rnd=rnd,\n",
    "        )\n",
    "        figs[\"train\"] = show_innate_record(\n",
    "            rec_target,\n",
    "            plot_range,\n",
    "            lw=1.5,\n",
    "            ls=\":\",\n",
    "            clear=True,\n",
    "            color=\"black\",\n",
    "            fig=figs[\"train\"],\n",
    "            pulse_range=pulse_range,\n",
    "            innate_range=innate_range,\n",
    "        )\n",
    "        figs[\"train\"] = show_innate_record(\n",
    "            rec_train,\n",
    "            plot_range,\n",
    "            lw=1.0,\n",
    "            ls=\"-\",\n",
    "            fig=figs[\"train\"],\n",
    "            cmap=plt.get_cmap(\"tab10\"),\n",
    "            title=f\"train (epoch #{epoch})\",\n",
    "        )\n",
    "        figs[\"train\"].savefig(\"{}/train/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
    "\n",
    "        # Evaluation phase\n",
    "        rec_eval = eval_network(record_range, net, f_in, rnd=rnd)\n",
    "        figs[\"eval\"] = show_innate_record(\n",
    "            rec_target,\n",
    "            plot_range,\n",
    "            lw=1.5,\n",
    "            ls=\":\",\n",
    "            clear=True,\n",
    "            color=\"black\",\n",
    "            fig=figs[\"eval\"],\n",
    "            pulse_range=pulse_range,\n",
    "            innate_range=innate_range,\n",
    "        )\n",
    "        figs[\"eval\"] = show_innate_record(\n",
    "            rec_eval,\n",
    "            plot_range,\n",
    "            lw=0.5,\n",
    "            ls=\"-\",\n",
    "            fig=figs[\"eval\"],\n",
    "            cmap=plt.get_cmap(\"tab10\"),\n",
    "            title=f\"eval (epoch #{epoch})\",\n",
    "        )\n",
    "        figs[\"eval\"].savefig(\"{}/eval/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
    "\n",
    "        # Record evaluation error\n",
    "        rec = eval_error(rec_eval, rec_target, innate_range, innate_node)\n",
    "        best_score = min(best_score, rec[\"nrmse\"].sum())\n",
    "        rec[\"best\"] = best_score\n",
    "\n",
    "        for key, val in rec.items():\n",
    "            if key not in record:\n",
    "                record[key] = np.zeros((innate_epoch, *val.shape))\n",
    "            record[key][epoch] = val\n",
    "\n",
    "    with out_figure:\n",
    "        clear_output(wait=True)\n",
    "        figs[\"nrmse\"] = show_innate_error(record[\"nrmse\"][: epoch + 1], fig=figs[\"nrmse\"])\n",
    "        figs[\"nrmse\"].savefig(f\"{save_dir}/nrmse.png\", dpi=200)\n",
    "        for _name, fig in figs.items():\n",
    "            size = fig.get_size_inches()\n",
    "            fig.set_size_inches(8, 3)\n",
    "            display(fig)\n",
    "            fig.set_size_inches(size)\n",
    "\n",
    "net.to_pickle(f\"{save_dir}/net_term.pkl\")\n",
    "np.savez_compressed(f\"{save_dir}/record.npz\", **record)\n",
    "\n",
    "for _name, fig in figs.items():\n",
    "    fig.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "徐々に、異なる初期値にもかかわらず、複雑な高次元カオスを再現的に生成できる様子が見て取れると思います。\n",
    "`{save_dir}/eval` 内に保存されている図を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.3. (Advanced)\n",
    "\n",
    "- ノード数を変化させ、MSEの違いを観察せよ。\n",
    "- より長い `innate_period` を試し、事前学習の性能を比較せよ。\n",
    "- `w_pulse_num` を増やし、複数の入力に対して事前学習せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 事後学習の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前学習したESNを用いて、リードアウト層を学習しましょう。\n",
    "以下のセルは`{load_dir}/net_term.pkl`に保存されたESNと、`{load_dir}/params.json` に保存されたパラメータファイルを読み込みます。\n",
    "事前学習済みの場合は前のセルをスキップして、ここから開始可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = \"./result\"\n",
    "\n",
    "net_init = InnateESN.read_pickle(f\"{load_dir}/net_init.pkl\")\n",
    "net_term = InnateESN.read_pickle(f\"{load_dir}/net_term.pkl\")\n",
    "w_pulse = np.load(f\"{load_dir}/w_pulse.npy\")\n",
    "with open(f\"{load_dir}/params.json\", mode=\"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "pulse_amp = params[\"pulse_amp\"]\n",
    "pulse_period = params[\"pulse_period\"]\n",
    "innate_period = params[\"innate_period\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルは、事前学習前と後のESNの軌道を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "w_pulse_num = 1\n",
    "washout_period, record_period = 1000, 10000\n",
    "record_range = [-washout_period, record_period]\n",
    "pulse_range = [-pulse_period, 0]\n",
    "innate_range = [0, innate_period]\n",
    "plot_range = list(range(5))\n",
    "\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "def f_in(t):\n",
    "    if -pulse_period <= t < 0:\n",
    "        return pulse_amp * w_pulse[:w_pulse_num]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "f_in.dim = w_pulse_num\n",
    "\n",
    "rec_sample_init = eval_network(record_range, net_init, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_sample_init,\n",
    "    plot_range,\n",
    "    lw=1.0,\n",
    "    title=\"initial\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")\n",
    "\n",
    "rec_sample_term = eval_network(record_range, net_term, f_in, rnd=rnd)\n",
    "fig = show_innate_record(\n",
    "    rec_sample_term,\n",
    "    plot_range,\n",
    "    lw=1.0,\n",
    "    title=\"pre-trained\",\n",
    "    pulse_range=pulse_range,\n",
    "    innate_range=innate_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に目標となるリードアウト層の出力時系列を用意しましょう。\n",
    "`./data/09_internal_optimization`以下には`abc.csv`と`star.csv`が用意されています。\n",
    "今回は`abc.csv`を使用してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./data/09_internal_optimization/abc.csv\", delimiter=\",\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(data[:, 0], data[:, 1])\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前学習したESNは、入力後 $t\\in[0, t_\\mathrm{innate})$ の期間再現的にinnate trajectoryを生成します。\n",
    "これをリードアウト層を用いて線型回帰により対応付けましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, xs = rec_sample_term[\"t\"], rec_sample_term[\"x\"]\n",
    "\n",
    "x_train = xs[washout_period : washout_period + innate_period, :, 0, :]\n",
    "\n",
    "target_func = interp1d(data, kind=1, axis=0)\n",
    "ds = target_func(np.linspace(0, 1, innate_period))\n",
    "ds = np.broadcast_to(ds[:, None, :], (*x_train.shape[:-1], ds.shape[-1]))\n",
    "\n",
    "w_out = RidgeReadout(net_term.dim, 2, lmbd=1e-2)\n",
    "weight, bias = w_out.train(x_train.reshape(-1, x_train.shape[-1]), ds.reshape(-1, ds.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`InteractiveView` は動的に入力を与えられるツールです。\n",
    "以下のセルを実行し、パルス入力後に適切に目標軌道が出力されるか確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import copy\n",
    "\n",
    "try:\n",
    "    del viewer  # type: ignore\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "net_term_cp = copy.deepcopy(net_term)\n",
    "\n",
    "net_term_cp.x = rnd.uniform(-1, 1, net_term_cp.dim)\n",
    "viewer = InteractiveViewer(\n",
    "    net_term_cp,\n",
    "    w_out,\n",
    "    w_pulse,\n",
    "    pulse_amp,\n",
    "    pulse_period,\n",
    "    plot_num=5,\n",
    "    input_num=w_pulse_num,\n",
    "    max_time_steps=10000,\n",
    "    cmap=\"Greens\",\n",
    ")\n",
    "\n",
    "viewer.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.1. (Advanced)\n",
    "\n",
    "- `InteractiveView` の引数 `input_num` の数を増やすと入力の種類を増やせる。\n",
    "ただ現時点では学習されていないため、意味のない出力しか得られない。\n",
    "入力の数を2に増やし（`w_pulse_num=2`）、別の入力に対しては「星」（`star.csv`）を出力するように事前学習と事後学習を行え (僅かな変更で実装できる) 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.2. (Advanced)\n",
    "\n",
    "- Innate trainingとほとんどコードを改変せずにFull FORCEを実装できる。[2]を参考に、`InnateESN`を継承した`FullFORCEESN`を実装せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Laje, R., & Buonomano, D. V. (2013). *Robust timing and motor patterns by taming chaos in recurrent neural networks*. Nature Neuroscience, 16(7), 925–933. https://doi.org/10.1038/nn.3405\n",
    "\n",
    "[2] DePasquale, B., Cueva, C. J., Rajan, K., Escola, G. S., & Abbott, L. F. (2018). *full-FORCE: A target-based method for training recurrent networks*. PLOS ONE, 13(2), e0191527. https://doi.org/10.1371/journal.pone.0191527\n",
    "\n",
    "[3] Sussillo, D., & Abbott, L. F. (2009). *Generating Coherent Patterns of Activity from Chaotic Neural Networks*. Neuron, 63(4), 544–557. https://doi.org/10.1016/j.neuron.2009.07.018\n",
    "\n",
    "[4] Inoue, K., Nakajima, K., & Kuniyoshi, Y. (2020). *Designing spontaneous behavioral switching via chaotic itinerancy*. Science Advances, 6(46), eabb3989. https://doi.org/10.1126/sciadv.abb3989"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc-bootcamp (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
