{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. ESNの最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章では、ESNや学習セットアップに登場するパラメータやハイパーパラメータの調整方法を学び、その計算能力を最大限に引き出す手法を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前書き"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回説明したESNでNARMA10を解くセットアップとそのパラメータを整理しましょう。\n",
    "一様乱数からサンプルされた入力 $u[k]\\sim\\mathcal{U}([-1, 1])$ をESNに線形変換で投射し、ESNの状態 $x[k]$ からNARMA10時系列 $y[k]$ を構成するタスクを考えます。\n",
    "この際、以下のパラメータが登場します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $v[k]=\\sigma u[k] + \\phi$\n",
    "  - $\\sigma \\in \\mathbb{R}$ : 入力スケール\n",
    "  - $\\phi \\in \\mathbb{R}$ : バイアス\n",
    "- $x[k+1] = (1-a)~x[k]+a~\\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} v[k+1]\\right)$\n",
    "  - $N \\in \\mathbb{Z}^+$ : ESNのノード数\n",
    "  - $\\rho \\in \\mathbb{R}^+$ : スペクトル半径\n",
    "  - $a \\in \\mathbb{R}^+$ : 漏れ率 (leaky rate)\n",
    "  - $x[0]$ : ESNの初期値\n",
    "- $y[k+1] = \\mathrm{NARMA10}(\\nu[k],\\nu[k-9],~y[k],~\\ldots,~y[k-9];\\alpha,\\beta,\\gamma,\\delta),~\\nu[k] = \\mu u[k] + \\kappa$\n",
    "  - $\\alpha,\\beta,\\gamma,\\delta \\in \\mathbb{R}$ : 関数パラメータ\n",
    "  - $\\mu,\\kappa\\in \\mathbb{R}$ : スケーリングパラメータ\n",
    "- その他\n",
    "  - $T_\\mathrm{washout}\\in\\mathbb{Z}^+$ : ウォッシュアウトの時間ステップ\n",
    "  - $T_\\mathrm{train}\\in\\mathbb{Z}^+$ : 学習用データの時間ステップ\n",
    "  - $T_\\mathrm{eval}\\in\\mathbb{Z}^+$ : 評価用データの時間ステップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今フェアな比較のため、ターゲットとなるNARMA10のパラメータを典型的なもの $(\\alpha,\\beta,\\gamma,\\delta,\\mu,\\kappa)=(0.3,0.05,1.5,0.1,0.25,0.25)$ に固定し、 $u[k]$ とそれに対応するNARMA10の時系列 $y[k]$ は同じものを使います。\n",
    "ここでは残りのうち重要なパラメータである、入力スケーリング $(\\sigma, \\phi)$ 、ESNパラメータ $(N,\\rho,a)$ 、そして学習データの長さ $T_\\mathrm{train}$ をそれぞれ個別に、もしくはまとめて最適化してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題と実演"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからは演習問題とデモンストレーションに移ります。\n",
    "前回と同じライブラリの他、前回の演習で実装した`ESN`・`Linear`・`narma_func`が`import`により利用できます。\n",
    "初めに次のセルを実行してください。\n",
    "\n",
    "なお`ESN`・`Linear`・`narma_func`の内部実装を再確認するには、`import inspect`以下の行をコメントアウトするか`...?? / ??...`を使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    if False:  # Set to True if you want to use Google Drive and save your work there.\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "        %cd /content/gdrive/My Drive/rc-bootcamp/\n",
    "        # NOTE: Change it to your own path if you put the zip file elsewhere.\n",
    "        # e.g., %cd /content/gdrive/My Drive/[PATH_TO_EXTRACT]/rc-bootcamp/\n",
    "    else:\n",
    "        pass\n",
    "        %cd /content/\n",
    "        !git clone --branch ja https://github.com/rc-bootcamp/rc-bootcamp.git\n",
    "        %cd /content/rc-bootcamp/\n",
    "else:\n",
    "    sys.path.append(\".\")\n",
    "\n",
    "from utils.reservoir import ESN, Linear\n",
    "from utils.style_config import Figure, plt\n",
    "from utils.task import narma_func\n",
    "from utils.tester import load_from_chapter_name\n",
    "from utils.tqdm import tqdm, trange\n",
    "\n",
    "test_func, show_solution = load_from_chapter_name(\"04_esn_fine_tuning\")\n",
    "\n",
    "# Uncomment it to see the implementations of `Linear` and `ESN`.\n",
    "# import inspect\n",
    "# print(inspect.getsource(Linear))\n",
    "# print(inspect.getsource(ESN))\n",
    "# print(inspect.getsource(narma_func))\n",
    "\n",
    "# Or just use ??.../...?? (uncomment the following lines).\n",
    "# Linear??\n",
    "# ESN??\n",
    "# narma_func??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 前準備とバッチ処理への拡張"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからは類似する大量データセットに対して類似の操作を繰り返します。\n",
    "その前準備として、前回実装した`LRReadout`と`calc_nrmse`を改造し、複数のデータセットに対してまとめて線型回帰とNRMSEの計算が可能になった`BatchLRReadout`と`calc_batch_nrmse`を実装しましょう。\n",
    "なおこのような一括処理はバッチ処理 (batch processing)と呼ばれ、NumPyではコツさえつかめば比較的容易に実装できます。\n",
    "また前章で扱われたように、NumPy内部の並列演算によりfor loopを回すよりも効率的な演算が期待できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.1.\n",
    "\n",
    "前回学んだとおり、1列目にバイアス項を加えた予測変数 $\\tilde{X}=[1 : X]\\in\\mathbb{R}^{T\\times (N+1)}$ と予測対象変数 $Y\\in \\mathbb{R}^{T \\times D}$ に対して、 $\\|Xw - Y\\|^2$ を最小化する $\\hat{w}\\in\\mathbb{R}^{(N+1)\\times D}$ は下記式により求められる。\n",
    "\n",
    "$$\n",
    "\\renewcommand{\\Rho}{\\mathrm{P}}\n",
    "\\begin{align*}\n",
    "\\hat{w} &= (\\tilde{X}^\\top \\tilde{X})^{-1}{\\tilde{X}}^\\top Y \\\\\n",
    "&=\\tilde{X}^+ Y\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "しかし[`np.linalg.lstsq`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html)の仕様上、前回実装した`LRReadout`では引数に多次元配列 $\\tilde{X}\\in\\mathbb{R}^{... \\times T \\times (N+1)},~Y\\in \\mathbb{R}^{... \\times T \\times D}$ を与えて、まとめて $\\hat{w}^\\mathrm{out} \\in \\mathbb{R}^{...\\times (N+1) \\times D}$ を得る操作は実現できない。\n",
    "[`np.linalg.pinv`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html)では多次元配列 $A\\in\\mathbb{R}^{...\\times M \\times N}$ の入力が許容され、その返り値として疑似逆行列 $A^+\\in\\mathbb{R}^{...\\times N \\times M}$ が得られる。\n",
    "上記の式と前章の回答を参考にしながら以下の穴埋めを実装し、線型回帰のバッチ処理が可能になった`BatchLRReadout`を完成させよ。\n",
    "\n",
    "- `BatchLRReadout.train`\n",
    "  - Argument(s):\n",
    "    - `x`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, input_dim)`\n",
    "    - `y`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, output_dim)`\n",
    "  - Return(s):\n",
    "    - `self.weight`: `np.ndarray`\n",
    "      - `shape`: `(..., output_dim, input_dim)`\n",
    "    - `self.bias`: `np.ndarray`\n",
    "      - `shape`: `(..., 1, output_dim)`\n",
    "\n",
    "  - Operation(s):\n",
    "      - `self.weight`の更新\n",
    "      - `self.bias`の更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLRReadout(Linear):\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        assert (x.ndim > 1) and (x.shape[-1] == self.input_dim)\n",
    "        assert (y.ndim > 1) and (y.shape[-1] == self.output_dim)\n",
    "        x_biased = np.ones((*x.shape[:-1], x.shape[-1] + 1), dtype=self.dtype)\n",
    "        x_biased[..., 1:] = x\n",
    "        # TODO\n",
    "        sol = ...\n",
    "        self.weight = ...\n",
    "        self.bias = ...\n",
    "        # end of TODO\n",
    "        return self.weight, self.bias\n",
    "\n",
    "\n",
    "def solution(dim_in, dim_out, x_train, y_train, x_eval):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    readout = BatchLRReadout(dim_in, dim_out)\n",
    "    readout.train(x_train, y_train)\n",
    "    return readout(x_eval)\n",
    "\n",
    "\n",
    "test_func(solution, \"01_01\")\n",
    "# show_solution(\"01_01\", \"BatchLRReadout\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.2.\n",
    "\n",
    "同様に長さ $T$ の多次元配列 $Y, \\hat{Y}\\in\\mathbb{R}^{...\\times T \\times d}$ に対してNRMSEをまとめて計算できる`calc_batch_nrmse`を実装せよ。\n",
    "ただしNRMSEは以下の式より与えられる。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{NRMSE}(y, \\hat{y}) :&= \\dfrac{\\mathrm{RMSE}(y, \\hat{y})}{\\sigma(y)} \\\\\n",
    "\\mathrm{RMSE}(y, \\hat{y}) :&=  \\sqrt{\\dfrac{\\mathrm{RSS}(y, \\hat{y}) }{T} }\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "- `calc_batch_nrmse`\n",
    "  - Argument(s):\n",
    "    - `y`: `np.ndarray`\n",
    "      - `shape`: `(..., t, d)`\n",
    "    - `yhat`: `np.ndarray`\n",
    "      - `shape`: `(..., t, d)`\n",
    "  - Return(s):\n",
    "    - `nrmse`: `np.ndarray`\n",
    "      - `shape`: `(..., d)`\n",
    "\n",
    "<details><summary>tips</summary>\n\n",
    "- [`np.mean`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)\n",
    "- [`np.var`](https://numpy.org/doc/stable/reference/generated/numpy.var.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_batch_nrmse(y, yhat):\n",
    "    # TODO\n",
    "    ...\n",
    "\n",
    "\n",
    "test_func(calc_batch_nrmse, \"01_02\")\n",
    "# show_solution(\"01_02\", \"calc_batch_nrmse\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.3.\n",
    "\n",
    "$x[k] \\in \\mathbb{R}^{... T_\\mathrm{train}\\times N} $に対して、サンプリングならびに線形回帰をまとめて実行しNRMSEを計算する`train_and_eval`を完成させよ。\n",
    "ただし前章最後に記載した下記のコードを参考にせよ。\n",
    "\n",
    "```python\n",
    "x = x_init\n",
    "xs = np.zeros((t_total, dim_esn))\n",
    "for idx in range(t_total):\n",
    "    x = net(x, w_in(us[idx]))\n",
    "    xs[idx] = x\n",
    "x_train, y_train = xs[t_washout:-t_eval], ys[t_washout:-t_eval]\n",
    "x_eval, y_eval = xs[-t_eval:], ys[-t_eval:]\n",
    "w_out.train(x_train, y_train)\n",
    "```\n",
    "\n",
    "- `train_and_eval`\n",
    "  - Argument(s):\n",
    "    - `x0`: `np.ndarray`\n",
    "      - `shape`: `(..., n)`\n",
    "    - `ys`: `np.ndarray`\n",
    "      - `shape`: `(...., t_washout + t_train + t_eval, d)`\n",
    "  - Return(s):\n",
    "    - `nrmse`: `np.ndarray`\n",
    "      - `shape`: `(..., d)`\n",
    "    - `xs`: `np.ndarray`\n",
    "      - `shape`: `(..., t_washout + t_train + t_eval, n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_setup(seed, dim, rho, a=None, f=np.tanh, bound=1.0, bias=0.0, cls=BatchLRReadout):\n",
    "    rnd = np.random.default_rng(seed)\n",
    "    w_in = Linear(1, dim, bound=bound, bias=bias, rnd=rnd)\n",
    "    net = ESN(dim, sr=rho, f=f, a=a, rnd=rnd)\n",
    "    w_out = cls(dim, 1)\n",
    "    return w_in, net, w_out\n",
    "\n",
    "\n",
    "def sample_dataset(\n",
    "    seed,\n",
    "    t_washout=1000,\n",
    "    t_train=2000,\n",
    "    t_eval=1000,\n",
    "    narma_parameters=None,\n",
    "):\n",
    "    narma_parameters = (\n",
    "        narma_parameters\n",
    "        if narma_parameters is not None\n",
    "        else dict(alpha=0.3, beta=0.05, gamma=1.5, delta=0.1, mu=0.25, kappa=0.25)\n",
    "    )\n",
    "    rnd = np.random.default_rng(seed)\n",
    "    t_total = t_washout + t_train + t_eval\n",
    "    ts = np.arange(-t_washout, t_train + t_eval)\n",
    "    us = rnd.uniform(-1, 1, (t_total, 1))\n",
    "    ys = narma_func(us, np.zeros((10, 1)), **narma_parameters)\n",
    "    time_info = dict(t_washout=t_washout, t_train=t_train, t_eval=t_eval)\n",
    "    return ts, us, ys, time_info\n",
    "\n",
    "\n",
    "def sample_dynamics(x0, w_in, net, ts, vs, display=False):\n",
    "    assert vs.shape[-2] == ts.shape[0]\n",
    "    x = x0\n",
    "    xs = np.zeros((*x.shape[:-1], ts.shape[0], x.shape[-1]))\n",
    "    for idx in trange(ts.shape[0], display=display):\n",
    "        x = ...  # TODO Iterate over `ts` to sample the dynamics.\n",
    "        xs[..., idx, :] = ...  # TODO Store the state `x` at each time step.\n",
    "    return xs\n",
    "\n",
    "\n",
    "def eval_nrmse(xs, ys, w_out, time_info, return_out=False, **kwargs):\n",
    "    t_washout, t_eval = time_info[\"t_washout\"], time_info[\"t_eval\"]\n",
    "    x_train, y_train = ...  # TODO Specify training range.\n",
    "    x_eval, y_eval = ...  # TODO Specify evaluation range.\n",
    "    out = w_out.train(x_train, y_train, **kwargs)\n",
    "    y_out = w_out(x_eval)\n",
    "    nrmse = calc_batch_nrmse(y_eval, y_out)\n",
    "    if return_out:\n",
    "        return nrmse, *out\n",
    "    else:\n",
    "        return nrmse\n",
    "\n",
    "\n",
    "def train_and_eval(x0, w_in, net, w_out, ts, vs, ys, time_info, display=False):\n",
    "    assert vs.shape[-2] == ts.shape[0]\n",
    "    assert ys.shape[-2] == ts.shape[0]\n",
    "    xs = sample_dynamics(x0, w_in, net, ts, vs, display=display)\n",
    "    nrmse = eval_nrmse(xs, ys, w_out, time_info)\n",
    "    return nrmse, xs\n",
    "\n",
    "\n",
    "test_func(train_and_eval, \"01_03\", multiple_output=True)\n",
    "# show_solution(\"01_03\", \"sample_dynamics\")  # Uncomment it to see the solution.\n",
    "# show_solution(\"01_03\", \"eval_nrmse\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 入力スケーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力スケーリングのパラメータ $(\\sigma, \\phi)$ の効果を確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずこれらのパラメータの機能的意義を説明します。\n",
    "前述のとおり今 $(\\sigma, \\phi)$ を用いて入力 $u[k]$ を以下のように変換します。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "v[k]= \\sigma u[k] + \\phi\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "$u[k]\\sim\\mathcal{U}([-1, 1])$ なので $v[k]\\sim\\mathcal{U}([-\\sigma + \\phi, \\sigma + \\phi])$ となります。\n",
    "分布の範囲より、 $\\sigma$ は入力の分散、 $\\phi$ は平均を調整します (分散 $\\mathrm{Var}[v]=\\frac{1}{3}\\sigma^2$ 、平均 $\\mathrm{E}[v]=\\phi$) 。\n",
    "これらの効果は活性化関数の「形状」との関連で議論できます。\n",
    "例えば図1に示されるとおり、 $\\tanh$ は奇関数 (すなわち $\\tanh\\left(-y\\right)=-\\tanh\\left(y\\right)$ )です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; width: 750px; margin: auto; background-color: #f8f9fa; padding: 10px; border-radius: 10px;\">\n",
    "\n",
    "<img src=\"data:image/webp;base64,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\" alt=\"fig_4_1.webp\">",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figcaption align = \"center\">\n",
    "\n",
    "図1 $f(x)=\\tanh(x)$ とその導関数 $\\dfrac{df}{dx}(x)=1-\\tanh^2(x)$ の形状。\n",
    "\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方で $v[k]$ を展開すると $x[k]$ の時間発展は以下のとおり表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] = \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + \\sigma W^\\mathrm{in} u[k+1] + \\phi W^\\mathrm{in}\\right)\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず $\\phi=0$ に固定して $\\sigma$ の特性を考察します。\n",
    "式と図からわかるとおり $\\sigma$ が大きいほど $\\tanh$ の「平ら」な範囲に定義域がおよびます。\n",
    "一方で $\\sigma$ が小さいほど $y=x$ に $\\tanh$ が近似できる領域に収まります。\n",
    "このように $\\sigma$ はESNの非線形性に大きな影響を与えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に $\\phi$ の効果を確認しましょう。\n",
    "$\\phi$ は、後の情報処理能力 (Information Processing Capacity; IPC)の章でより詳細に説明されますが、変換に含まれる成分の次数に影響をあたえます。\n",
    "今入力が対称 (平均0) であるので、 $x[k]$ を $\\{ u[k],~u[k-1].~\\ldots\\}$ を用いて多項式展開すると、$\\phi=0$のケースでは、奇数次数の要素 ( $u^3[\\cdot], u^5[\\cdot], u[\\cdot]u^2[\\cdot]$ 等) のみ登場します。\n",
    "対照的に$\\phi\\neq 0$の場合、0平均でなくなるので、その要素に偶数次数 ( $u^2[\\cdot], u^4[\\cdot]$ 等)の要素も加わります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの関数の次数の分布はタスク性能に大きな影響を及ぼします。\n",
    "例えば今回使うパラメータセットにおけるNARMA10タスクは、解析によりそのほとんどが以下に記される成分で占められると判明しています<sup>[1]</sup>。\n",
    "- 1次: $u[k-1],~u[k-2],~u[k-3],~u[k-10],~u[k-11],~u[k-12]$\n",
    "- 2次: $u[k-1]u[k-10],~u[k-2]u[k-11],~u[k-3]u[k-12]$\n",
    "\n",
    "したがって$\\phi=0$と$\\phi\\neq0$のケースで性能に大きな差が生じます。\n",
    "以下の演習問題においてここまで確認した$(\\sigma, \\phi)$の影響を確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.1.\n",
    "\n",
    "長さ $k$ の配列としてパラメータ $\\Sigma = (\\sigma_0$, $\\sigma_1,~\\ldots,~\\sigma_{k-1})$ ならびに $\\Phi = (\\phi_0$, $\\phi_1,~\\ldots,~\\phi_{k-1})$ が与えられる。\n",
    "各 $(\\sigma_i, \\phi_i)$ に対するNRMSEをまとめて評価するための $v_i[k] = \\sigma_i u[k] + \\phi_i$ を出力する関数`convert_us_into_vs`を完成させよ。\n",
    "ただし与えられる`us`として与えられる $U=\\{u[0],~\\ldots,~u[k-1]\\} \\in \\mathbb{R}^{T \\times 1}$ の`shape` に留意せよ。\n",
    "\n",
    "- `convert_us_into_vs`\n",
    "  - Argument(s):\n",
    "    - `us`: `np.ndarray`\n",
    "      - `shape`: `(t, 1)`\n",
    "    - `sigma`: `np.ndarray`\n",
    "      - `shape`: `(k,)`\n",
    "    - `phi`: `np.ndarray`\n",
    "      - `shape`: `(k,)`\n",
    "  - Return(s):\n",
    "    - `vs`: `np.ndarray`\n",
    "      - `shape`: `(k, t, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_us_into_vs(us, sigma, phi):\n",
    "    assert len(sigma) == len(phi)\n",
    "    vs = ...  # TODO Use broadcasting to convert `us` into `vs`.\n",
    "    return vs\n",
    "\n",
    "\n",
    "test_func(convert_us_into_vs, \"02_01\")\n",
    "# show_solution(\"02_01\", \"convert_us_into_vs\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装した`convert_us_into_vs`を用いて入力が対称なケース ( $v[k]\\sim \\mathcal{U}([-\\sigma, \\sigma])$ ) と非対称なケース ( $v[k]\\sim \\mathcal{U}([0, \\sigma])$ )で比較してみましょう。\n",
    "$\\sigma$ が小さいケースで非対称なケースが精度の面で対称入力を上回っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678  # you can freely change here\n",
    "dim, rho = 100, 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "\n",
    "w_in, net, w_out = create_setup(seed_setup, dim, rho, f=np.tanh)\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "\n",
    "\n",
    "sigmas = np.logspace(-2, 0, 21)  # 10^{-2.0}, 10^{-1.9}, ... 10^{0.0}\n",
    "x0 = np.zeros((sigmas.shape[0], net.dim))\n",
    "\n",
    "# Symmetrical case (phi=0).\n",
    "vs_sym = convert_us_into_vs(us, sigmas, np.zeros_like(sigmas))\n",
    "nrmse_sym, _xs_sym = train_and_eval(x0, w_in, net, w_out, ts, vs_sym, ys, time_info)\n",
    "best_sym = np.argmin(nrmse_sym[:, 0])\n",
    "\n",
    "# Asymmetrical case (phi=sigma).\n",
    "vs_asym = convert_us_into_vs(us, 0.5 * sigmas, 0.5 * sigmas)\n",
    "nrmse_asym, _xs_asym = train_and_eval(x0, w_in, net, w_out, ts, vs_asym, ys, time_info)\n",
    "best_asym = np.argmin(nrmse_asym[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.plot(sigmas, nrmse_sym[:, 0], label=r\"sym: $[-\\sigma, \\sigma]$\")\n",
    "ax.plot(sigmas, nrmse_asym[:, 0], label=r\"asym: $[0, \\sigma]$\")\n",
    "ax.scatter(sigmas[best_sym], nrmse_sym[best_sym, 0], s=100.0, marker=\"*\")\n",
    "ax.scatter(sigmas[best_asym], nrmse_asym[best_asym, 0], s=100.0, marker=\"*\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(r\"$\\sigma$\")\n",
    "ax.set_ylabel(r\"NRMSE (best: $\\bigstar$)\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.2. (Advanced)\n",
    "\n",
    "- 他の非線形関数に関しても試してみよ。特に $f$ を偶関数にするとどうなるか実験し、結果を考察せよ。\n",
    "- $\\sigma$ が大きくなると急激に精度が悪化する。$x[k]$ の時系列を描画しながら比較し、その理由を考察せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ESNパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にESN内のパラメータ $(N, \\rho, a)$ の役割を確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESNのノード数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず一般的にリザバーの性能は次元数 $N$ が大きいほど高くなります。\n",
    "これは、後のIPCの章で議論されますが、IPCの上限がリザバーの次元数 $N$ によって決定されるからです。\n",
    "また$N$の大きさは**高次元性**と呼ばれリザバーの性能を決定づける重要な特性といえます。\n",
    "\n",
    "次のセルは $N$ を変化させたときの NRMSEの変化を描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "dims = [10, 20, 50, 100, 200, 500, 1000]\n",
    "rho = 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "\n",
    "w_in, net, w_out = create_setup(seed_setup, dim, rho, f=np.tanh)\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = 0.05 * us + 0.05  # vs \\in [0.0, 0.1]\n",
    "\n",
    "nrmses = []\n",
    "for dim in tqdm(dims):\n",
    "    x0 = np.zeros(dim)\n",
    "    w_in, net, w_out = create_setup(seed_setup, dim, rho, f=np.tanh)\n",
    "    nrmse = train_and_eval(x0, w_in, net, w_out, ts, vs, ys, time_info)\n",
    "    nrmses.append(nrmse[0])\n",
    "nrmses = np.asarray(nrmses)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.plot(dims, nrmses, marker=\".\", markersize=10.0)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"# of ESN nodes\")\n",
    "ax.set_ylabel(\"NRMSE\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "より厳密にはリザバーが有するIPCの上限は 階数 $r (\\leq N)$ によって決定されます。\n",
    "これは線形独立な状態時系列の数を表し、一般的に $X$ (定数成分を除外しない場合) または分散共分散行列$C(X):=\\mathrm{E}[(X-\\mathrm{E}[X])^\\top (X-\\mathrm{E}[X])]$ (定数成分を除外する場合) の階数 から計算されます。\n",
    "例えば、以下の次元数 $N=3$ の状態行列 $X=[{x}_0; {x}_1; {x}_2]^{}\\in\\mathbb{R}^{T\\times 3}$を考えます。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{x}_0 &= [u[0],~u[1],~\\ldots,~u[T-1]]^\\top, \\\\\n",
    "{x}_1 &= [u^2[0],~u^2[1],~\\ldots,~u^2[T-1]]^\\top, \\\\\n",
    "{x}_2 &= [3u^2[0]-4u[0],~3u^2[1]-4u[1],~\\ldots,~3u^2[T-1]-4u[T-1]] ^\\top\n",
    ".\\end{align}\n",
    "$$\n",
    "\n",
    "$x_2=3x_1 - 4x_0$ より $x_2$ は線形従属で $X$ の階数は $2$となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "In [*]: rnd = np.random.default_rng(1234)\n",
    "   ...: us = rnd.uniform(-1, 1, (100, 1))\n",
    "   ...: xs = np.concatenate([us, us**2, 3 * us**2 - 4 * us], axis=1)\n",
    "   ...: xs_m = xs - xs.mean(axis=0)\n",
    "   ...: print('rank: {}'.format(np.linalg.matrix_rank(xs_m.T @ xs_m)))\n",
    "rank: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線型回帰とその出力 $\\hat{Y}$ は、$X$ によって張られる部分空間に対する $Y$ の射影として解釈され、射影行列 $P_X=X X^+$を用いて $\\hat{Y}=P_X Y$と表されます。\n",
    "そしてその部分空間の次元は $X$ の階数 $r$ によって規定されます。\n",
    "上記の例では線形従属な成分 $x_2$ は部分空間の次元を増やさず、したがって残差誤差 $\\|P_X Y - Y \\|^2$ の低減には寄与しません。\n",
    "IPC的な意味では、$x_2$はIPCの増加に寄与しない余分な成分といえます。\n",
    "このように階数 $r$ は冗長な成分を定量的に評価する重要な指標で、RCの文脈で頻繁に登場します。\n",
    "\n",
    "階数が最大でないケースは、活性化関数に恒等写像を採用した線形ESNの場合に簡単に構成できます。\n",
    "以下は線形ESNと $\\tanh$ を活性化関数に有する非線形ESNの階数を比較するコードです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dims = np.arange(1, 11) * 10\n",
    "rho = 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=0)\n",
    "\n",
    "ts, us, _ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = sigma * us + phi\n",
    "\n",
    "rank_nlin, rank_lin = [], []\n",
    "for dim in tqdm(dims):\n",
    "    x0 = np.zeros(dim)\n",
    "    t_washout = dataset_info[\"t_washout\"]\n",
    "    w_in, net, _w_out = create_setup(seed_setup, dim, rho, f=np.tanh)\n",
    "    # Non-linear case\n",
    "    xs_nlin = sample_dynamics(x0, w_in, net, ts, vs)[t_washout:]\n",
    "    xs_nlin -= xs_nlin.mean(axis=0)\n",
    "    rank_nlin.append(np.linalg.matrix_rank(xs_nlin.T @ xs_nlin))\n",
    "    # Linear case\n",
    "    net.f = lambda val: val  # Identity function\n",
    "    xs_lin = sample_dynamics(x0, w_in, net, ts, vs)[t_washout:]\n",
    "    xs_lin -= xs_lin.mean(axis=0)\n",
    "    rank_lin.append(np.linalg.matrix_rank(xs_lin.T @ xs_lin))\n",
    "rank_nlin = np.asarray(rank_nlin)\n",
    "rank_lin = np.asarray(rank_lin)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.plot(dims, dims, color=\"k\", label=r\"$r=N$\")\n",
    "ax.plot(dims, rank_nlin, marker=\".\", markersize=10.0, color=\"red\", ls=\":\", label=r\"$f=\\tanh$\")\n",
    "ax.plot(\n",
    "    dims,\n",
    "    rank_lin,\n",
    "    marker=\".\",\n",
    "    markersize=10.0,\n",
    "    color=\"blue\",\n",
    "    ls=\"--\",\n",
    "    label=r\"$f=\\mathrm{id}_\\mathbb{R}$\",\n",
    ")\n",
    "ax.set_xlabel(\"# of ESN nodes\")\n",
    "ax.set_ylabel(r\"rank $r$\")\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.1. (Advanced)\n",
    "\n",
    "- 線形なケースだと$N$が大きい時に上の例に示されるように階数が最大にならない。この原因を直感的に理解するため、各$N$に対して分散共分散行列 $C(X)$ の固有値 $\\{\\lambda_i \\}_{i=0}^{N-1}$ の絶対値 $|\\lambda_{i}|$ を昇順に並べ対数グラフで描画し、線形ESNと非線形ESNを比較せよ。\n",
    "- 固有値の絶対値の分布を基に考察し、線形ESNでも階数を最大にするための$W^\\mathrm{rec}$の上手い初期化の戦略を考察せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スペクトル半径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にスペクトル半径 $\\rho$ の影響を調査します。\n",
    "前章で扱ったように、スペクトル半径 $\\rho$ は $W^\\mathrm{rec}$ の固有値 $\\{\\lambda_i \\}_{i=0}^{N-1}$ のうち最大の絶対値として以下の式を用いて定義されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\rho(W^\\mathrm{rec}):=\\max_{i} |\\lambda_{i}|\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "スペクトル「半径」と呼ばれる理由は、前回紹介されたとおり、固有値を複素平面上に並べると視覚的に理解できます。\n",
    "特に正規分布 $\\mathcal{N}\\left(0, \\frac{1}{N}\\right)$ より $W^\\mathrm{rec} \\in \\mathbb{R}^{N\\times N}$ の各要素をサンプリングする場合、その固有値は半径1の単円板上におおよそ一様分布する点が知られています (より厳密には複素平面上で半径1の単位円板上の一様測度に $N\\to \\infty$ でほとんど確実に分布収束)。\n",
    "またこれは[円則](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E8%A1%8C%E5%88%97#%E5%86%86%E5%89%87)として知られるランダム行列の重要な特性です。\n",
    "\n",
    "`ESN`では、`normalize=True`によってスペクトル半径 $\\rho$ を分離しハイパーパラメータとして扱えます。\n",
    "まずは様々な $\\rho$ に対して一度に $x[t]$ のサンプリングを可能にする`reshape_rho`を以下の設問で実装しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.2.\n",
    "\n",
    "長さ$k$ の配列としてスペクトル半径 $\\Rho = \\left(\\rho_0, \\rho_1,~\\ldots,~\\rho_{k-1} \\right)$ が与えられる。\n",
    "同じ入力 $u[k]$ と $W^\\mathrm{rec}$ に対してスペクトル半径のみを $\\rho_{i}$ に変えたときの $x_{i}[k]$ をまとめてサンプリングできるように、`reshape_rho`を完成させよ。\n",
    "\n",
    "- `reshape_rho`\n",
    "  - Argument(s):\n",
    "    - `rho`: `np.ndarray`\n",
    "      - `shape`: `(k,)`\n",
    "  - Return(s):\n",
    "    - `rho_new`: `np.ndarray`\n",
    "      - `shape`: `(k, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_rho(rho):\n",
    "    rho_new = ...  # TODO\n",
    "    return rho_new\n",
    "\n",
    "\n",
    "test_func(reshape_rho, \"03_02\")\n",
    "# show_solution(\"03_02\", \"reshape_rho\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スペクトル半径 $\\rho$ の効果を直感的に理解するため、$u[k]=0, f=\\mathrm{id}_\\mathbb{R}$ の無入力線形ESNのケースを考えます。\n",
    "この際、ESNの時間発展は以下の式で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[t+1] = \\rho W^\\mathrm{rec} x[t]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この際、$x[k]$の解析解は以下の式で表されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k] = \\rho^k \\left({W^\\mathrm{rec}}\\right)^k x[0]\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W^\\mathrm{rec}$ は正規化されているため、$\\left({W^\\mathrm{rec}}\\right)^k$ はそのものは発散しません。\n",
    "一方で $\\rho^k$ は $\\rho > 1$ の時無限大に発散、$\\rho < 1$ の時収束します。\n",
    "以下のセルは $\\rho$ の違いが与える $x[k]$ の応答を図示化します (比較のために $\\tanh$ を活性化関数に有する非線形ESNのケースを右側に描画しています)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "dim, rhos = 50, np.array([0.99, 1.0, 1.01])\n",
    "dataset_info = dict(t_washout=300, t_train=0, t_eval=0)\n",
    "\n",
    "w_in, net, _w_out = create_setup(seed_setup, dim, reshape_rho(rhos))  # Use `reshape_rho`.\n",
    "ts, us, _ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = np.zeros_like(us)  # Zero input\n",
    "x0 = net.rnd.uniform(low=-0.5, high=0.5, size=(1, dim))\n",
    "x0 = np.broadcast_to(x0, (len(rhos), dim))  # Using the same initial conditions\n",
    "\n",
    "xs_nlin = sample_dynamics(x0, w_in, net, ts, vs)\n",
    "net.f = lambda val: val  # Identity function\n",
    "xs_lin = sample_dynamics(x0, w_in, net, ts, vs)\n",
    "\n",
    "fig, ax = plt.subplots(len(rhos), 2, figsize=(12, 10), gridspec_kw=dict(hspace=0.05, wspace=0.2))\n",
    "for idx, rho in enumerate(rhos):\n",
    "    ax[idx, 0].set_ylabel(r\"$\\rho = {:.2f}$\".format(rho))\n",
    "    for idy, xs in enumerate([xs_lin, xs_nlin]):\n",
    "        ax[idx, idy].plot(xs[idx], lw=1.0)\n",
    "        ax[idx, idy].axhline(1.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "        ax[idx, idy].axhline(-1.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "        ax[idx, idy].set_yticks([-1.0, 1.0])\n",
    "        if idx < len(rhos) - 1:\n",
    "            ax[idx, idy].set_xticklabels([])\n",
    "ax[-1, 0].set_xlabel(\"time steps\")\n",
    "ax[-1, 1].set_xlabel(\"time steps\")\n",
    "ax[0, 0].set_title(r\"$f=\\mathrm{id}_\\mathbb{R}$\")\n",
    "ax[0, 1].set_title(r\"$f=\\tanh$\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず同じ初期値 $x[k]$ にもかかわらず、 $\\rho = 1.01$ で $x[k]$ の値の範囲が $[-1, 1]$ を大きく逸脱しています。\n",
    "また非線形ESNの場合、 $\\rho\\geq 1$ でも $x[k]$ は $\\tanh$ により $[-1, 1]$ の範囲に収まり無限に発散する状況は発生しませんが、$\\rho<1$ のケースのように0に収束しません。\n",
    "この際、ESPは成立せず、$x[0]$ の影響が残り続けます。\n",
    "後の章でも扱いますが、$\\rho$ を大きくすると非周期的で初期値鋭敏性を有する**カオス**が生じる場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "したがってNARMA10等の通常の用途では $\\rho < 1$ に限定して探索される場合が多いです。\n",
    "再び入力ありのケースを考えましょう。\n",
    "今簡単のため入力スケール$(\\sigma, \\phi)=(1, 0)$、$(f, W^\\mathrm{rec})=(\\mathrm{id}_\\mathrm{R}, I) $となる線形ESNを考えます。\n",
    "この際、状態の時間発展は以下の式で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] = \\rho x[k] + W^\\mathrm{in} u[k+1]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x[k]$の解析解は以下の式で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k] = W^\\mathrm{in} \\sum_{j=0}^\\infty \\rho^{j}  u[k-j]\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式から推測されるとおり、 $\\rho$ は内部状態 $x[k]$ をどれほど保持するか制御するパラメータで $\\rho$ が 1に近いほど 過去の入力を保持しやすくなります。\n",
    "この効果を確かめるため、NARMA10精度の $\\rho$ 依存性を調べてみましょう。\n",
    "次のコードは $\\rho$ を0.02刻みで 0から1まで変化させたときの NARMA10タスクの NRMSEと $x[k]$ の階数を描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dims = [25, 50, 100]\n",
    "rhos = np.linspace(0.0, 1.0, 51)[1:-1]  # 0.02, ..., 0.98\n",
    "rhos_batch = reshape_rho(rhos)  # use `reshape_rhos`.\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = sigma * us + phi\n",
    "\n",
    "nrmses, best_ids, ranks = [], [], []\n",
    "for dim in tqdm(dims):\n",
    "    w_in, net, w_out = create_setup(seed_setup, dim, rhos_batch, f=np.tanh)\n",
    "    x0 = np.zeros((rhos.shape[0], net.dim))\n",
    "    nrmse, xs = train_and_eval(x0, w_in, net, w_out, ts, vs, ys, time_info)\n",
    "    nrmses.append(nrmse[:, 0])\n",
    "    best_ids.append(np.argmin(nrmse[:, 0]))\n",
    "    xs_m = xs - xs.mean(axis=-2, keepdims=True)\n",
    "    ranks.append(np.linalg.matrix_rank(xs_m.swapaxes(-2, -1) @ xs_m))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw=dict(hspace=0.05))\n",
    "for dim, nrmse, best_id, rank in zip(dims, nrmses, best_ids, ranks, strict=False):\n",
    "    ax[0].plot(rhos, rank / dim, label=r\"$N={}$\".format(dim))\n",
    "    ax[1].plot(rhos, nrmse, label=r\"$N={}$\".format(dim))\n",
    "    ax[1].scatter(rhos[best_id], nrmse[best_id], s=100.0, marker=\"*\")\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylabel(r\"$r/N$\")\n",
    "ax[1].set_xlabel(r\"$\\rho$\")\n",
    "ax[1].set_ylabel(r\"NRMSE (best: $\\bigstar$)\")\n",
    "ax[1].legend(frameon=False)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NARMA10は10次程度の過去入力の成分を有するため、比較的 $\\rho$ が $1$ に近く、長く入力情報を保持できる領域が最適であるとわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 漏れ率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その他に重要なESNのパラメータとして $a$ が挙げられます。\n",
    "スペクトル半径 $\\rho$ と同様に過去状態をどの程度保持するかを制御するパラメータで $[0, 1]$の範囲の値を取ります。\n",
    "特に $a=1$ のケースでは線形項のない離散ESNと、 $a=0$ では定数 $x[k]=\\mathrm{const.}$ と等価になります。\n",
    "\n",
    "下記のような連続時間上で定義される連続ESNとその近似の文脈で漏れ率 $a$ はしばしば登場します。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tau \\dfrac{dx}{dt}(t) = -x(t) + \\tanh\\left(\\rho W^\\mathrm{rec} x(t) + W^\\mathrm{in} v(t)\\right)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで $\\tau \\in \\mathbb{R}$ は時定数です。\n",
    "この式をオイラー法により離散方程式として以下の近似式で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x(t+\\Delta t) = \\left(1-\\dfrac{\\Delta t}{\\tau}\\right) x(t) + \\dfrac{\\Delta t}{\\tau}\\tanh\\left(\\rho W^\\mathrm{rec} x(t) + W^\\mathrm{in} v(t + \\Delta t)\\right)\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t := k \\Delta t, a=\\Delta t / \\tau$ により冒頭の式と等価になります。\n",
    "上記の連続ESNの文脈では $a=0.1$ がよく見られますが、もちろんその限りではありません。\n",
    "$\\rho$ 同様に様々な $a$ に対して一度に $x[k]$ をサンプリングする`reshape_lr`を以下の設問で実装しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.3.\n",
    "\n",
    "長さ$k$ の配列として漏れ率 $A = \\left(a_0, a_1,~\\ldots,~a_{k-1} \\right) $ が与えられる。\n",
    "同じ入力 $u[k]$ と $W^\\mathrm{rec}$ に対して漏れ率のみを $a_{i}$ に変えたときのESNの時系列 $x_{i}[k]$ をまとめてサンプリングできるように、`reshape_lr`を完成させよ。\n",
    "\n",
    "- `reshape_lr`\n",
    "  - Argument(s):\n",
    "    - `lr`: `np.ndarray`\n",
    "      - `shape`: `(k,)`\n",
    "  - Return(s):\n",
    "    - `lr_new`: `np.ndarray`\n",
    "      - `shape`: `(k, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_lr(lr):\n",
    "    lr_new = ...  # TODO\n",
    "    return lr_new\n",
    "\n",
    "\n",
    "test_func(reshape_lr, \"03_03\")\n",
    "# show_solution(\"03_03\", \"reshape_lr\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードは $a$ を $10^{-2}$ から $1$ (離散ESN) まで変化させたときの NARMA10タスクの NRMSEを描画します。\n",
    "スペクトル半径を $\\rho=0.5$ に設定し、内部結合がもたらす記憶特性への寄与を小さくしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dims = [25, 50, 100]\n",
    "rho = 0.5\n",
    "leaky_rates = np.logspace(-1, 0, 21)\n",
    "lr_batch = reshape_lr(leaky_rates)  # Use `reshape_lr`.\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = sigma * us + phi\n",
    "\n",
    "nrmses, best_ids = [], []\n",
    "for dim in tqdm(dims):\n",
    "    w_in, net, w_out = create_setup(seed_setup, dim, rho, f=np.tanh, a=lr_batch)\n",
    "    x0 = np.zeros((leaky_rates.shape[0], net.dim))\n",
    "    nrmse, xs = train_and_eval(x0, w_in, net, w_out, ts, vs, ys, time_info)\n",
    "    nrmses.append(nrmse[:, 0])\n",
    "    best_ids.append(np.argmin(nrmse[:, 0]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "for dim, nrmse, best_id in zip(dims, nrmses, best_ids, strict=False):\n",
    "    ax.plot(leaky_rates, nrmse, label=r\"$N={}$\".format(dim))\n",
    "    ax.scatter(leaky_rates[best_id], nrmse[best_id], s=100.0, marker=\"*\")\n",
    "ax.set_xlabel(r\"$a$\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(r\"NRMSE (best: $\\bigstar$)\")\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True, which=\"minor\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.4. (Advanced)\n",
    "\n",
    "- NARMA10よりも時定数の短いタスク (NARMA2)を試し、$\\rho$ や $a$ 依存性がどのように変化するか確かめよ。\n",
    "- オイラー法は[1次のルンゲ・クッタ (Runge-Kutta; RK)法](https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods) として一般化される。上記の連続時間上のESNの微分方程式に対して、より高次なRK法 (例えばRK4) を適用し離散化したESNを実装せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. データセットのサイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットのサイズ $T_\\textrm{train}$ の影響を確認しましょう。\n",
    "一般に学習データの時系列が長いほどより信頼性の高い評価が可能になります。\n",
    "以下のコードは $(\\sigma, \\phi, N, \\rho) = (0.05, 0.05, 50, 0.9)$ に対して  $T_\\textrm{train}= (100,200,400,800,1600,3200)$ と変化させたときのNARMA10のNRMSEの分布 (デフォルトでは100個の $(W^\\mathrm{in}, W^\\mathrm{rec})$ をランダムに生成) を描画します (完了まで数分程度かかる場合があります。あまりに時間がかかる場合は`sample_num`や`dim`を小さくしてください)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 100\n",
    "seed_setup, seed_dataset = 1234, 5678\n",
    "t_trains = [100, 200, 400, 800, 1600, 3200]\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dim, rho = 50, 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=max(t_trains), t_eval=1000)\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "w_in_ws, net_ws = [], []\n",
    "for seed in trange(sample_num):  # Create setups for `sample_num` times.\n",
    "    w_in, net, _w_out = create_setup(seed_setup + seed, dim, rho, f=np.tanh)\n",
    "    w_in_ws.append(w_in.weight)\n",
    "    net_ws.append(net.weight)\n",
    "\n",
    "w_in_batch = Linear(1, dim)\n",
    "w_in_batch.weight = np.array(w_in_ws)[:, None, :, :]  # [*bs, 1, N, 1] ([1] -> [*bs, 1, N])\n",
    "net_batch = ESN(dim, sr=rho)\n",
    "net_batch.weight = np.array(net_ws)  # [bs, N, N] ([*bs, 1, N] -> [*bs, 1, N])\n",
    "w_out = BatchLRReadout(dim, 1)\n",
    "\n",
    "vs = sigma * us + phi\n",
    "x0 = np.zeros((sample_num, 1, net.dim))\n",
    "xs = sample_dynamics(x0, w_in_batch, net_batch, ts, vs, display=True)\n",
    "nrmse_dict = {}\n",
    "for t_train in t_trains:\n",
    "    time_info[\"t_washout\"] = dataset_info[\"t_washout\"] + max(t_trains) - t_train\n",
    "    nrmse = eval_nrmse(xs, ys, w_out, time_info=time_info)[:, 0, 0]\n",
    "    nrmse_dict[t_train] = nrmse\n",
    "    print(\"t_train={}: {:.3e}±{:.3e} (#sample={})\".format(t_train, nrmse.mean(), nrmse.std(), nrmse.size))\n",
    "\n",
    "nrmse_aves = [nrmse.mean() for nrmse in nrmse_dict.values()]\n",
    "nrmse_stds = [nrmse.std() for nrmse in nrmse_dict.values()]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.errorbar(t_trains, nrmse_aves, nrmse_stds)\n",
    "ax.set_xlabel(r\"$T_\\mathrm{train}$\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"NRMSE\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, which=\"both\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_\\mathrm{train}$ が小さい時、学習精度が悪くかつその分散が大きく不安定です。\n",
    "これは最大ランクとなる $N \\geq T_\\mathrm{train}$ の条件**のみ**では不十分で、より長い時間のサンプルの必要性を示唆しています。\n",
    "実際 $T_\\mathrm{train}$ は $N$ よりずっと大きい値が望ましく、経験的には10倍以上の長さがしばしば採用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.1. (Advanced)\n",
    "\n",
    "- $N$ を大きくして同様に $T_\\mathrm{train}$ とNRMSEの関係を調べよ。\n",
    "- 他のタスクに関しても同様に調査せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 時系列の長さが短いときの対処法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *\"I remember my friend Johnny von Neumann used to say, with four parameters I can fit an elephant, and with five I can make him wiggle his trunk.\"*,\n",
    "> by [Enrico Fermi, 1953](https://en.wikipedia.org/wiki/Von_Neumann%27s_elephant)\n",
    ">\n",
    "> *ジョニーは言っていたよ、『パラメータが4つあったら象だって描けるし、5つあればその鼻さえ動かせる』と。* (エンリコ・フェルミ 1953)\n",
    "\n",
    "前節では $T_\\mathrm{train}$ の大きさの重要性を示しました。\n",
    "しかしながら現実にはリザバーの次元数 $N$ に対して十分なサイズの学習データを確保できない状況にしばしば遭遇します。\n",
    "典型的には物理リザバーの研究のように、物性固有の時定数やセンサーのサンプリング周波数によって十分大きな $T_\\mathrm{train}$ を確保できない状況が考えられます。\n",
    "逆にあまりに高次元な設定、すなわち $N$ が大きすぎて要求される $T_\\mathrm{train}$ が大きいが、その計算や保存が現実的ではない場合もありえます。\n",
    "\n",
    "このような状況で注意しなければならないのは **過学習 (overfitting)** と呼ばれる現象の発生です。\n",
    "すなわち学習データに過適合しすぎて、評価データに対する汎化性能が低い状況を指します。\n",
    "ここではそのような過学習を避けるテクニックとして **リッジ回帰** (ridge regression) ならびに **赤池情報量規準** (Akaike Information Criteria; AIC) を用いたリッジ回帰のパラメータの自動調整を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### リッジ回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リッジ回帰は最小二乗問題におけるコスト関数 $\\mathrm{RSS}(X, Y, w):=\\|Xw - Y\\|^2$ に正則化項を追加して、パラメータ $w$ の大きさ ( $L^2$ ノルム) に制限を加える手法です。\n",
    "リッジパラメータ $\\lambda(>0)$ を用いてそのコスト関数 $\\mathcal{L}^\\mathrm{ridge}$ は以下の式で定義されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}^\\mathrm{ridge}(X, Y, w, \\lambda) & := \\mathrm{RSS}(X, Y, w) + \\lambda \\|w\\|^2\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでこのコスト関数を最小化する $\\hat{w}^\\mathrm{ridge}$ は以下の式より線形回帰同様にワンショット (one-shot) で求まります。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{w}^\\mathrm{ridge}(X, Y, \\lambda):&=\\mathrm{arg}\\min_{w} \\mathcal{L}^\\mathrm{ridge}(X, Y, w, \\lambda) \\\\\n",
    "&=(X^\\top X + \\lambda I)^{-1}X^\\top Y\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラム行列 $X^\\top X$ は半正定値行列 (すべての固有値が0以上) なので $X^\\top X + \\lambda I$ は正定値行列で常に逆行列が存在します。\n",
    "したがって通常の線型回帰よりもリッジ回帰は数値的に安定といえます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.1.\n",
    "\n",
    "`Linear`を継承し、バイアス項を加えた予測変数 $\\tilde{X}=[1 : X]\\in\\mathbb{R}^{...\\times T\\times (N+1)}$、予測対象変数 $Y\\in \\mathbb{R}^{... \\times T \\times D}$ ならびにリッジパラメータ$\\lambda \\in \\mathbb{R}^{+}$ に対して、 $\\mathcal{L}^\\mathrm{ridge}(\\tilde{X}, Y, w)$ を最小化する $\\hat{w}^\\mathrm{ridge}\\in\\mathbb{R}^{...\\times(N+1)\\times D}$ を計算し、その重みとバイアスを更新する `RidgeReadout` を完成させよ。\n",
    "なお`BatchLRReadout`の実装を参考にせよ。\n",
    "\n",
    "- `RidgeReadout.train`\n",
    "  - Argument(s):\n",
    "    - `x`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, input_dim)`\n",
    "    - `y`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, output_dim)`\n",
    "  - Returns(s):\n",
    "    - `self.weight`: `np.ndarray`\n",
    "      - `shape`: `(..., output_dim, input_dim)`\n",
    "    - `self.bias`: `np.ndarray`\n",
    "      - `shape`: `(..., 1, output_dim)`\n",
    "\n",
    "  - Operation(s):\n",
    "      - `self.weight`の更新\n",
    "      - `self.bias`の更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeReadout(Linear):\n",
    "    def __init__(self, *args, lmbd: float = 0.0, **kwargs):\n",
    "        super(RidgeReadout, self).__init__(*args, **kwargs)\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray):\n",
    "        assert (x.ndim > 1) and (x.shape[-1] == self.input_dim)\n",
    "        assert (y.ndim > 1) and (y.shape[-1] == self.output_dim)\n",
    "        x_biased = np.ones((*x.shape[:-1], x.shape[-1] + 1), dtype=self.dtype)\n",
    "        x_biased[..., 1:] = x\n",
    "        # TODO Implement ridge regression to obtain `self.weight` and `self.bias`.\n",
    "        xtx = ...\n",
    "        xty = ...\n",
    "        sol = ...\n",
    "        self.weight = ...\n",
    "        self.bias = ...\n",
    "        # end of TODO\n",
    "        return self.weight, self.bias\n",
    "\n",
    "\n",
    "def solution(dim_in, dim_out, x_train, y_train, x_eval, lmbd):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    readout = RidgeReadout(dim_in, dim_out, lmbd=lmbd)\n",
    "    readout.train(x_train, y_train)\n",
    "    return readout(x_eval)\n",
    "\n",
    "\n",
    "test_func(solution, \"05_01\")\n",
    "# show_solution(\"05_01\", \"RidgeReadout\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のコードは先程の $T_\\mathrm{train}$ を変更するコードで `BatchLRReadout` を `RidgeReadout` に置き換えてNRMSEを描画するコードです。\n",
    "$\\lambda = 0$ の代入でリッジ回帰が線型回帰と等価になる点に注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 100\n",
    "seed_setup, seed_dataset = 1234, 5678\n",
    "t_trains = [50, 100, 200, 400, 800, 1600, 3200]\n",
    "ridge_parameters = [0.0, 1.0, 1e-2, 1e-4, 1e-6, 1e-8]\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dim, rho = 50, 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=max(t_trains), t_eval=1000)\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "w_in_ws, net_ws = [], []\n",
    "for seed in trange(sample_num):  # Create setups for `sample_num` times.\n",
    "    w_in, net, _w_out = create_setup(seed_setup + seed, dim, rho, f=np.tanh)\n",
    "    w_in_ws.append(w_in.weight)\n",
    "    net_ws.append(net.weight)\n",
    "\n",
    "w_in_batch = Linear(1, dim)\n",
    "w_in_batch.weight = np.array(w_in_ws)[:, None, :, :]  # [bs, 1, N, 1] (-> [bs, 1, N])\n",
    "net_batch = ESN(dim, sr=rho)\n",
    "net_batch.weight = np.array(net_ws)  # [bs, N, N] ([bs, 1, N] -> [bs, 1, N])\n",
    "w_out = RidgeReadout(dim, 1)  # Use ridge regression.\n",
    "\n",
    "vs = sigma * us + phi\n",
    "x0 = np.zeros((sample_num, 1, net.dim))\n",
    "xs = sample_dynamics(x0, w_in_batch, net_batch, ts, vs, display=True)\n",
    "nrmse_dict = {lmbd: {} for lmbd in ridge_parameters}\n",
    "for lmbd, t_train in tqdm(list(itertools.product(ridge_parameters, t_trains))):\n",
    "    time_info[\"t_washout\"] = dataset_info[\"t_washout\"] + max(t_trains) - t_train\n",
    "    w_out.lmbd = lmbd\n",
    "    nrmse = eval_nrmse(xs, ys, w_out, time_info=time_info)[:, 0, 0]\n",
    "    nrmse_dict[lmbd][t_train] = nrmse\n",
    "    # print('λ={:.2e}, t_train={}: {:.3e}±{:.3e} (#sample={})'.format(\n",
    "    #     lmbd, t_train, nrmse.mean(), nrmse.std(), nrmse.size))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "for lmbd in ridge_parameters:\n",
    "    nrmse_aves = [nrmse.mean() for nrmse in nrmse_dict[lmbd].values()]\n",
    "    nrmse_stds = [nrmse.std() for nrmse in nrmse_dict[lmbd].values()]\n",
    "    if lmbd == 0.0:\n",
    "        plot_kws = dict(label=r\"LR ($\\lambda=0$)\", color=\"k\", ls=\":\")\n",
    "    else:\n",
    "        plot_kws = dict(label=r\"Ridge ($\\lambda=10^{{{:.0f}}}$)\".format(np.log10(lmbd)))\n",
    "    ax.errorbar(t_trains, nrmse_aves, nrmse_stds, **plot_kws)\n",
    "ax.set_xlabel(r\"$T_\\mathrm{train}$\")\n",
    "ax.set_ylabel(\"NRMSE\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"upper right\", borderaxespad=0, ncol=1, frameon=False)\n",
    "ax.grid(True, which=\"both\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特に $T_\\mathrm{train} \\approx N $ 周辺で 線型回帰が不安定になるのに対し、Ridge ( $\\lambda=10^{-4}, 10^{-6}$ )における精度は安定しています。\n",
    "また $T_\\mathrm{train} \\gg N$ でも 線型回帰とほぼ同等の精度と安定性を有します。\n",
    "一方で $\\lambda$ が大きい ( $\\lambda=10^{0}, 10^{-2}$ ) と精度は安定するものの、線型回帰に大きく劣る結果になっています。\n",
    "この現象は過学習の対義語で**学習不足 (underfitting)** と呼ばれます。\n",
    "逆に $\\lambda$ を小さくしすぎる ( $\\lambda=10^{-8}$ ) と線形回帰同様の不安定性、すなわち過学習が $T_\\mathrm{train} \\approx N$ で発生します。\n",
    "\n",
    "このように リッジパラメータ $\\lambda$ の適切な選択は、学習の精度や安定性の意味でとても重要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AICを用いたリッジパラメータ $\\lambda$ の自動調整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リッジ回帰ではリッジパラメータの導入により、$T_\\mathrm{train}$ が小さいケースでもより安定な学習が可能になりました。\n",
    "一方で先述のとおり、このリッジパラメータ $\\lambda$ はハイパーパラメータの一種であり、その調整が別途必要です。\n",
    "特に $\\lambda$ は任意の正の実数を取りうるので、その探索範囲は無限大におよびその取り扱いはかなり厄介です。\n",
    "そこでこの $\\lambda$ を自動的に決定するためにAICと呼ばれる指標を導入します。\n",
    "AICはモデルサイズと残差誤差のバランスをとり、妥当なモデルを構築するための指標 (情報量規準) で機械学習の分野で広く使用されます。\n",
    "リッジ回帰の場合は以下の式で計算されます<sup>[2]</sup>。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{AIC}(X, Y, \\lambda) :&= T \\ln\\left(\\mathrm{RSS}(X, Y, \\hat{w}^\\mathrm{ridge}(X, Y, \\lambda))\\right) + \\mathrm{df}(X, \\lambda) \\\\\n",
    "&= T\\ln\\left(\\|X\\hat{w}^\\mathrm{ridge}(X, Y, \\lambda) - Y\\|^2\\right) + \\mathrm{df}(X, \\lambda)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで$\\mathrm{df}(X, \\lambda)$はモデルの自由度を表し以下の式で計算されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathrm{df}(X, \\lambda) :&= \\mathrm{tr}[X(X^\\top X + \\lambda I)^{-1}X^\\top] \\\\\n",
    "&= \\sum_{i=0}^{N-1}\\frac{\\sigma_{i}^2}{\\sigma_{i}^2+\\lambda}\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\{\\sigma_i \\}_{i=0}^{N-1}$ は $X \\in \\mathbb{R}^{T\\times N}$ を特異値分解した際の特異値です。\n",
    "AICの最小化により妥当な $\\lambda$ を選択できます。\n",
    "一方で式より $0<\\mathrm{df} \\leq N$ となります。\n",
    "したがって $\\lambda$ の代わりに予め $\\mathrm{df}$ の候補 $\\{\\mathrm{df}_k \\}$を用意し、$\\mathrm{df}_k = \\mathrm{df}(X, \\lambda_k)$ となる $\\lambda_k$ を逆算し、$\\mathrm{AIC}(X, Y, \\lambda_k)$ が最小となる $\\lambda_k$ を選ぶ指針を取れます。\n",
    "このような手順で、無限大まで及んだ $\\lambda$ の候補を $\\mathrm{df}$ の範囲に置き換えて、探索範囲を狭められます。\n",
    "\n",
    "以下、詳細なアルゴリズムを記載します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\{\\mathrm{df}_k\\}$ の候補を作成します。\n",
    "典型的には整数値 $\\{1,~\\ldots,~N\\}$ のみを候補として選択します。\n",
    "2. ニュートン法により$f(\\lambda_k)=0$の解 $\\lambda_k$ を求めます。\n",
    "3. $\\lambda_k$ を用いて $\\mathrm{AIC}(X, Y, \\lambda_k)$ を計算します。\n",
    "4. $\\mathrm{AIC}(X, Y, \\lambda_k)$ を最小化する $k$ ならびに $\\lambda_k$ を求めます。\n",
    "\n",
    "ただし$f(\\lambda_k)$は以下の式で定義されます\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\lambda_k) = \\mathrm{df}_k - \\sum_{i=0}^{N-1}\\frac{\\sigma_{i}^2}{\\sigma_{i}^2+\\lambda_k}\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "またニュートン法では以下の式で与えられる導関数 $\\dfrac{df}{d\\lambda_k}$ を使用します。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\dfrac{df}{d\\lambda_k}(\\lambda_k) = \\sum_{i=0}^{N-1}\\frac{\\sigma_{i}^2}{\\left(\\sigma_{i}^2+\\lambda_k\\right)^2}\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.2.\n",
    "\n",
    "上記のアルゴリズムを実装するため、穴埋めを実装し`calc_df_and_lambda`・`calc_aic`・`AutoRidgeReadout`を完成させよ。\n",
    "\n",
    "- `AutoRidgeReadout.train`\n",
    "  - Argument(s):\n",
    "    - `x`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, input_dim)`\n",
    "    - `y`: `np.ndarray`\n",
    "      - `shape`: `(..., time_steps, output_dim)`\n",
    "  - Return(s):\n",
    "    - `self.weight`: `np.ndarray`\n",
    "      - `shape`: `(..., output_dim, input_dim)`\n",
    "    - `self.bias`: `np.ndarray`\n",
    "      - `shape`: `(..., 1, output_dim)`\n",
    "    - `*misc`\n",
    "\n",
    "  - Operation(s):\n",
    "      - `self.weight`の更新 ( $\\mathrm{AIC}$ を最小化する重み )\n",
    "      - `self.bias`の更新 ( $\\mathrm{AIC}$ を最小化するバイアス )\n",
    "      - `self.lmbd`の更新　( $\\mathrm{AIC}$ を最小化する $\\lambda$ )\n",
    "\n",
    "<details><summary>tips</summary>\n",
    "\n",
    "- [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton.html)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_df_and_lambda(xs: np.array, df_max: int = None, num_cand: int = None, lmbd0=1e-12):\n",
    "    batch_size, dim = xs.shape[:-2], xs.shape[-1]\n",
    "    if df_max is None:\n",
    "        df_max = dim\n",
    "    if num_cand is None:\n",
    "        num_cand = df_max\n",
    "\n",
    "    _left, sigma, _right = np.linalg.svd(xs)\n",
    "    sigma2 = (sigma**2)[..., None, :]  # [*bs, 1, dim]\n",
    "    dfs = np.linspace(0, df_max, num_cand + 1)[1:]  # Candidates for degrees of freedom -> [num_cand]\n",
    "    init_cond = np.full((*batch_size, num_cand), lmbd0)  # Initial condition for λ -> [*bs, num_cand]\n",
    "\n",
    "    def func(lmbd):\n",
    "        # TODO `lmbd`: [*bs, num_cand], `sigma2`: [*bs, 1, dim]\n",
    "        ...\n",
    "\n",
    "    def fprime(lmbd):\n",
    "        # TODO `lmbd`: [*bs, num_cand], `sigma2`: [*bs, 1, dim]\n",
    "        ...\n",
    "\n",
    "    # TODO Solve f(λ) = 0 for using Newton's method. The output `lmbds` should be of shape [*bs, num_cand].\n",
    "    lmbds = ...\n",
    "    # end of TODO\n",
    "    lmbds[lmbds < 0] = 0  # Remove negative λ due to numerical errors.\n",
    "    return dfs, lmbds\n",
    "\n",
    "\n",
    "def calc_aic(xs, ys, **kwargs):\n",
    "    assert xs.shape[-2] == ys.shape[-2]\n",
    "    *batch_size, length, dim_in = xs.shape\n",
    "    dfs, lmbds = calc_df_and_lambda(xs, **kwargs)  # dfs: [num_cand], lmbds: [*bs, num_cand]\n",
    "    xs = xs[..., None, :, :]  # [*bs, 1, length, dim_in]\n",
    "    ys = ys[..., None, :, :]  # [*bs, 1, length, dim_in]\n",
    "    xtx = xs.swapaxes(-2, -1) @ xs  # X^T X: [*bs, 1, dim_in, dim_in]\n",
    "    xty = xs.swapaxes(-2, -1) @ ys  # X^T Y: [*bs, 1, dim_in, dim_out]\n",
    "    # TODO Ridge regression with λ -> [*bs, num_cand, dim_in, dim_out]\n",
    "    sol = ...\n",
    "    # end of TODO\n",
    "    rss = ...  # TODO RSS: [*bs, num_cand]\n",
    "    aics = ...  # TODO AIC: [*bs, num_cand]\n",
    "    return dfs, lmbds, sol, rss, aics\n",
    "\n",
    "\n",
    "class AutoRidgeReadout(Linear):\n",
    "    def __init__(self, *args, lmbd: float = 0.0, **kwargs):\n",
    "        super(AutoRidgeReadout, self).__init__(*args, **kwargs)\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "    def train(self, x: np.ndarray, y: np.ndarray, **kwargs):\n",
    "        assert (x.ndim > 1) and (x.shape[-1] == self.input_dim)\n",
    "        assert (y.ndim > 1) and (y.shape[-1] == self.output_dim)\n",
    "        x_biased = np.ones((*x.shape[:-1], x.shape[-1] + 1), dtype=self.dtype)\n",
    "        x_biased[..., 1:] = x\n",
    "        dfs, lmbds, sol, rss, aics = calc_aic(x_biased, y, **kwargs)\n",
    "        # dfs: [num_cand], lmbds: [*bs, num_cand]\n",
    "        # sol: [*bs, num_cand, dim_in, dim_out]\n",
    "        # rss: [*bs, num_cand], aics: [*bs, num_cand]\n",
    "        best_idx = ...  # TODO Extract the index of the best solution minimizing AIC.\n",
    "        sol_best = ...  # TODO Choose the best solution minimizing AIC.\n",
    "        self.lmbd = ...  # TODO Save the best λ minimizing AIC.\n",
    "        self.weight = ...  # TODO Update weight based on `sol_best`.\n",
    "        self.bias = ...  # TODO Update bias based on `sol_best`.\n",
    "        return self.weight, self.bias, dfs, lmbds, sol, rss, aics\n",
    "\n",
    "\n",
    "def solution(dim_in, dim_out, x_train, y_train, x_eval):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    readout = AutoRidgeReadout(dim_in, dim_out)\n",
    "    readout.train(x_train, y_train)\n",
    "    return readout(x_eval)\n",
    "\n",
    "\n",
    "test_func(solution, \"05_02\")\n",
    "# show_solution(\"05_02\", \"calc_df_and_lambda\")  # Uncomment it to see the solution.\n",
    "# show_solution(\"05_02\", \"calc_aic\")  # Uncomment it to see the solution.\n",
    "# show_solution(\"05_02\", \"AutoRidgeReadout\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(\\sigma,\\phi,N,\\rho,T_\\mathrm{train})=(0.05,0.05,500,0.9,2000)$ のケースで実装した`AutoRidgeReadout`の効果を検証してみましょう (時間の短縮のため`num_cand = dim // 10` により $\\{\\mathrm{df}_k\\}=\\{10, 20,~\\ldots,~500\\}$ としています)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678  # Please choose your favorite seeds.\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dim, rho = 500, 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs = sigma * us + phi\n",
    "\n",
    "w_in, net, w_out = create_setup(seed_setup, dim, rho, f=np.tanh, cls=AutoRidgeReadout)\n",
    "\n",
    "x0 = np.zeros(net.dim)\n",
    "xs = sample_dynamics(x0, w_in, net, ts, vs, display=True)\n",
    "nrmse, _weight, _bias, dfs, lmbds, sol, rss, aics = eval_nrmse(\n",
    "    xs, ys, w_out, time_info, return_out=True, df_max=dim, num_cand=dim // 10\n",
    ")\n",
    "\n",
    "best_idx = np.argmin(aics)\n",
    "rel_aics = aics - aics.min() + 1e0  # Normalize AICs for better visualization.\n",
    "y_out = w_out(xs)\n",
    "\n",
    "plot_length = 200\n",
    "fig = Figure(figsize=(8, 8))\n",
    "fig.create_grid(2, 1, height_ratios=(2, 1), hspace=0.4)\n",
    "ax0, ax1 = fig[0], fig[1]\n",
    "ax0.create_grid(2, 1, wspace=0.4)\n",
    "ax0[0].plot(dfs, lmbds)\n",
    "ax0[0].scatter(dfs[best_idx], lmbds[best_idx], s=100.0, marker=\"*\")\n",
    "ax0[0].set_yscale(\"log\")\n",
    "ax0[0].set_ylabel(r\"$\\lambda$\")\n",
    "ax0[0].set_xticklabels([])\n",
    "ax0[1].plot(dfs, rel_aics)\n",
    "ax0[1].scatter(dfs[best_idx], rel_aics[best_idx], s=100.0, marker=\"*\")\n",
    "ax0[1].set_ylabel(r\"relative $\\mathrm{AIC}$\")\n",
    "ax0[1].set_yscale(\"log\")\n",
    "info_str = r\"best: $\\mathrm{{df}}={:.0f},~\\lambda=10^{{{:.2f}}}$\".format(dfs[best_idx], np.log10(lmbds[best_idx]))\n",
    "ax0.set_title(info_str)\n",
    "ax0[1].set_xlabel(\"df\")\n",
    "\n",
    "ax1.set_xlabel(r\"$\\mathrm{{df}}$\")\n",
    "ax1.plot(ts[-plot_length:], ys[-plot_length:], color=\"k\", ls=\":\", lw=1.5)\n",
    "ax1.plot(ts[-plot_length:], y_out[-plot_length:], lw=1.5, color=\"red\")\n",
    "ax1.set_title(\"NRMSE={:.3e}\".format(nrmse[0]))\n",
    "ax1.set_ylabel(r\"$y[k]$ & $\\hat{y}[k]$\")\n",
    "ax1.set_xlabel(\"time steps\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線型回帰 ( $\\lambda=0$ ) やUnderfitting ( $\\lambda=10^{-2}$ ) のケースと`AutoRidgeReadout` を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 20\n",
    "seed_setup, seed_dataset = 1234, 5678\n",
    "t_trains = [100, 200, 400, 800, 1600, 3200]\n",
    "sigma, phi = 0.05, 0.05  # vs \\in [0.0, 0.1]\n",
    "dim, rho = 50, 0.9\n",
    "dataset_info = dict(t_washout=100, t_train=max(t_trains), t_eval=1000)\n",
    "ridge_parameters = [0.0, 1e-2, None]  # None: `AutoRidgeReadout`\n",
    "\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "w_in_ws, net_ws = [], []\n",
    "for seed in trange(sample_num):  # Create setups for `sample_num` times.\n",
    "    w_in, net, _w_out = create_setup(seed_setup + seed, dim, rho, f=np.tanh)\n",
    "    w_in_ws.append(w_in.weight)\n",
    "    net_ws.append(net.weight)\n",
    "\n",
    "w_in_batch = Linear(1, dim)\n",
    "w_in_batch.weight = np.array(w_in_ws)[:, None, :, :]  # [bs, 1, N, 1] (-> [bs, 1, N])\n",
    "net_batch = ESN(dim, sr=rho)\n",
    "net_batch.weight = np.array(net_ws)  # [bs, N, N] ([bs, 1, N] -> [bs, 1, N])\n",
    "x0 = np.zeros((sample_num, 1, net.dim))\n",
    "vs = sigma * us + phi\n",
    "xs = sample_dynamics(x0, w_in_batch, net_batch, ts, vs, display=True)\n",
    "\n",
    "nrmse_dict = {lmbd: {} for lmbd in ridge_parameters}\n",
    "lbmd_dict = {lmbd: {} for lmbd in ridge_parameters}\n",
    "for lmbd, t_train in tqdm(list(itertools.product(ridge_parameters, t_trains))):\n",
    "    time_info[\"t_washout\"] = dataset_info[\"t_washout\"] + max(t_trains) - t_train\n",
    "    if lmbd is None:\n",
    "        w_out = AutoRidgeReadout(dim, 1)\n",
    "        train_kws = dict(df_max=dim)\n",
    "    else:\n",
    "        w_out = RidgeReadout(dim, 1, lmbd=np.array(lmbd))\n",
    "        train_kws = {}\n",
    "    nrmse = eval_nrmse(xs, ys, w_out, time_info=time_info, **train_kws)\n",
    "    nrmse_dict[lmbd][t_train] = np.array(nrmse)\n",
    "    lbmd_dict[lmbd][t_train] = np.array(w_out.lmbd)\n",
    "    # print('t_train={}: λ: {:.3e}±{:.3e}, NRMSE: {:.3e}±{:.3e}'.format(\n",
    "    #     t_train, w_out.lmbd.mean(), w_out.lmbd.std(), nrmse.mean(), nrmse.std()))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw=dict(height_ratios=(1, 2), hspace=0.05))\n",
    "for lmbd in ridge_parameters:\n",
    "    nrmse_aves = [nrmse.mean() for nrmse in nrmse_dict[lmbd].values()]\n",
    "    nrmse_stds = [nrmse.std() for nrmse in nrmse_dict[lmbd].values()]\n",
    "    lmbd_aves = [lmbd.mean() for lmbd in lbmd_dict[lmbd].values()]\n",
    "    lmbd_stds = [lmbd.std() for lmbd in lbmd_dict[lmbd].values()]\n",
    "    if lmbd is None:\n",
    "        plot_kws = dict(label=r\"AutoRidge\", color=\"red\", ls=\"--\", lw=2.0)\n",
    "        ax[0].errorbar(t_trains, lmbd_aves, lmbd_stds, **plot_kws)\n",
    "    elif lmbd == 0.0:\n",
    "        plot_kws = dict(label=r\"LR ($\\lambda=0$)\", color=\"k\", ls=\":\")\n",
    "    else:\n",
    "        plot_kws = dict(label=r\"Ridge ($\\lambda=10^{{{:.0f}}}$)\".format(np.log10(lmbd)))\n",
    "    ax[1].errorbar(t_trains, nrmse_aves, nrmse_stds, **plot_kws)\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylabel(r\"$\\lambda$\")\n",
    "ax[0].grid(True, which=\"both\")\n",
    "ax[1].set_xlabel(r\"$T_\\mathrm{train}$\")\n",
    "ax[1].set_ylabel(\"NRMSE\")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].legend(loc=\"upper right\", borderaxespad=0, ncol=1, frameon=False)\n",
    "ax[1].grid(True, which=\"both\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.3. (Advanced)\n",
    "\n",
    "- $\\sigma$ や $\\rho$ を変化させて、`AutoRidgeReadout` のロバスト性を確認せよ。\n",
    "- 様々な $\\lambda$ による精度を `RidgeReadout` によって検証し、 `AutoRidgeReadout`のそれと比較せよ。\n",
    "- 必ずしも `AutoRidgeReadout`は評価誤差 (NRMSE) を最小にする $\\lambda$ を選択できるわけではない。この理由を考察せよ。\n",
    "- ベイズ情報量規準 (Bayesian Information Criterion; BIC) 等、他にも情報量規準は存在する。これら他の情報規準量を最小化するコードを実装し、AICと比較せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. グリッドサーチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは複数パラメータをまとめて探索しベストな組み合わせを得る**グリッドサーチ**の方法を学びます。\n",
    "グリッドサーチでは、予め与えられたハイパーパラメータの候補の**全て**の組み合わせを網羅的に探索されます。\n",
    "例えば、入力スケールとバイアス、スペクトル半径の3つのパラメータ $(\\sigma,\\phi,\\rho)$ のベストな組み合わせを探索したいとします。\n",
    "それぞれに関して以下に記される範囲を候補として考えます。\n",
    "\n",
    "- $\\sigma$ : $(0.05,0.10,0.15,~\\ldots~,1.00)$\n",
    "- $\\phi$ : $(0.00,0.05,0.10,~\\ldots~,1.00)$\n",
    "- $\\rho$ : $(0.6,0.7,0.8,0.9)$\n",
    "\n",
    "この際、$20\\times 21\\times 4=840$ 個の組み合わせが考えられ、グリッドサーチではその全てが検証されます。\n",
    "なおこのグリッドサーチでは先程より登場したバッチ処理が有効です。\n",
    "ここでもグリッドサーチに向けた、$u[k]$ ならびにESN初期値の指定方法を以下の設問で学びましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.1.\n",
    "\n",
    "入力時系列 $U=\\{u[k]\\} \\in \\mathbb{R}^{T\\times 1}$ 、\n",
    "長さ $k$ の入力スケール配列 $\\Sigma = (\\sigma_0$, $\\sigma_1,~\\ldots,~\\sigma_{k-1})$ 、\n",
    "長さ $l$ のバイアスを格納した配列 $\\Phi = (\\phi_0$, $\\phi_1,~\\ldots,~\\phi_{l-1})$\n",
    "ならびに 長さ $m$ のスペクトル半径を格納した配列 $\\Rho = (\\rho_0$, $\\rho_1,~\\ldots,~\\rho_{m-1})$ が与えられる。\n",
    "同じ $W^\\mathrm{in}, W^\\mathrm{rec}$ に対して 全部で $k\\times l\\times m$ 個の条件をまとめて $x[k] \\in \\mathbb{R}^{k\\times l\\times m\\times N}$ としてサンプリングするために $v[k]$ を生成し $\\Rho$ を変形する`create_grid_search_setup` を完成させよ。\n",
    "\n",
    "- `create_grid_search_setup`\n",
    "  - Argument(s):\n",
    "    - `us`: `np.ndarray`\n",
    "      - `shape`: `(t, 1)`\n",
    "    - `sigma`: `np.ndarray`\n",
    "      - `shape`: `(k,)`\n",
    "    - `phi`: `np.ndarray`\n",
    "      - `shape`: `(l,)`\n",
    "    - `rho`: `np.ndarray`\n",
    "      - `shape`: `(m,)`\n",
    "  - Return(s):\n",
    "    - `vs`: `np.ndarray`\n",
    "      - `shape`: `(k, l, 1, t, 1)`\n",
    "    - `rho_new`: `np.ndarray`\n",
    "      - `shape`: `(m, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_search_setup(us, sigma, phi, rho):\n",
    "    vs = ...  # TODO\n",
    "    rho_new = ...  # TODO\n",
    "    return vs, rho_new\n",
    "\n",
    "\n",
    "test_func(create_grid_search_setup, \"06_01\", multiple_output=True)\n",
    "# show_solution(\"06_01\", \"create_grid_search_setup\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードは $840$ 個の組み合わせに対してまとめてNRMSEを評価するコードです (環境によっては描画まで数分かかったり、メモリ不足により実行できないかもしれません。あまりに時間がかかる場合は `dim` や `t_train`を小さくしたり、`sigmas`・`phis`・`rhos`の間隔を大きくしてください)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_setup, seed_dataset = 1234, 5678\n",
    "dim = 50\n",
    "sigmas = np.linspace(0.0, 1.0, 21)[1:]  # [0.05, 0.10, ...., 1.00]\n",
    "phis = np.linspace(0.0, 1.0, 21)  # [0.0, 0.05,, ...., 1.00]\n",
    "rhos = np.array([0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "vs_batch, rhos_batch = create_grid_search_setup(us, sigmas, phis, rhos)  # Use `create_grid_search_setup`.\n",
    "\n",
    "w_in, net, w_out = create_setup(seed_setup, dim, rhos_batch, f=np.tanh)\n",
    "x0 = np.zeros((sigmas.shape[0], phis.shape[0], rhos.shape[0], net.dim))\n",
    "xs = sample_dynamics(x0, w_in, net, ts, vs_batch, display=True)\n",
    "nrmse = eval_nrmse(xs, ys, w_out, time_info)[..., 0]  # [k, l, m]\n",
    "\n",
    "top_num = 5\n",
    "best_ids = np.array(np.unravel_index(np.argsort(nrmse, axis=None)[:top_num], nrmse.shape)).T\n",
    "for idx, pos in enumerate(best_ids):\n",
    "    print(\n",
    "        \"#{}: NRMSE={:.2e}, σ={:.2e}, Φ={:.2e}, ρ={:.2e}\".format(\n",
    "            idx + 1, nrmse[(*pos,)], sigmas[pos[0]], phis[pos[1]], rhos[pos[2]]\n",
    "        )\n",
    "    )\n",
    "\n",
    "grid_num = (len(rhos) ** 0.5).__ceil__()\n",
    "fig = Figure(figsize=(6 * grid_num, 5 * grid_num))\n",
    "fig.create_grid(grid_num, grid_num, hspace=0.5, wspace=0.5)\n",
    "\n",
    "vmax = min(1.0, np.max(nrmse))\n",
    "vmin = max(0.1, np.min(nrmse))\n",
    "for idx, rho in enumerate(rhos):\n",
    "    fig[idx].plot_matrix(\n",
    "        nrmse[..., idx],\n",
    "        index=sigmas,\n",
    "        column=phis,\n",
    "        vmax=vmax,\n",
    "        vmin=vmin,\n",
    "        cmap=\"viridis\",\n",
    "        zscale=\"log\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    fig[idx].set_xlabel(r\"$\\phi$\")\n",
    "    fig[idx].set_ylabel(r\"$\\sigma$\")\n",
    "    fig[idx].set_title(r\"$\\rho={:.2f}$\".format(rho))\n",
    "\n",
    "px, py, idx = best_ids[0]\n",
    "fig[idx].scatter(py, px, s=200.0, marker=\"*\", color=\"magenta\")\n",
    "fig.suptitle(\n",
    "    r\"best NRMSE={:.2e}, $(\\sigma,\\phi,\\rho)=$({:g},{:g},{:g})\".format(\n",
    "        nrmse[(*best_ids[0],)], sigmas[px], phis[py], rhos[idx]\n",
    "    )\n",
    ")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドサーチは組み合わせの数に比例する計算量が発生します。\n",
    "したがってハイパーパラメータの数が増えると、計算が現実的でなかったりメモリ不足が発生する場合があります。\n",
    "一般的にはパラメータを粗く設定した後に、より詳細にパラメータを探索する戦略が取られる場合があります。\n",
    "\n",
    "様々な方法がありますが、最も簡便な例として以下のアルゴリズムが考えられます。\n",
    "1. パラメータの分割数 $p$ を決定\n",
    "2. 最適化するパラメータ $\\theta$ の最小値 $\\theta_\\mathrm{min}$ と最大値 $\\theta_\\mathrm{max}$ を指定\n",
    "3. 探索される $p$ 個の パラメータ $\\theta_{k} = \\theta_\\mathrm{min} + (k + 0.5)(\\theta_\\mathrm{max}-\\theta_\\mathrm{min})/p~(0 \\leq k < p)$ を用意\n",
    "4. 各 $\\theta_k$ に対して目的関数 $\\mathcal{L}(\\theta_k)$ を計算\n",
    "5. $\\mathcal{L}(\\theta_k)$ を最小化する $\\hat{k}:=\\mathrm{argmin}_k \\mathcal{L}(\\theta_k)$ を計算\n",
    "6. $\\theta_\\mathrm{min}\\leftarrow \\theta_\\mathrm{min}+\\hat{k}(\\theta_\\mathrm{max}-\\theta_\\mathrm{min})/p$\n",
    "7. $\\theta_\\mathrm{max}\\leftarrow \\theta_\\mathrm{min}+(\\hat{k}+1)(\\theta_\\mathrm{max}-\\theta_\\mathrm{min})/p$\n",
    "8. 3.に戻る\n",
    "\n",
    "無論このアルゴリズムは $\\mathcal{L}$ の値の変化が パラメータの分割間隔と比して十分に「滑らか」でないと機能しませんが、実装が簡単なので大雑把に良いパラメータの組み合わせを調査するのに使用できます。\n",
    "次の設問でこのアルゴリズムの重要な箇所を実装しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.2.\n",
    "\n",
    "実数  $\\theta_\\mathrm{min}, \\theta_\\mathrm{max}$ と分割数を表す正の整数 $p$ が与えられる。\n",
    "長さ $p$ の配列 $\\{\\theta_{k}\\}$ を生成する`create_parameter_set`を実装せよ。\n",
    "\n",
    "- `create_parameter_set`\n",
    "  - Argument(s):\n",
    "    - `th_min`: `float`\n",
    "    - `th_max`: `float`\n",
    "    - `num_split` : `int`\n",
    "  - Return(s):\n",
    "    - `th_new`: `np.ndarray`\n",
    "      - `shape`: `(num_split,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameter_set(th_min, th_max, num_split):\n",
    "    th_new = ...  # TODO\n",
    "    return th_new\n",
    "\n",
    "\n",
    "test_func(create_parameter_set, \"06_02\")\n",
    "# show_solution(\"06_02\", \"create_parameter_set\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードは 下記の範囲のパラメータを分割数 5 (`num_split`) で 10回 (`num_iteration`) 繰り返し探索します。\n",
    "\n",
    "- $\\sigma\\in (0.0, 1.0)$\n",
    "- $\\phi\\in (0.0, 1.0)$\n",
    "- $\\rho\\in (0.0, 2.0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split = 5\n",
    "num_iteration = 10\n",
    "seed_setup, seed_dataset = 1234, 5678\n",
    "dim = 50\n",
    "parameter_range = dict(\n",
    "    sigma=(0.0, 1.0),\n",
    "    phi=(0.0, 1.0),\n",
    "    rho=(0.0, 2.0),\n",
    ")\n",
    "dataset_info = dict(t_washout=100, t_train=2000, t_eval=1000)\n",
    "ts, us, ys, time_info = sample_dataset(seed_dataset, **dataset_info)\n",
    "\n",
    "for idx in range(num_iteration):\n",
    "    # print(parameter_range)\n",
    "    sigmas, phis, rhos = map(lambda v: create_parameter_set(*v, num_split), parameter_range.values())\n",
    "    # print(sigmas, phis, rhos)\n",
    "    vs_batch, rhos_batch = create_grid_search_setup(us, sigmas, phis, rhos)\n",
    "    w_in, net, w_out = create_setup(seed_setup, dim, rhos_batch, f=np.tanh)\n",
    "    x0 = np.zeros((sigmas.shape[0], phis.shape[0], rhos.shape[0], net.dim))\n",
    "    xs = sample_dynamics(x0, w_in, net, ts, vs_batch, display=False)\n",
    "    nrmse = eval_nrmse(xs, ys, w_out, time_info)[..., 0]  # [k, l, m]\n",
    "    best_ids = np.unravel_index(np.argmin(nrmse, axis=None), nrmse.shape)\n",
    "    print(\n",
    "        \"#{:>2}: NRMSE={:.6e}, σ={:g}, Φ={:g}, ρ={:g}\".format(\n",
    "            idx + 1, nrmse[(*best_ids,)], sigmas[best_ids[0]], phis[best_ids[1]], rhos[best_ids[2]]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    parameter_set_new = dict()\n",
    "    for pos, (key, param_range) in zip(best_ids, parameter_range.items(), strict=False):\n",
    "        vmin, vmax = param_range\n",
    "        vmin_new = vmin + (vmax - vmin) * pos / num_split\n",
    "        vmax_new = vmin + (vmax - vmin) * (pos + 1) / num_split\n",
    "        parameter_set_new[key] = (vmin_new, vmax_new)\n",
    "    parameter_range = parameter_set_new\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.3. (Advanced)\n",
    "\n",
    "- $N$ や $p$ を大きくすると環境によってはメモリ不足が発生する場合がある。メモリ不足を回避しながら実行できるようにコードを改変せよ。\n",
    "- $N$ や $p$ を変化させこのアルゴリズムの長所と短所を考察せよ。\n",
    "- よりロバストなハイパーパラメータ探索の方法を調査し、実装に組み込め。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.4. (Advanced)\n",
    "\n",
    "- 今回学んだパラメータの探索方法を活用し、物理リザバーの研究に応用せよ。\n",
    "- 例えば空気圧人工筋肉 (Pneumatic Artificial Muscle; PAM)<sup>[3, 4]</sup> の研究で公開されているデータセットを用いて、今回のセットアップで検証せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Kubota, T., Takahashi, H., & Nakajima, K. (2021). *Unifying framework for information processing in stochastically driven dynamical systems*. Physical Review Research, 3(4), 043135. https://doi.org/10.1103/PhysRevResearch.3.043135\n",
    "\n",
    "[2] Goto, K., Nakajima, K., & Notsu, H. (2021). *Twin vortex computer in fluid flow*. New Journal of Physics, 23(6), 063051. https://doi.org/10.1088/1367-2630/ac024d\n",
    "\n",
    "[3] Sakurai, R., Nishida, M., Sakurai, H., Wakao, Y., Akashi, N., Kuniyoshi, Y., Minami, Y., & Nakajima, K. (2020). *Emulating a sensor using soft material dynamics: A reservoir computing approach to pneumatic artificial muscle*. 2020 3rd IEEE International Conference on Soft Robotics (RoboSoft), 710–717. https://doi.org/10.1109/RoboSoft48309.2020.9115974\n",
    "\n",
    "[4] Akashi, N., Yamaguchi, T., Tsunegi, S., Taniguchi, T., Nishida, M., Sakurai, R., Wakao, Y., & Nakajima, K. (2020). *Input-driven bifurcations and information processing capacity in spintronics reservoirs*. Physical Review Research, 2(4), 043303. https://doi.org/10.1103/PhysRevResearch.2.043303"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc-bootcamp (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
