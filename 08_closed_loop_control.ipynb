{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. RCにおける閉ループ制御"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章では、RCを用いた閉ループ制御について学びます。\n",
    "特にオフライン学習とオンライン学習の2つを学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前書き"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまで主に開ループ系、すなわち出力が入力に影響を与えない系を用いたRCの手法を扱いました。\n",
    "この章では**閉ループ系**、すなわち出力が入力に影響を与える設定を扱います。\n",
    "\n",
    "このような閉ループ系は歴史的には制御工学の文脈で登場し、したがって機械やロボットの制御との大きな関連があります。\n",
    "そして物理リザバー計算（PRC）でも、出力が環境やその系そのものに密接に相互作用している場合には不可避的に閉ループ系が登場し、その制御を考えなければなりません。\n",
    "例えば柔らかい魚ロボットの身体と環境に内在する情報処理能力を活用し、その制御を物理系上で実現する研究<sup>[1]</sup> では閉ループ制御による制御信号の埋め込みによって魚の動きが実現されています。\n",
    "ここではアクチュエータを介して魚の動きが生成され、環境とその身体形状に影響を及ぼし、リードアウト層に結合するセンサの値に影響を与える閉ループが構成されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定式化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRC以前にも、数値計算の形でESNを用いた閉ループ制御はこれまで多くの研究で実証されてきました。\n",
    "ここではこれまで扱われてきた以下のESNによる典型的な1入力1出力の開ループ系との対比で考えましょう。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]\\right)\\\\\n",
    "y[k] &= W^\\mathrm{out}[1 ; x[k]]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで $x[k]\\in \\mathbb{R}^N$ はESNの状態、$W^\\mathrm{in} \\in \\mathbb{R}^{N\\times 1}, W^\\mathrm{rec} \\in \\mathbb{R}^{N\\times N}, W^\\mathrm{out} \\in \\mathbb{R}^{1\\times (N+1)}$ は結合行列になります。\n",
    "特に $W^\\mathrm{out}$ は目標時系列 $d[k]$ を用いて $y[k]\\approx d[k]$ となるように学習されます。\n",
    "閉ループ制御では以下のような $W^\\mathrm{feed} \\in \\mathbb{R}^{N\\times 1}$ を加え出力 $y[k]$ がもう一度入力に作用します。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed} y[k] \\right)\\\\\n",
    "y[k] &= W^\\mathrm{out}[1 ; x[k]]\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "またタスクが入力時系列の置き換え、すなわち $d[k] = u[k+1]$ の場合は、$W^\\mathrm{in}$ を使用せずに以下のようになります。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{feed} y[k] \\right)\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで開ループ系と式はほとんど同じものの $W^\\mathrm{out}$ が系全体の性質を変更する点に注意ください。\n",
    "特にリードアウト層が線形な今回のケースでは、実質的にESNの内部結合が変化します（すなわち $\\rho W^\\mathrm{rec} + W^\\mathrm{feed} W^\\mathrm{out}$ ）。\n",
    "実際Full-FORCE<sup>[2]</sup> や、後の章で紹介される Innate training <sup>[3]</sup>と呼ばれる手法では、このような内部結合と閉ループの等価性を活用し様々な制御のESN上での埋め込みを実証しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オフライン学習とオンライン学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCにおける閉ループ制御、すなわち $W^\\mathrm{out}$ の学習方法は**オフライン学習**と**オンライン学習**に大別されます。\n",
    "オフライン学習はほとんど開ループ系の学習と同じで、線型回帰ないしはリッジ回帰によって達成されます。\n",
    "その際、正解データである $d(t)$ が直接ESNに投射され $x(t)$ の時系列を $W^\\mathrm{out}$ の学習に用いた後に評価フェーズで閉ループに切り替えられます。\n",
    "このような学習方法は **教師強制 (teacher forcing)** と呼ばれます。\n",
    "H. JaegerらによるRC最初の論文では、\n",
    "教師強制でサンプルされたデータを基に、ESNに接続した線形の閉ループ結合を学習し、 **カオス時系列データ** の予測に、他のニューラルネットワークを用いた手法と比してより高い精度で成功しています<sup>[4]</sup>。\n",
    "\n",
    "一方でオンライン学習は、逐次パラメータ $W^\\mathrm{out}$ を更新する学習方式を指します。\n",
    "このオンライン学習の手法の中で特にRCにおいて成功を収めたのがD. Sussilloらによって提唱されたFORCE（First-Order Reduced and Controlled Error）学習<sup>[5]</sup>です。\n",
    "FORCE 学習は、[再帰最小二乗（Recursive Least Squares; RLS）フィルター](https://en.wikipedia.org/wiki/Recursive_least_squares_filter) と呼ばれる適応フィルター（適応制御に登場する手法）のアルゴリズムを利用して線形閉ループを調整します。\n",
    "RLSフィルターを使用したオンライン学習は先述のH. Jaegerらによる論文で既に提案され実証されていますが、FORCE 学習の特異性はその使用されるネットワーク条件にあります。\n",
    "つまり、FORCE 学習では初期設定として **カオス ESN** が使用されます。\n",
    "これまで扱ったとおりESPが成り立たないカオスESNをリザバーとして使用するのは一見奇妙に見えるかもしれませんが、FORCE学習はシステムのカオス性をうまく活用し、カオス時系列を含む様々な目的のダイナミクスを設計できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題と実演"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同様、各種ライブラリおよび実装済みの関数の`import`を行うために次のセルを実行してください。なお内部実装を再確認するには、`import inspect`以下の行をコメントアウトするか`...?? / ??...`を使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    if False:  # Set to True if you want to use Google Drive and save your work there.\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "        %cd /content/gdrive/My Drive/rc-bootcamp/\n",
    "        # NOTE: Change it to your own path if you put the zip file elsewhere.\n",
    "        # e.g., %cd /content/gdrive/My Drive/[PATH_TO_EXTRACT]/rc-bootcamp/\n",
    "    else:\n",
    "        pass\n",
    "        %cd /content/\n",
    "        !git clone --branch ja https://github.com/rc-bootcamp/rc-bootcamp.git\n",
    "        %cd /content/rc-bootcamp/\n",
    "else:\n",
    "    sys.path.append(\".\")\n",
    "\n",
    "from utils.reservoir import ESN, Linear, RidgeReadout\n",
    "from utils.tester import load_from_chapter_name\n",
    "from utils.tqdm import trange\n",
    "from utils.viewer import (\n",
    "    construct_delayed_coord,\n",
    "    show_3d_coord,\n",
    "    show_delayed_coord,\n",
    "    show_record,\n",
    "    show_return_map,\n",
    "    show_trajectory,\n",
    ")\n",
    "\n",
    "test_func, show_solution = load_from_chapter_name(\"08_closed_loop_control\")\n",
    "\n",
    "# Uncomment it to see the implementations.\n",
    "# import inspect\n",
    "# print(inspect.getsource(Linear))\n",
    "# print(inspect.getsource(ReReadout))\n",
    "# print(inspect.getsource(ESN))\n",
    "\n",
    "# Or just use ??.../...?? (uncomment the following lines).\n",
    "# Linear??\n",
    "# RidgeReadout??\n",
    "# ESN??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 目標時系列の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず目標となる時系列を生成しましょう。\n",
    "今回はカオス時系列を用意し、閉ループ系を用いて最終的にESN上で目標時系列を自律的に生成させましょう。\n",
    "このようなタスクは「埋め込み」と呼ばれます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目標時系列 #1（ローレンツ系）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは前の章で実装したローレンツ系をルンゲ・クッタ法（RK4）で生成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chaos import lorenz_func, runge_kutta\n",
    "\n",
    "# Uncomment it to see the implementations.\n",
    "# runge_kutta??\n",
    "# lorenz_func??\n",
    "\n",
    "dt = 0.01\n",
    "time_steps = 20000\n",
    "z0 = np.array([1.0, 1.0, 1.0])\n",
    "lorenz_params = dict(a=10.0, b=28.0, c=8.0 / 3.0)\n",
    "lorenz_func_rk4 = runge_kutta(dt, lorenz_func, **lorenz_params)\n",
    "\n",
    "ds_lz = np.zeros((time_steps + 1, 3))\n",
    "ds_lz[0] = z0\n",
    "for idx in trange(time_steps):\n",
    "    ds_lz[idx + 1] = lorenz_func_rk4(ds_lz[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3次元座標上でローレンツ系の時系列を可視化しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_3d_coord(ds_lz)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各 $x(t), y(t), z(t)$ に対して時間遅れ座標 $(x(t), x(t + 10 \\Delta t))$ を表示し、同様に特徴的なdouble wingが見られるか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(\"xyz\"):\n",
    "    tau = 10\n",
    "    fig = show_delayed_coord(ds_lz[:, idx], tau=tau)\n",
    "    fig[0].set_title(r\"$\\left({{{}}}(t), {{{}}}(t+{{{}}}\\Delta t)\\right)$\".format(name, name, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この図は、部分的な観測からでも元の力学系に関する情報を再構築できる可能性を示唆しています ([Takensの埋め込み定理](https://en.wikipedia.org/wiki/Takens%27s_theorem)を参照)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目標時系列 #2（マッキー・グラス方程式）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H. Jaegerらによる最初の論文 <sup>[4]</sup>では、白血球細胞の生成過程をモデル化したマッキー・グラス（Mackey-Glass; MG）方程式<sup>[6]</sup>と呼ばれる**遅延微分方程式**を使用しています。\n",
    "遅延微分方程式は、現時点の状態のみならず過去の状態にもその導関数が依存するような微分方程式を指します。\n",
    "実際MG方程式は以下の式のような遅延項 $x(t-\\tau)$ を含んだ形で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\\\\n",
    "\\frac{dx}{dt}(t) = \\frac{\\beta x(t-\\tau)}{1 + x(t-\\tau)^{n}} - \\gamma x(t)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで $\\beta, \\gamma, n, \\tau$ はパラメータを表します。\n",
    "MG方程式は様々な領域でカオス的挙動が報告されており、実際H. Jaegerらは $\\beta=0.2, \\gamma=0.1, n=10, \\tau=17$ を採用しています。\n",
    "このMG方程式によって生成される時系列そのものは1次元であるものの、$t=t_0$ における値 $x(t_0)$ のみならず $t \\in [t_0 -\\tau, t_0]$ の情報がその後の求積（時間発展）には必要になり、この意味でMG方程式は無限次元力学系です。\n",
    "またより一般に遅延微分方程式は連続関数の空間を相空間とする無限次元力学系とみなせます。\n",
    "しかしながら、計算機上では無限の状態を保持できず、したがってMG方程式の計算には工夫が必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このような状況でよく用いられるのが履歴を状態とみなすテクニックです。\n",
    "いま時間幅 $\\Delta T$ を用いて$ [t_0-\\tau, t_0]$ を $N (\\in \\mathbb{N})$ 分割します（$ \\Delta T = \\tau / (N - 1) $）。\n",
    "このとき新たに $g(t) = [x(t-\\tau)\\quad  x(t-\\tau + \\Delta T) \\quad \\cdots \\quad x(t-\\Delta T) \\quad x(t)]^\\top \\in \\mathbb{R}^{N} $ を状態として定義します。\n",
    "すると上記の式は以下のとおり書けます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\\\\n",
    "\\frac{dx}{dt}(t) &= \\frac{dg_{N-1}}{dt}(t) \\\\\n",
    "&= \\frac{\\beta g_{0}(t)}{1 + g_{0}(t)^{n}} - \\gamma \\cdot g_{N-1}(t)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この式はRK4等で積分すると $x(t+\\Delta T)$ が求まります。\n",
    "あとは $g_{k}(t + \\Delta T) = g_{k+1} (t)$ によってずらせば解がえられます。\n",
    "この処理を実装してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.1.\n",
    "\n",
    "上記の説明を基に、MG方程式による時系列を生成する関数 `mackey_glass_func` と `sample_mg_dynamics` を完成させよ。\n",
    "\n",
    "- `mackey_glass_func`\n",
    "  - Argument(s):\n",
    "    - `gn`: `np.ndarray | float`\n",
    "    - `g0`: `np.ndarray | float`\n",
    "  - Return(s):\n",
    "    - `gn_dot`: `np.ndarray | float`\n",
    "\n",
    "- `sample_mg_dynamics`\n",
    "  - Argument(s):\n",
    "    - `time_steps`: `int`\n",
    "    - `tau`: `np.ndarray | float`\n",
    "    - `num_split`: `int`\n",
    "  - Return(s):\n",
    "    - `ts`: `np.ndarray`\n",
    "      - shape: `(time_steps,)`\n",
    "    - `out`: `np.ndarray`\n",
    "      - shape: `(time_steps, ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mackey_glass_func(gn, g0, beta: float = 0.2, gamma: float = 0.1, n: float = 10.0):\n",
    "    gn_dot = ...  # TODO\n",
    "    return gn_dot\n",
    "\n",
    "\n",
    "def sample_mg_dynamics(\n",
    "    time_steps: int,\n",
    "    tau: float,\n",
    "    num_split: int,\n",
    "    values_before_zero=lambda t: 0.5,\n",
    "    display=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    t_pre = np.linspace(-tau, 0, num_split)\n",
    "    dt = t_pre[1] - t_pre[0]\n",
    "    gs = [values_before_zero(t) for t in t_pre]\n",
    "\n",
    "    out = None\n",
    "    ts = np.arange(time_steps) * dt\n",
    "    for idx in trange(time_steps, display=display):\n",
    "        mg_func_rk4 = ...  # TODO Use `runge_kutta`.\n",
    "        # TODO Update `gs` using `mg_func_rk4`.\n",
    "        ...\n",
    "        if out is None:\n",
    "            out = np.zeros((time_steps, *gs[-1].shape))\n",
    "        out[idx] = gs[-1]\n",
    "    return ts, out\n",
    "\n",
    "\n",
    "test_func(sample_mg_dynamics, \"01_01\", multiple_output=True)\n",
    "# show_solution(\"01_01\", \"sample_mg_dynamics\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装した関数でMG方程式のダイナミクスを描画しましょう。\n",
    "以下のセルは時間遅れ座標 $(x(t), x(t-\\tau))$ を描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 17.0\n",
    "dt = 1.0\n",
    "num_split = int(tau // dt + 1)\n",
    "time_steps = 20000\n",
    "\n",
    "ts, ds_mg = sample_mg_dynamics(time_steps, tau, num_split, lambda t: 0.5)\n",
    "\n",
    "fig = show_delayed_coord(ds_mg, tau=num_split - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3次元の時間遅れ座標 $(x(t), x(t-\\tau), x(t-2\\tau))$ だとどうなるでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = construct_delayed_coord(ds_mg[10000:], num_split - 1, 3)\n",
    "fig = show_3d_coord(data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.3. (Advanced)\n",
    "\n",
    "- MG方程式の各種パラメータに関して分岐図を書け。\n",
    "- 時間幅が可変な求積法も存在する。このような状況で今回のようなテクニックは使用できない。遅延微分方程式の求積方法に関して調査し、Pythonで実装せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. オフライン学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目標となる時系列データが用意できたのでオフライン学習を実装をしましょう。\n",
    "まずは閉ループと開ループを切り替え、ESNの状態の時系列をサンプルする関数を実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.1.\n",
    "\n",
    "以下の空欄を埋め、開ループと閉ループと切り替えESNの時系列を記録する `emulate_offline` を完成させよ。\n",
    "ただし $k\\in[t_0, t_1)$ のときは開ループ系 $x[k+1]=f(x[k], d[k])$、それ以外のときは閉ループ系 $x[k+1]=f(x[k],W^\\mathrm{out} x[k])$ を使用する。\n",
    "\n",
    "- `emulate_offline`:\n",
    "  - Argument(s):\n",
    "    - `time_steps`: `int`\n",
    "      - $T$\n",
    "    - `x0`: `np.ndarray`\n",
    "      - $x[0]$\n",
    "    - `net`: `ESN`\n",
    "    - `w_feed`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{feed}$\n",
    "    - `w_out`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{out}$\n",
    "    - `ds`: `np.ndarray`\n",
    "      - $[d[0], d[1],~\\ldots]$\n",
    "    - `open_range`: `tuple(int, int)`\n",
    "      - $[t_\\mathrm{b}, t_\\mathrm{e})$\n",
    "  - Return(s):\n",
    "    - `record`: `dict`\n",
    "      - `'t'`: `np.ndarray`\n",
    "        - $[0, 1,~\\ldots,~T-1, T]$\n",
    "      - `'x'`: `np.ndarray`\n",
    "        - $[x[0], x[1],~\\ldots,~x[T-1], x[T]]$\n",
    "      - `'y'`: `np.ndarray`\n",
    "        - $[y[0], y[1],~\\ldots,~y[T-1]]$\n",
    "\n",
    "<details><summary>tips</summary>\n\n",
    "- `ds` が `None` かつ $k \\in [t_\\mathrm{b}, t_\\mathrm{e})$ の場合、出力 `y` をシステムにフィードバックする。\n",
    "- それ以外の場合は、`ds[idx]` を使用する。\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate_offline(\n",
    "    time_steps,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_out,\n",
    "    ds=None,\n",
    "    open_range=None,\n",
    "    label=None,\n",
    "    display=True,\n",
    "):\n",
    "    open_range = open_range if open_range is not None else [0, 0]\n",
    "    record = {}\n",
    "    record[\"t\"] = np.arange(0, time_steps + 1)\n",
    "    record[\"x\"] = np.zeros((time_steps + 1, *x0.shape))\n",
    "    record[\"y\"] = np.zeros((time_steps, *w_out(x0).shape))\n",
    "    record[\"open_range\"] = open_range\n",
    "    x = x0\n",
    "    record[\"x\"][0] = x0\n",
    "    pbar = trange(time_steps, display=display)\n",
    "    for idx in pbar:\n",
    "        if label is not None:\n",
    "            pbar.set_description(label)\n",
    "        if (ds is not None) and (idx < len(ds)) and (open_range[0] <= idx < open_range[1]):\n",
    "            y = ...  # TODO Training phase (i.e., teacher forcing by `ds`)\n",
    "        else:\n",
    "            y = ...  # TODO Evaluation phase (i.e., autonomous closed-loop mode by `w_out`)\n",
    "        x = ...  # TODO Implement x[k + 1] = f(x[k], y[k])\n",
    "        record[\"x\"][idx + 1] = x\n",
    "        record[\"y\"][idx] = y\n",
    "    return record\n",
    "\n",
    "\n",
    "def solution(*args, **kwargs):\n",
    "    record = emulate_offline(*args, **kwargs)\n",
    "    return record[\"x\"], record[\"y\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"02_01\", multiple_output=True)\n",
    "# show_solution(\"02_01\", \"emulate_offline\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装した `emulate_offline` を用いて時系列を収集し、そのデータを基に $W^\\mathrm{out}$ を学習しましょう。\n",
    "以下の設問はそのような処理を実現する関数 `run_train_and_eval` を実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.2.\n",
    "\n",
    "以下の空欄を埋め、開ループ系における教師強制によるサンプリングと、閉ループ系における評価を実施する `run_train_and_eval` を実装せよ。\n",
    "\n",
    "- `run_train_and_eval`:\n",
    "  - Argument(s):\n",
    "    - `t_washout, t_train, t_eval`: `int`\n",
    "      - $T_\\mathrm{washout}, T_\\mathrm{train}, T_\\mathrm{eval}$\n",
    "    - `x0`: `np.ndarray`\n",
    "      - $x[0]$\n",
    "    - `net`: `ESN`\n",
    "    - `w_feed`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{feed}$\n",
    "    - `w_out`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{out}$\n",
    "    - `ds`: `np.ndarray`\n",
    "      - $[d[0], d[1],~\\ldots]$\n",
    "\n",
    "  - Return(s):\n",
    "    - `record_t`: `dict`\n",
    "      - 学習フェーズにおける時系列\n",
    "    - `record_e`: `dict`\n",
    "      - 評価フェーズにおける時系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_and_eval(t_washout, t_train, t_eval, x0, net, w_feed, w_out, ds, display=True):\n",
    "    # Training phase (open loop)\n",
    "    record_t = emulate_offline(\n",
    "        t_washout + t_train,\n",
    "        x0,\n",
    "        net,\n",
    "        w_feed,\n",
    "        w_out,\n",
    "        ds,\n",
    "        open_range=[0, t_washout + t_train],\n",
    "        label=\"Train\",\n",
    "        display=display,\n",
    "    )\n",
    "\n",
    "    # Run ridge regression and update of the weight\n",
    "    x_train = ...  # TODO t \\in [t_washout, t_washout + t_train)\n",
    "    y_train = ...  # TODO t \\in [t_washout, t_washout + t_train)\n",
    "    y_eval = ds[t_washout + t_train : t_washout + t_train + t_eval]\n",
    "    w_out.train(x_train, y_train)\n",
    "\n",
    "    # Evaluation phase (closed loop)\n",
    "    x1 = np.array(record_t[\"x\"][-1])\n",
    "    record_e = emulate_offline(t_eval, x1, net, w_feed, w_out, label=\"Eval\", display=display)\n",
    "    record_e[\"d\"] = y_eval\n",
    "    return record_t, record_e\n",
    "\n",
    "\n",
    "def solution(*args, **kwargs):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    _record_t, record_e = run_train_and_eval(*args, **kwargs)\n",
    "    return record_e[\"x\"], record_e[\"y\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"02_02\", multiple_output=True)\n",
    "# show_solution(\"02_02\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非カオスESNを用いたデモンストレーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからは実際に生成した目標時系列を非カオスESNを用いて埋め込みます。\n",
    "まずはローレンツ系の予測をスペクトル半径 $\\rho=0.1$ のESNを用いて行います。\n",
    "このときリードアウト層の出力次元が3である点に注意ください（`out_dim = 3`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 3\n",
    "t_washout, t_train, t_eval = 2000, 8000, 5000\n",
    "\n",
    "net = ESN(net_dim, sr=0.1, p=0.01, a=None, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=1.0, bias=0.2, rnd=rnd)\n",
    "w_out = RidgeReadout(\n",
    "    net_dim, out_dim, lmbd=0, rnd=rnd\n",
    ")  # Set positive value to alpha (e.g., alpha=1e-6) if output is unstable.\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "ds = (ds_lz * 0.01)[:, :out_dim]\n",
    "rec_lz_t, rec_lz_e = run_train_and_eval(t_washout, t_train, t_eval, x0, net, w_feed, w_out, ds)\n",
    "\n",
    "fig_t = show_record(rec_lz_t, [\"x\", \"y\"])\n",
    "fig_t[0].set_title(\"Training\")\n",
    "fig_e = show_record(rec_lz_e, [\"x\", \"y\"])\n",
    "fig_e[0].set_title(\"Evaluation\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ローレンツ系の埋め込みが成功したかどうかを定性的に評価するため、3次元座標のでアトラクタの形と、リターンマップを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_return_map(output=rec_lz_e[\"y\"][:, 2], desired=rec_lz_e[\"d\"][:, 2])\n",
    "\n",
    "fig = show_3d_coord(output=rec_lz_e[\"y\"], desired=rec_lz_e[\"d\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度はMG方程式による時間遅れ時系列をスペクトル半径 $\\rho=0.9$ のESNに埋め込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 1\n",
    "t_washout, t_train, t_eval = 2000, 8000, 5000\n",
    "\n",
    "net = ESN(net_dim, sr=0.9, p=0.01, a=None, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=0.5, bias=0.5, rnd=rnd)\n",
    "w_out = RidgeReadout(\n",
    "    net_dim, out_dim, lmbd=0, rnd=rnd\n",
    ")  # Set positive value to alpha (e.g., alpha=1e-6) if output is unstable.\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "ds = (ds_mg - 1.0)[:, None]\n",
    "rec_mg_t, rec_mg_e = run_train_and_eval(t_washout, t_train, t_eval, x0, net, w_feed, w_out, ds)\n",
    "\n",
    "fig_t = show_record(rec_mg_t, [\"x\", \"y\"])\n",
    "fig_t[0].set_title(\"Training\")\n",
    "fig_e = show_record(rec_mg_e, [\"x\", \"y\"])\n",
    "fig_e[0].set_title(\"Evaluation\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遅延遅れ座標系を構成し、目標軌道と合わせて3次元座標系上に表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = construct_delayed_coord(rec_mg_e[\"y\"], 17, 3)\n",
    "data2 = construct_delayed_coord(rec_mg_e[\"d\"], 17, 3)\n",
    "fig = show_3d_coord(output=data1, desired=data2)\n",
    "fig.show()\n",
    "# fig = show_return_map(output=rec_mg_e['y'][:, 0], desired=rec_mg_e['d'][:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ローレンツ系、MG方程式いずれのケースも、ESNが自律的に生成できる様子が確認できると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.2. (Advanced)\n",
    "\n",
    "- $\\rho$ や他のパラメータを変え学習の安定性を調査せよ。\n",
    "- カオス時系列は初期値鋭敏性を有するため、仮に高い精度でアトラクタの構成に成功しても目標時系列との差分が指数的に拡大してしまい MSE等の指標が使えない。\n",
    "埋め込みの可否を定量的に評価する指標を考え実装せよ。\n",
    "- 1次元のみの時系列からのローレンツ系の埋め込みを試し（`out_dim = 1`に変更せよ）、学習がうまく行くパラメータのセットを探せ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カオスESNを用いたデモンストレーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでは非カオスESN（$\\rho<1$）を用いてオフライン学習を行いました。\n",
    "カオスESNの場合はどうなるか検証しましょう。\n",
    "以下のセルは先ほどとほぼ同じですが $\\rho$ のみが $1.5$ に変更されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 3\n",
    "t_washout, t_train, t_eval = 2000, 8000, 5000\n",
    "\n",
    "net = ESN(net_dim, sr=1.5, p=0.01, a=None, rnd=rnd)  # Spectral radius 1.5\n",
    "w_feed = Linear(out_dim, net_dim, bound=1.0, bias=0.2, rnd=rnd)\n",
    "w_out = RidgeReadout(\n",
    "    net_dim, out_dim, lmbd=0, rnd=rnd\n",
    ")  # Set positive value to alpha (e.g., alpha=1e-6) if output is unstable.\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "ds = (ds_lz * 0.01)[:, :out_dim]\n",
    "rec_lz_t, rec_lz_e = run_train_and_eval(t_washout, t_train, t_eval, x0, net, w_feed, w_out, ds)\n",
    "\n",
    "fig_t = show_record(rec_lz_t, [\"x\", \"y\"])\n",
    "fig_t[0].set_title(\"Training\")\n",
    "fig_e = show_record(rec_lz_e, [\"x\", \"y\"])\n",
    "fig_e[0].set_title(\"Evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3次元座標上でのアトラクタの形を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_3d_coord(output=rec_lz_e[\"y\"], desired=rec_lz_e[\"d\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧のとおり、$\\rho < 1$ のケースよりもうまくいっていない様子が見て取れます（`seed`や他のパラメータを変えて試して見てください）。\n",
    "一般にオフライン学習の場合、カオスESNを用いた学習が一般に困難である場合が多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. オンライン学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度はオンライン学習を実装してみましょう。\n",
    "特にここではFORCE学習ならびにその背後で使用されるRLSアルゴリズムを実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RLSアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずRLSアルゴリズムを実装します。\n",
    "RLSアルゴリズムは非常に収束性が高い適応フィルタの一種として知られ以下の一連の式で表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\\\\n",
    "k &= P x \\\\\n",
    "g &= \\frac{1}{1+x^\\top k} \\\\\n",
    "\\Delta P &= g k k^\\top \\\\\n",
    "\\Delta w^{\\mathrm{out}} &= g (d - y) k^\\top \\\\\n",
    "P &\\leftarrow P - \\Delta P \\\\\n",
    "w^\\mathrm{out} &\\leftarrow w^\\mathrm{out} + \\Delta w^\\mathrm{out}\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、$P \\in \\mathbb{R}^{N\\times N}$ は正定値行列、$y, d$ はそれぞれシステム出力と目的出力、$x$ はシステムの状態です。\n",
    "RLSアルゴリズムは、$P(0)$ の初期値を $I/\\lambda$ に設定すると、正則化項 $\\lambda$ を使用したリッジ回帰と同等になります。\n",
    "すなわち以下の式として表現されます。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\\\\n",
    "P[T]&=\\left(\\sum_{k=1}^{T} {x}[k]{x}^{\\top}[k] + \\lambda I\\right)^{-1} \\\\\n",
    "&=\\left(X^\\top X + \\lambda I\\right)^{-1}\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、$X=[{x}^\\top[1]; x^\\top[1]; \\cdots x^\\top[T]]\\in \\mathbb{R}^{T\\times N}$ は学習データです。\n",
    "RLS アルゴリズムでは、[シャーマン・モリソンの公式 (ウッドベリー行列恒等式の特殊系) ](https://en.wikipedia.org/wiki/Woodbury_matrix_identity) を利用して、この逆行列の更新を効率的に計算します。\n",
    "以下の式で $A=P^{-1}, B=x, C=x^\\top, D=1$ を代入して上記の式の正しさを確認してください。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(A+BDC)^{-1} = A^{-1} - A^{-1}B(D^{-1}+CA^{-1}B)^{-1}CA^{-1}\n",
    ".\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "制御工学になれ親しんだ方はこのRLSの更新式が、カルマンフィルタのそれとよく似ている点に気が付かれるでしょう。\n",
    "実際RLSアルゴリズムもカルマンフィルタもどちらも推定アルゴリズムの一種であり、いくつかの前提条件によりカルマンフィルタの特殊系としてRLSアルゴリズムは位置づけられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "またFORCE学習は、その名前のとおり「1次の制御された誤差（First-Order Reduced and Controlled Error）」が制御されます。\n",
    "RLSアルゴリズムによる更新前の誤差と更新後の誤差をそれぞれ $e^-[t], e^+[t]$としたとき、FORCE学習では常に $|e^+[t]|<|e^-[t]|$ に、また $e^+[t]/e^-[t]\\to 1~(t \\gg 1)$ になるように重みが制御されます。\n",
    "その収束性に関わらず、このような条件を満たす学習アルゴリズムであればFORCE学習に当てはまります<sup>[5]</sup>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.1.\n",
    "\n",
    "上記の説明を基に、FORCE学習ならびにRLSアルゴリズムによって重みを逐次更新する線形層のクラス `FORCEReadout` を実装せよ。\n",
    "\n",
    "- `rls_update`\n",
    "  - Argument(s)\n",
    "    - `P`: `np.ndarray`\n",
    "      - `shape`: `(n, n)`\n",
    "      - `dtype`: `np.float64`\n",
    "    - `x`: `np.ndarray`\n",
    "      - `shape`: `(n,)`\n",
    "      - `dtype`: `np.float64`\n",
    "  - Return(s)\n",
    "    - `g`: `np.ndarray`\n",
    "      - `shape`: `()`\n",
    "      - `dtype`: `np.float64`\n",
    "    - `k`: `np.ndarray`\n",
    "      - `shape`: `(..., 1, n)`\n",
    "      - `dtype`: `np.float64`\n",
    "    - `P_new`: `np.ndarray`\n",
    "      - `shape`: `(..., n, n)`\n",
    "      - `dtype`: `np.float64`\n",
    "\n",
    "- `FORCEReadout.step`\n",
    "  - Argument(s)\n",
    "    - `x`: `np.ndarray`\n",
    "    - `d`: `np.ndarray`\n",
    "  - Return(s)\n",
    "    - `dws`: `np.ndarray`\n",
    "\n",
    "  - Operation(s)\n",
    "    - `rls_update`を用いた`ForceReadout.P`の更新\n",
    "    - `FORCEReadout.weight` の更新\n",
    "\n",
    "<details><summary>tips</summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rls_update(P, x):\n",
    "    k = ...  # TODO\n",
    "    g = ...  # TODO\n",
    "    dP = ...  # TODO\n",
    "    P_new = ...  # TODO\n",
    "    return g, k, P_new\n",
    "\n",
    "\n",
    "class FORCEReadout(Linear):\n",
    "    def __init__(self, *args, lmbd=1.0, initialize_with_zero=True, **kwargs):\n",
    "        super(FORCEReadout, self).__init__(*args, **kwargs)\n",
    "        self.P = ...  # TODO Create initial value of P.\n",
    "        if initialize_with_zero:\n",
    "            self.weight[:] = 0\n",
    "            self.bias[:] = 0\n",
    "\n",
    "    def step(self, x, d):\n",
    "        assert x.ndim == 1\n",
    "        e = d - self(x)\n",
    "        g, k, P_new = ...  # TODO Use `rls_update`.\n",
    "        dw = ...  # TODO Calculate `dw`.\n",
    "        self.P = P_new\n",
    "        self.weight += dw\n",
    "        return dw\n",
    "\n",
    "\n",
    "def solution(dim_in, dim_out, x_train, y_train, x_eval):\n",
    "    # DO NOT CHANGE HERE.\n",
    "    readout = FORCEReadout(dim_in, dim_out)\n",
    "    readout.step(x_train, y_train)\n",
    "    return readout(x_eval)\n",
    "\n",
    "\n",
    "test_func(solution, \"03_01\")\n",
    "# show_solution(\"03_01\", \"rls_update\")  # Uncomment it to see the solution.\n",
    "# show_solution(\"03_01\", \"FORCEReadout\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FORCE学習による重みの更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にFORCE学習によって重みを更新する関数を実装しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.2.\n",
    "\n",
    "以下の空欄を埋め、FORCE学習によって $W^\\mathrm{out}$ を時々刻々更新する `emulate_online` を完成させよ。\n",
    "ただし $k\\in[t_0, t_1) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every}) $ のときに $W^\\mathrm{out}$ を更新、それ以外のときは変更しない。\n",
    "\n",
    "- `emulate_offline`:\n",
    "  - Argument(s):\n",
    "    - `time_steps`: `int`\n",
    "      - $T$\n",
    "    - `x0`: `np.ndarray`\n",
    "      - $x[0]$\n",
    "    - `net`: `ESN`\n",
    "    - `w_feed`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{feed}$\n",
    "    - `w_out`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{out}$\n",
    "    - `ds`: `np.ndarray`\n",
    "      - $[d[0], d[1], \\ldots]$\n",
    "    - `force_every`: `int`\n",
    "      - $t_\\mathrm{every}$\n",
    "    - `train__range`: `tuple(int, int)`\n",
    "      - $[t_\\mathrm{b}, t_\\mathrm{e})$\n",
    "  - Return(s):\n",
    "    - `record`: `dict`\n",
    "      - `'t'`: `np.ndarray`\n",
    "        - $[0, 1, \\ldots, T-1, T]$\n",
    "      - `'x'`: `np.ndarray`\n",
    "        - $[x[0], x[1], \\ldots, x[T-1], x[T]]$\n",
    "      - `'y'`: `np.ndarray`\n",
    "        - $[y[0], y[1], \\ldots, y[T-1]]$\n",
    "      - `'d'`: `np.ndarray`\n",
    "        - $[d[0], d[1], \\ldots, d[T-1]]$\n",
    "      - `'w'`: `np.ndarray`\n",
    "        - $[W^\\mathrm{out}[0], W^\\mathrm{out}[1], \\ldots, W^\\mathrm{out}[T-1], W^\\mathrm{out}[T]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate_online(\n",
    "    time_steps,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_out,\n",
    "    ds=None,\n",
    "    train_range=None,\n",
    "    force_every=1,\n",
    "    display=True,\n",
    "):\n",
    "    train_range = train_range if train_range is not None else [0, 0]\n",
    "    record = {}\n",
    "    record[\"t\"] = np.arange(0, time_steps + 1)\n",
    "    record[\"x\"] = np.zeros((time_steps + 1, *x0.shape))\n",
    "    record[\"y\"] = np.zeros((time_steps, *w_out(x0).shape))\n",
    "    record[\"d\"] = np.zeros((time_steps, *w_out(x0).shape))\n",
    "    record[\"w\"] = np.zeros((time_steps + 1, *w_out.weight.shape))\n",
    "    record[\"train_range\"] = train_range\n",
    "\n",
    "    x = x0\n",
    "    record[\"x\"][0] = x0\n",
    "    record[\"w\"][0] = w_out.weight\n",
    "    pbar = trange(time_steps, display=display)\n",
    "    for idx in pbar:\n",
    "        y = ...  # TODO Implement y[k] = w^out x[k].\n",
    "        d = ds[idx] if (ds is not None) and (idx < len(ds)) else 0.0\n",
    "        if idx % force_every == 0 and (train_range[0] <= idx < train_range[1]):\n",
    "            dws = ...  # TODO Update weight.\n",
    "            pbar.set_description(\"|ΔW|={:.3e}\".format(np.linalg.norm(dws)))\n",
    "        x = ...  # TODO Implement x[k + 1] = f(x[k], y[k])\n",
    "        record[\"x\"][idx + 1] = x\n",
    "        record[\"y\"][idx] = y\n",
    "        record[\"d\"][idx] = d\n",
    "        record[\"w\"][idx + 1] = w_out.weight\n",
    "    return record\n",
    "\n",
    "\n",
    "def solution(time_steps, x0, net, w_feed, dim, dim_in, **kwargs):\n",
    "    w_out = FORCEReadout(dim, dim_in)\n",
    "    record = emulate_online(time_steps, x0, net, w_feed, w_out, **kwargs)\n",
    "    return record[\"x\"], record[\"y\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"03_02\", multiple_output=True)\n",
    "# show_solution(\"03_02\", \"emulate_online\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 周期関数の埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは元論文<sup>[5]</sup>と同様に周期関数の埋め込みを試しましょう。\n",
    "以下の式で表される目標時系列を用意します。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\\\\n",
    "d(t) =\n",
    "\\frac{2}{3} \\sin\\left(\\frac{\\pi t}{T}\\right) +\n",
    "\\frac{1}{3} \\sin\\left(\\frac{2\\pi t}{T}\\right) +\n",
    "\\frac{1}{9} \\sin\\left(\\frac{3\\pi t}{T}\\right) +\n",
    "\\frac{2}{9} \\sin\\left(\\frac{4\\pi t}{T}\\right)\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし $T=60$ です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 20000, 20001)\n",
    "\n",
    "amps = [2 / 3, 1 / 3, 1 / 9, 2 / 9]\n",
    "freqs = [1.0, 2.0, 3.0, 4.0]\n",
    "\n",
    "ds_p = np.zeros_like(ts)\n",
    "for a, f in zip(amps, freqs, strict=True):\n",
    "    ds_p += a * np.sin(f * np.pi * ts / 60)\n",
    "ds_p = ds_p / 1.5\n",
    "\n",
    "fig = show_trajectory(ds_p[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほど学習に失敗したネットワークと同じ重み行列で、漏れ率  $a=0.1$ を加えたリーキーESNを用意します。\n",
    "出力されるグラフのうちピンク色の領域において、FORCE学習によって $W^\\mathrm{out}$ が更新されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 1\n",
    "\n",
    "net = ESN(net_dim, sr=1.5, p=0.01, a=0.1, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=5.0, bias=0.2, rnd=rnd)\n",
    "w_out = FORCEReadout(net_dim, out_dim, lmbd=0.1, rnd=rnd, initialize_with_zero=True)\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "t_total = 5000\n",
    "train_range = [1000, 4000]\n",
    "force_every = 2\n",
    "\n",
    "record_t = emulate_online(\n",
    "    t_total,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_out,\n",
    "    ds=ds_p,\n",
    "    force_every=force_every,\n",
    "    train_range=train_range,\n",
    ")\n",
    "fig = show_record(record_t, [\"x\", \"y\", \"dw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的の軌道をどれだけうまく出力されているかを時間遅れ座標で確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(record_t[\"x\"][-1])\n",
    "record_e = emulate_online(1000, x1, net, w_feed, w_out, ds=ds_p[t_total:])\n",
    "fig = show_delayed_coord(record_e[\"y\"][:, 0], record_e[\"d\"][:, 0], tau=10, labels=[\"output\", \"desired\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ローレンツ系の埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に、同じパラメータのネットワークでローレンツ系の埋め込みを試しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 3\n",
    "\n",
    "net = ESN(net_dim, sr=1.5, p=0.01, a=0.1, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=5.0, bias=0.2, rnd=rnd)\n",
    "w_out = FORCEReadout(net_dim, out_dim, lmbd=0.1, rnd=rnd, initialize_with_zero=True)\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "t_total = 5000\n",
    "train_range = [1000, 4000]\n",
    "force_every = 2\n",
    "\n",
    "ds = ds_lz[:, :out_dim] * 0.01\n",
    "record_t = emulate_online(\n",
    "    t_total,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_out,\n",
    "    ds=ds,\n",
    "    force_every=force_every,\n",
    "    train_range=train_range,\n",
    ")\n",
    "fig = show_record(record_t, [\"x\", \"y\", \"dw\"])\n",
    "\n",
    "x1 = np.array(record_t[\"x\"][-1])\n",
    "record_e = emulate_online(10000, x1, net, w_feed, w_out, ds=ds[t_total:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じく3次元座標上でアトラクタの形を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_3d_coord(output=record_e[\"y\"], desired=record_e[\"d\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は同じESNパラメータでローレンツアトラクターの一部だけを提示してうまく表示できるか試しましょう（`out_dim=1`）。\n",
    "時間遅れにより3次元表示を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 1  # NOTE 3 to 1\n",
    "\n",
    "net = ESN(net_dim, sr=1.5, p=0.01, a=0.1, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=10.0, bias=0.5, rnd=rnd)\n",
    "w_out = FORCEReadout(net_dim, out_dim, lmbd=0.1, rnd=rnd, initialize_with_zero=True)\n",
    "x0 = rnd.uniform(-1, 1, net_dim)\n",
    "\n",
    "t_total = 7000\n",
    "train_range = [1000, 6000]\n",
    "force_every = 2\n",
    "\n",
    "ds = ds_lz[:, :out_dim] * 0.01\n",
    "record_t = emulate_online(\n",
    "    t_total,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_out,\n",
    "    ds=ds,\n",
    "    force_every=force_every,\n",
    "    train_range=train_range,\n",
    ")\n",
    "fig = show_record(record_t, [\"x\", \"y\", \"dw\"])\n",
    "\n",
    "x1 = np.array(record_t[\"x\"][-1])\n",
    "record_e = emulate_online(10000, x1, net, w_feed, w_out, ds=ds[t_total:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遅延遅れ座標形状でのアトラクタの形を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = construct_delayed_coord(record_e[\"y\"], 10, 3)\n",
    "data2 = construct_delayed_coord(record_e[\"d\"], 10, 3)\n",
    "fig = show_3d_coord(output=data1, desired=data2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 複数のアトラクタの埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じESNに複数のアトラクターを埋め込めます。\n",
    "以下の設問では複数のアトラクタに対して学習できるように `emulate_online` を拡張した `emulate_parallel` を実装しましょう。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "{x}[k+1] &= (1-a){x}[k]+a\\tanh\\left(\\rho W^\\text{rec} {x}[k] + W^\\mathrm{feed}{y}[k] + W^\\mathrm{in} u[k]\\right)\\\\\n",
    "{y}[k] &= W^{\\text{out}} {x}[k]\n",
    ",\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、$u$ は制御パラメータ、$W^\\mathrm{in} \\in \\mathbb{R}^{N}$ は $u$ をESNに投影する行列です。\n",
    "それぞれ $u=-1$ と $u=1$ に設定したときに、同じ線形重みで、ローレンツ アトラクターと [L. Choingxinら<sup>[6]</sup>](https://www.sciencedirect.com/science/article/pii/S0960077904005909) によって提案された別の蝶型アトラクターを出力する閉ループ系を設計してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.3.\n",
    "\n",
    "以下の空欄を埋め、FORCE学習によって **複数提示された** $d(t)$ に対して$W^\\mathrm{out}$ を時々刻々更新する `emulate_parallel` を完成させよ。\n",
    "ただし $k\\in[t_0, t_1) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every}) $ のときに $W^\\mathrm{out}$ を更新、それ以外のときは変更はない。\n",
    "\n",
    "- `emulate_parallel`:\n",
    "  - Argument(s):\n",
    "    - `time_steps`: `int`\n",
    "      - $T$\n",
    "    - `x0`: `np.ndarray`\n",
    "      - $x[0]$\n",
    "    - `net`: `ESN`\n",
    "    - `w_feed`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{feed}$\n",
    "    - `w_out`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{out}$\n",
    "    - `w_in`: `Linear | RidgeReadout`\n",
    "      - $W^\\mathrm{in}$\n",
    "    - `ds`: `np.ndarray`\n",
    "      - `shape`: `(t, k, dim_out)`\n",
    "      - $[d[0], d[1],~\\ldots]$\n",
    "    - `us`: `np.ndarray`\n",
    "      - `shape`: `(t, k, dim_in)`\n",
    "      - $[u[0], u[1],~\\ldots]$\n",
    "    - `force_every`: `int`\n",
    "      - $t_\\mathrm{every}$\n",
    "    - `train__range`: `tuple(int, int)`\n",
    "      - $[t_0, t_1)$\n",
    "  - Return(s):\n",
    "    - `record`: `dict`\n",
    "      - `'t'`: `np.ndarray`\n",
    "        - $[0, 1, \\ldots, T-1, T]$\n",
    "      - `'x'`: `np.ndarray`\n",
    "        - $[x[0], x[1], \\ldots, x[T-1], x[T]]$\n",
    "      - `'y'`: `np.ndarray`\n",
    "        - $[y[0], y[1], \\ldots, y[T-1]]$\n",
    "      - `'d'`: `np.ndarray`\n",
    "        - $[d[0], d[1], \\ldots, d[T-1]]$\n",
    "      - `'w'`: `np.ndarray`\n",
    "        - $[W^\\mathrm{out}[0], W^\\mathrm{out}[1], \\ldots, W^\\mathrm{out}[T-1], W^\\mathrm{out}[T]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate_parallel(\n",
    "    time_steps,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_in,\n",
    "    w_out,\n",
    "    ds=None,\n",
    "    us=None,\n",
    "    train_range=None,\n",
    "    force_every=1,\n",
    "    display=True,\n",
    "):\n",
    "    train_range = train_range if train_range is not None else [0, 0]\n",
    "    record = {}\n",
    "    record[\"t\"] = np.arange(0, time_steps + 1)\n",
    "    record[\"x\"] = np.zeros((time_steps + 1, *x0.shape))\n",
    "    record[\"y\"] = np.zeros((time_steps, *w_out(x0).shape))\n",
    "    record[\"d\"] = np.zeros((time_steps, *w_out(x0).shape))\n",
    "    record[\"w\"] = np.zeros((time_steps + 1, *w_out.weight.shape))\n",
    "    record[\"train_range\"] = train_range\n",
    "\n",
    "    x = x0\n",
    "    record[\"x\"][0] = x0\n",
    "    record[\"w\"][0] = w_out.weight\n",
    "    pbar = trange(time_steps, display=display)\n",
    "    for idx in pbar:\n",
    "        y = ...  # TODO Implement y[k] = w^out x[k].\n",
    "        d = ds[idx] if (ds is not None) and (idx < len(ds)) else 0.0\n",
    "        u = us[idx] if (us is not None) and (idx < len(us)) else 0.0\n",
    "        if idx % force_every == 0 and (train_range[0] <= idx < train_range[1]):\n",
    "            if x.ndim == 1:\n",
    "                dws = ...  # TODO Implement weight update for 1D case.\n",
    "            elif x.ndim == 2:\n",
    "                dws = []\n",
    "                for idy in range(x.shape[0]):\n",
    "                    out = ...  # TODO Implement weight update for 2D case.\n",
    "                    dws.append(out)\n",
    "            pbar.set_description(\"|ΔW|={:.3e}\".format(np.linalg.norm(dws)))\n",
    "        x = ...  # TODO Implement x[k + 1] = f(x[k], y[k], u[k])\n",
    "        record[\"x\"][idx + 1] = x\n",
    "        record[\"y\"][idx] = y\n",
    "        record[\"d\"][idx] = d\n",
    "        record[\"w\"][idx + 1] = w_out.weight\n",
    "    return record\n",
    "\n",
    "\n",
    "def solution(time_steps, x0, net, w_feed, w_in, dim, dim_in, **kwargs):\n",
    "    w_out = FORCEReadout(dim, dim_in)\n",
    "    record = emulate_parallel(time_steps, x0, net, w_feed, w_in, w_out, **kwargs)\n",
    "    return record[\"x\"], record[\"y\"]\n",
    "\n",
    "\n",
    "test_func(solution, \"03_03\", multiple_output=True)\n",
    "# show_solution(\"03_03\", \"emulate_parallel\")  # Uncomment it to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chongxin_func` は以下の微分方程式を実装しています。\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d x_1}{d t} &= a(x_2 - x_1) \\\\\n",
    "\\frac{d x_2}{d t} &= b x_1 - k x_1 x_3 \\\\\n",
    "\\frac{d x_3}{d t} &= - c x_3 + h x_1^2\n",
    ".\\end{align*}\n",
    "$$\n",
    "\n",
    "この微分方程式を時間発展させると、次のセルで表示されるようにローレンツ系の蝶形構造の中央に渦が追加されるような軌跡が描かれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chaos import chongxin_func\n",
    "\n",
    "# Uncomment it to see the implementations.\n",
    "# chongxin_func??\n",
    "\n",
    "dt = 0.01\n",
    "time_steps = 20000\n",
    "z0 = np.array([1.0, 1.0, 1.0])\n",
    "chongxin_params = dict(a=10.0, b=28.0, c=8.0 / 3.0, k=1, h=4)\n",
    "chongxin_func_rk4 = runge_kutta(dt, chongxin_func, **chongxin_params)\n",
    "\n",
    "ds_cx = np.zeros((time_steps + 1, 3))\n",
    "ds_cx[0] = z0\n",
    "for idx in trange(time_steps):\n",
    "    ds_cx[idx + 1] = chongxin_func_rk4(ds_cx[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算が完了したら、3次元座標上でアトラクタの形を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_3d_coord(lorenz=ds_lz[:5000], chongxin=ds_cx[:5000])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧のとおりこの2つのアトラクタは重複が多いです。\n",
    "重複している点ではその履歴に応じて次の出力が決定されなければなりません。\n",
    "以下のセルはこの新しいアトラクタと、ローレンツアトラクタを、同じリードアウト層 $W^\\mathrm{out}$ で入力に応じて別々に出力するように学習します。\n",
    "果たしてうまく行くでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "rnd = np.random.default_rng(seed)\n",
    "\n",
    "net_dim = 1000\n",
    "out_dim = 3\n",
    "\n",
    "net = ESN(net_dim, sr=1.5, p=0.01, a=0.1, rnd=rnd)\n",
    "w_feed = Linear(out_dim, net_dim, bound=5.0, bias=0.5, rnd=rnd)\n",
    "w_in = Linear(1, net_dim, bound=0.1, rnd=rnd)\n",
    "w_out = FORCEReadout(net_dim, out_dim, lmbd=0.1, rnd=rnd, initialize_with_zero=True)\n",
    "\n",
    "x0 = rnd.uniform(-1, 1, (2, net_dim))\n",
    "\n",
    "t_total = 10000\n",
    "train_range = [1000, 6000]\n",
    "force_every = 2\n",
    "\n",
    "\n",
    "ds_all = np.array([ds_lz * 0.01, ds_cx * 0.01]).swapaxes(0, 1)\n",
    "us_all = np.zeros((len(ds_all), 2, 1))\n",
    "us_all[:, 1] = 1  # u=1 for lorenz\n",
    "us_all[:, 0] = -1  # u=-1 for chongxin\n",
    "\n",
    "record_t = emulate_parallel(\n",
    "    t_total,\n",
    "    x0,\n",
    "    net,\n",
    "    w_feed,\n",
    "    w_in,\n",
    "    w_out,\n",
    "    ds=ds_all,\n",
    "    us=us_all,\n",
    "    force_every=force_every,\n",
    "    train_range=train_range,\n",
    ")\n",
    "\n",
    "fig_lz = show_record(record_t, [\"x\", \"y\", \"dw\"], view_slice=(..., 0))\n",
    "fig_lz[0].set_title(\"Lorenz system\")\n",
    "fig_cx = show_record(record_t, [\"x\", \"y\", \"dw\"], view_slice=(..., 1))\n",
    "fig_cx[0].set_title(\"Chongxin system\")\n",
    "\n",
    "x1 = np.array(record_t[\"x\"][-1])\n",
    "record_e = emulate_parallel(10000, x1, net, w_feed, w_in, w_out, ds=ds_all[t_total:], us=us_all[t_total:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同じく、3次元座標上でアトラクタの形を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_3d_coord(\n",
    "    lorenz_out=record_e[\"y\"][:, 0],\n",
    "    lorenz_des=record_e[\"d\"][:, 0],\n",
    "    chongxin_out=record_e[\"y\"][:, 1],\n",
    "    chongxin_des=record_e[\"d\"][:, 1],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`..._des` が目標軌道 `..._out` が実際の出力を表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.4. (Advanced)\n",
    "- 上記の切り替えタスクで動的に $u[k]$ を変化させたとき何が生じるか確認せよ。\n",
    "- $-1$ と $1$ の中間の値を与えたときのアトラクタを描画せよ。\n",
    "- 他にも様々なアトラクタの埋め込みを試し、FORCE学習の利点と限界を探れ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Horii, Y., Inoue, K., Nishikawa, S., Nakajima, K., Niiyama, R., & Kuniyoshi, Y. (2021, July 19). *Physical reservoir computing in a soft swimming robot*. ALIFE 2021: The 2021 Conference on Artificial Life. https://doi.org/10.1162/isal_a_00426\n",
    "\n",
    "[2] DePasquale, B., Cueva, C. J., Rajan, K., Escola, G. S., & Abbott, L. F. (2018). *full-FORCE: A target-based method for training recurrent networks*. PLOS ONE, 13(2), e0191527. https://doi.org/10.1371/journal.pone.0191527\n",
    "\n",
    "[3] Laje, R., & Buonomano, D. V. (2013). *Robust timing and motor patterns by taming chaos in recurrent neural networks*. Nature Neuroscience, 16(7), 925–933. https://doi.org/10.1038/nn.3405\n",
    "\n",
    "[4] Jaeger, H., & Haas, H. (2004). *Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication*. Science, 304(5667), 78–80. https://doi.org/10.1126/science.1091277\n",
    "\n",
    "[5] Sussillo, D., & Abbott, L. F. (2009). *Generating Coherent Patterns of Activity from Chaotic Neural Networks*. Neuron, 63(4), 544–557. https://doi.org/10.1016/j.neuron.2009.07.018\n",
    "\n",
    "[6] Chongxin, L., Ling, L., Tao, L., & Peng, L. (2006). *A new butterfly-shaped attractor of Lorenz-like system*. Chaos, Solitons & Fractals, 28(5), 1196–1203. https://doi.org/10.1016/j.chaos.2004.09.111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc-bootcamp (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
